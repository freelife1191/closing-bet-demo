#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹œê·¸ë„ ìƒì„±ê¸° (Main Engine)
- Collectorë¡œë¶€í„° ë°ì´í„° ìˆ˜ì§‘
- Scorerë¡œ ì ìˆ˜ ê³„ì‚°
- PositionSizerë¡œ ìê¸ˆ ê´€ë¦¬
- ìµœì¢… Signal ìƒì„± (Batch LLM ì§€ì›)
"""

import asyncio
from datetime import date, datetime, timedelta
from typing import List, Optional, Dict
import time
import sys
import os
import json
import logging

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from engine.config import config, app_config
import engine.shared as shared_state
from engine.models import (
    StockData, Signal, SignalStatus, ScoreDetail, ChecklistDetail, ScreenerResult, ChartData, Grade
)
from engine.collectors import KRXCollector, EnhancedNewsCollector, NaverFinanceCollector
from engine.scorer import Scorer
from engine.position_sizer import PositionSizer

from engine.llm_analyzer import LLMAnalyzer
from engine.market_gate import MarketGate

logger = logging.getLogger(__name__)


class SignalGenerator:
    """ì¢…ê°€ë² íŒ… ì‹œê·¸ë„ ìƒì„±ê¸° (v2)"""

    def __init__(
        self,
        config=None,
        capital: float = 10_000_000,
    ):
        """
        Args:
            capital: ì´ ìë³¸ê¸ˆ (ê¸°ë³¸ 5ì²œë§Œì›)
            config: ì„¤ì • (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
        """
        self.config = config
        self.capital = capital

        self.scorer = Scorer(self.config)
        self.position_sizer = PositionSizer(capital, self.config)
        self.llm_analyzer = LLMAnalyzer()

        self._collector: Optional[KRXCollector] = None
        self._news: Optional[EnhancedNewsCollector] = None
        self._naver: Optional[NaverFinanceCollector] = None
        
        # ìŠ¤ìº” í†µê³„
        self.scan_stats = {
            "scanned": 0,
            "phase1": 0,
            "phase2": 0,
            "final": 0
        }
        
        # íƒˆë½ í†µê³„ (ì§„ë‹¨ìš©)
        self.drop_stats = {
            "low_trading_value": 0,
            "low_volume_ratio": 0,
            "low_pre_score": 0,
            "no_news": 0,
            "grade_fail": 0,
            "other": 0
        }

    async def __aenter__(self):
        self._collector = KRXCollector(self.config)
        await self._collector.__aenter__()

        self._news = EnhancedNewsCollector(self.config)
        await self._news.__aenter__()
        
        self._naver = NaverFinanceCollector(self.config)
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._collector:
            await self._collector.__aexit__(exc_type, exc_val, exc_tb)
        if self._news:
            await self._news.__aexit__(exc_type, exc_val, exc_tb)
        
        if self.llm_analyzer:
            await self.llm_analyzer.close()

    async def generate(
        self,
        target_date: date = None,
        markets: List[str] = None,
        top_n: int = 300,
    ) -> List[Signal]:
        """ì‹œê·¸ë„ ìƒì„± (Batch Processing ì ìš©)"""
        start_time = time.time()  # [Fix] ì‹œì‘ ì‹œê°„ ì´ˆê¸°í™”

        # ì£¼ë§/íœ´ì¼ ì²˜ë¦¬: ì œê³µëœ ë‚ ì§œê°€ ì—†ìœ¼ë©´ ê°€ì¥ ìµœê·¼ ì¥ ë§ˆê° ë‚ ì§œ ì‚¬ìš©
        if target_date is None:
            latest_str = self._collector._get_latest_market_date()
            target_date = datetime.strptime(latest_str, '%Y%m%d').date()
            
        markets = markets or ["KOSPI", "KOSDAQ"]

        all_signals = []
        
        # íƒˆë½ í†µê³„ ì´ˆê¸°í™”
        self.drop_stats = {
            "low_trading_value": 0,
            "low_volume_ratio": 0,
            "low_pre_score": 0,
            "no_news": 0,
            "grade_fail": 0,
            "other": 0
        }

        for market in markets:
            logger.info(f"="*60)
            logger.info(f"[ì¢…ê°€ë² íŒ…] {market} ìŠ¤í¬ë¦¬ë‹ ì‹œì‘ (v2.2 Batch)")
            logger.info(f"="*60)
            print(f"\n[{market}] ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª© ìŠ¤í¬ë¦¬ë‹... (v2.2 Batch)")

            # 1. ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª© ì¡°íšŒ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹œ ì§€ì • ë‚ ì§œ ì‚¬ìš©)
            target_date_str = target_date.strftime('%Y%m%d') if target_date else None
            candidates = await self._collector.get_top_gainers(market, top_n, target_date_str)
            logger.info(f"[{market}] ìƒìŠ¹ë¥  ìƒìœ„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(candidates)}ê°œ")
            print(f"  - 1ì°¨ í•„í„° í†µê³¼: {len(candidates)}ê°œ")
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.scan_stats["scanned"] += len(candidates)

            # --- Phase 1: Base Analysis & Pre-Screening ---
            pending_items = []  # {'stock':, 'charts':, 'supply':, 'news':}
            
            print(f"  [Phase 1] ê¸°ë³¸ ë¶„ì„ ë° ì„ ë³„ ì§„í–‰ ì¤‘...")
            for i, stock in enumerate(candidates):
                if shared_state.STOP_REQUESTED:
                    print(f"\n[STOP] ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€")
                    raise Exception("ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­")
                base_data = await self._analyze_base(stock)
                
                # 1ì°¨ í•„í„° ì¡°ê±´ ê°•í™” (2026-02-05):
                # - Pre-Score ë°©ì‹ ëŒ€ì‹  Determine Grade(Dê¸‰ ì´ìƒ) ì¡°ê±´ì„ ì„ í–‰ ì ìš©
                # - LLM ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ìµœì¢… í›„ë³´êµ° ìˆ˜ì¤€ë§Œ ë¶„ì„
                # PRE_SCORE_THRESHOLD = 2 (Deprecated)

                
                if base_data:
                    stock_obj = base_data['stock']
                    pre_score = base_data['pre_score']
                    score_details = base_data.get('score_details', {})
                    trading_value = getattr(stock_obj, 'trading_value', 0)
                    volume_ratio = score_details.get('volume_ratio', 0)
                    
                    # 1. 1ì°¨ í•„í„°: ê¸°ë³¸ ì¡°ê±´ (ê±°ë˜ëŒ€ê¸ˆ, ê±°ë˜ëŸ‰ ë“±)
                    # - ê±°ë˜ëŒ€ê¸ˆ 300ì–µ ì´ìƒ (Config Min)
                    # - ê±°ë˜ëŸ‰ ë°°ìˆ˜ 2ë°° ì´ìƒ
                    MIN_TRADING_VALUE = self.scorer.config.trading_value_min
                    
                    if trading_value < MIN_TRADING_VALUE:
                        self.drop_stats["low_trading_value"] += 1
                        print(f"    [Drop] ê±°ë˜ëŒ€ê¸ˆ ë¶€ì¡±: {stock.name} ({trading_value//100_000_000}ì–µ < {MIN_TRADING_VALUE//100_000_000}ì–µ)")
                        continue
                        
                    if volume_ratio < 2.0:
                        self.drop_stats["low_volume_ratio"] += 1
                        print(f"    [Drop] ê±°ë˜ëŸ‰ë°°ìˆ˜ ë¶€ì¡±: {stock.name} ({volume_ratio:.1f} < 2.0)")
                        continue

                    # 2. ìµœì¢… í•„í„° (Pre-LLM): ë“±ê¸‰ ë¯¸ë‹¬ ì‚¬ì „ ì°¨ë‹¨
                    # LLM ì—†ì´ë„ ìµœì†Œ Dë“±ê¸‰ ê¸°ì¤€(6ì )ì€ ë„˜ì–´ì•¼ í•¨
                    # (scorer.determine_gradeëŠ” ê±°ë˜ëŒ€ê¸ˆ, ë“±ë½ë¥ , ì ìˆ˜ ë“±ì„ ì¢…í•© í‰ê°€)
                    temp_grade = self.scorer.determine_grade(
                        stock_obj, pre_score, score_details, base_data['supply'], base_data['charts']
                    )
                    
                    if temp_grade:
                        # í†µê³¼
                        pending_items.append(base_data)
                        grade_val = getattr(temp_grade, 'value', temp_grade)
                        logger.debug(f"[Phase1 Pass] {stock.name}: Grade={grade_val}, Score={pre_score.total}")
                    else:
                        # ë“±ê¸‰ ë¯¸ë‹¬ íƒˆë½
                        self.drop_stats["grade_fail"] += 1
                        # 1ì°¨ í•„í„°ëŠ” í†µê³¼í–ˆìœ¼ë‚˜ ë“±ê¸‰ ìš”ê±´ ë¶ˆì¶©ì¡±
                        print(f"    [Drop] ë“±ê¸‰ ë¯¸ë‹¬: {stock.name} (Score={pre_score.total}, Pre-Grade=None)")
                
                if (i+1) % 10 == 0:
                    print(f"    Processing {i+1}/{len(candidates)}...", end='\r')
            
            logger.info(f"[Phase1 ì™„ë£Œ] {market}: {len(pending_items)}ê°œ í†µê³¼ (íƒˆë½: ê±°ë˜ëŒ€ê¸ˆë¶€ì¡±={self.drop_stats['low_trading_value']}, ê±°ë˜ëŸ‰ë¶€ì¡±={self.drop_stats['low_volume_ratio']}, ë“±ê¸‰ë¯¸ë‹¬={self.drop_stats['grade_fail']})")
            print(f"\n    -> 1ì°¨ ì„ ë³„ ì™„ë£Œ: {len(pending_items)}ê°œ (ì‚¬ì „ ë“±ê¸‰ Dê¸‰ ì´ìƒ, ëŒ€ê¸ˆ/ê±°ë˜ëŸ‰ ì¶©ì¡±)")
            self.scan_stats["phase1"] += len(pending_items)

            # --- Phase 2: News Fetching & Batch LLM ---
            print(f"  [Phase 2] ë‰´ìŠ¤ ìˆ˜ì§‘ ë° Batch LLM ë¶„ì„...")
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            stocks_to_analyze = []
            news_fail_count = 0
            for item in pending_items:
                if shared_state.STOP_REQUESTED:
                    print(f"\n[STOP] ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€")
                    raise Exception("ì‚¬ìš©ì ìš”ì²­ ì¤‘ë‹¨")
                stock = item['stock']
                news_list = await self._news.get_stock_news(stock.code, 3, stock.name)
                if news_list:
                    item['news'] = news_list
                    stocks_to_analyze.append(item)
                    logger.debug(f"[ë‰´ìŠ¤] {stock.name}: {len(news_list)}ê°œ ìˆ˜ì§‘")
                else:
                    news_fail_count += 1
                    self.drop_stats["no_news"] += 1
                    logger.debug(f"[ë‰´ìŠ¤ ì—†ìŒ] {stock.name}")
            
            logger.info(f"[Phase2 ë‰´ìŠ¤ìˆ˜ì§‘] {market}: {len(stocks_to_analyze)}ê°œ ì„±ê³µ, {news_fail_count}ê°œ ë‰´ìŠ¤ ì—†ìŒ")
            print(f"    -> ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(stocks_to_analyze)}ê°œ ì¢…ëª© (ë‰´ìŠ¤ ì—†ìŒ: {news_fail_count}ê°œ)")

            # Market Gate ìƒíƒœ ì¡°íšŒ
            market_status = None
            try:
                from engine.market_gate import MarketGate
                mg = MarketGate()
                market_status = mg.analyze()
            except Exception as e:
                print(f"    âš ï¸ Market Gate ì¡°íšŒ ì‹¤íŒ¨: {e}")

            # Batch LLM Analysis
            llm_results_map = {}
            if self.llm_analyzer.client and stocks_to_analyze:
                # Provider check (Analysis LLM)
                is_analysis_llm = app_config.LLM_PROVIDER == 'gemini' # or other analysis providers
                
                # 5ê°œì”© Chunking
                chunk_size = app_config.ANALYSIS_LLM_CHUNK_SIZE if is_analysis_llm else app_config.LLM_CHUNK_SIZE
                chunks = [stocks_to_analyze[i:i + chunk_size] for i in range(0, len(stocks_to_analyze), chunk_size)]
                
                total_chunks = len(chunks)
                # 5. Parallel Batch Processing
                concurrency = app_config.ANALYSIS_LLM_CONCURRENCY if is_analysis_llm else app_config.LLM_CONCURRENCY
                semaphore = asyncio.Semaphore(concurrency)
                
                async def _process_chunk(chunk_idx, chunk_data):
                    async with semaphore:
                        try:
                            start = time.time()
                            print(f"    [LLM Batch] Processing Chunk {chunk_idx}/{total_chunks} ({len(chunk_data)} stocks)...")
                            # chunk_dataëŠ” ì´ë¯¸ full context dict ë¦¬ìŠ¤íŠ¸ì„
                            result = await self.llm_analyzer.analyze_news_batch(chunk_data, market_status)
                            elapsed = time.time() - start
                            print(f"    âœ… Chunk {chunk_idx} Done in {elapsed:.2f}s")
                            return result
                        except Exception as e:
                            print(f"    âš ï¸ Chunk {chunk_idx} Error: {e}")
                            return {}

                tasks = [
                    _process_chunk(i, chunk) 
                    for i, chunk in enumerate(chunks, 1)
                ]
                
                print(f"    ğŸš€ Starting {len(tasks)} batch requests (Concurrency: {concurrency})...")
                results_list = await asyncio.gather(*tasks)
                
                for res in results_list:
                    if res:
                        llm_results_map.update(res)

            # --- Phase 3: Final Scoring ---
            print(f"  [Phase 3] ìµœì¢… ì ìˆ˜ ê³„ì‚°...")
            for item in stocks_to_analyze:
                stock = item['stock']
                llm_result = llm_results_map.get(stock.name)
                
                # í…Œë§ˆ ìˆ˜ì§‘
                themes = await self._naver.get_themes(stock.code) if self._naver else []
                
                # ìµœì¢… ì‹œê·¸ë„ ìƒì„±
                signal = self._create_final_signal(
                    stock, target_date, item['news'], llm_result, item['charts'], item['supply'], themes
                )

                if signal:
                    grade_val = getattr(signal.grade, 'value', signal.grade)
                    if grade_val != 'C':
                        all_signals.append(signal)
                        logger.info(f"[ì‹œê·¸ë„ ìƒì„±] {stock.name}: {grade_val}ê¸‰ (ì ìˆ˜: {signal.score.total}, ê±°ë˜ëŒ€ê¸ˆ: {stock.trading_value//100_000_000}ì–µ, ë“±ë½ë¥ : {stock.change_pct:.1f}%)")
                        print(f"    âœ… {stock.name}: {grade_val}ê¸‰ (ì ìˆ˜: {signal.score.total})")
                else:
                    self.drop_stats["grade_fail"] += 1

            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (KOSPI ë¶„ì„ ì™„ë£Œ í›„ ì¦‰ì‹œ ë°˜ì˜ì„ ìœ„í•´)
            if market == markets[0] and len(markets) > 1:
                mid_processing_time = (time.time() - start_time) * 1000
                mid_result = ScreenerResult(
                    date=target_date, # [Fix] parsed_date -> target_date
                    total_candidates=len(all_signals),
                    filtered_count=self.scan_stats.get("phase1", 0), # [Fix] generator -> self
                    scanned_count=self.scan_stats.get("scanned", 0),  # [Fix] generator -> self
                    signals=all_signals,
                    by_grade=self.get_summary(all_signals)["by_grade"], # [Fix] generator -> self
                    by_market=self.get_summary(all_signals)["by_market"], # [Fix] generator -> self
                    processing_time_ms=mid_processing_time,
                    market_status=market_status,
                    market_summary="", # ì¤‘ê°„ ë‹¨ê³„ì—ì„œëŠ” ìš”ì•½ ìƒëµ
                    trending_themes=[] # ì¤‘ê°„ ë‹¨ê³„ì—ì„œëŠ” í…Œë§ˆ ìƒëµ
                )
                save_result_to_json(mid_result)
                logger.info(f"[{market}] ë¶„ì„ ì™„ë£Œ - ì¤‘ê°„ ê²°ê³¼ ì €ì¥ë¨ ({len(all_signals)}ê°œ ì‹œê·¸ë„)")

        return all_signals

    async def _analyze_base(self, stock: StockData) -> Optional[Dict]:
        """1ë‹¨ê³„: ê¸°ë³¸ ë¶„ì„ (ì°¨íŠ¸, ìˆ˜ê¸‰, Pre-Score)"""
        try:
            # ìƒì„¸ ì •ë³´
            detail = await self._collector.get_stock_detail(stock.code)
            if detail:
                stock.high_52w = detail.get('high_52w', stock.high_52w)
                stock.low_52w = detail.get('low_52w', stock.low_52w)

            # ì°¨íŠ¸
            charts = await self._collector.get_chart_data(stock.code, 60)
            
            # ìˆ˜ê¸‰
            supply = await self._collector.get_supply_data(stock.code)
            
            # Pre-Score ê³„ì‚° (ë‰´ìŠ¤/LLM ì—†ìŒ)
            pre_score, _, score_details = self.scorer.calculate(stock, charts, [], supply, None)
            
            return {
                'stock': stock,
                'charts': charts,
                'supply': supply,
                'pre_score': pre_score,
                'score_details': score_details
            }
        except Exception as e:
            print(f"    âš ï¸ ê¸°ë³¸ ë¶„ì„ ì˜¤ë¥˜ {stock.name}: {e}")
            return None

    def _create_final_signal(
        self, stock, target_date, news_list, llm_result, charts, supply, themes: List[str] = None
    ) -> Optional[Signal]:
        """ìµœì¢… ì‹œê·¸ë„ ìƒì„± í—¬í¼"""
        try:
            # ì ìˆ˜ ê³„ì‚°
            score, checklist, score_details = self.scorer.calculate(stock, charts, news_list, supply, llm_result)
            
            # [Fix] AI ë¶„ì„ ê²°ê³¼ ë³´ì¡´
            if llm_result:
                score_details['ai_evaluation'] = llm_result
                score.ai_evaluation = llm_result
            
            # ë“±ê¸‰ ë¯¸ë‹¬ ì œì™¸ (None)
            grade = self.scorer.determine_grade(stock, score, score_details, supply, charts)
            
            if not grade:
                print(f"    [DEBUG] ë“±ê¸‰íƒˆë½ {stock.name}: Score={score.total}, Value={stock.trading_value//100_000_000}ì–µ, Rise={stock.change_pct}%, VolRatio={score_details.get('volume_ratio', 0)}")
                return None

            # í¬ì§€ì…˜ ê³„ì‚°
            position = self.position_sizer.calculate(stock.close, grade)

            return Signal(
                stock_code=stock.code,
                stock_name=stock.name,
                market=stock.market,
                sector=stock.sector,
                signal_date=target_date,
                signal_time=datetime.now(),
                grade=grade,
                score=score,
                checklist=checklist,
                news_items=[{
                    "title": n.title,
                    "source": n.source,
                    "published_at": n.published_at.isoformat() if n.published_at else "",
                    "url": n.url,
                    "weight": getattr(n, 'weight', 1.0)
                } for n in news_list[:5]],
                current_price=stock.close,
                change_pct=stock.change_pct,
                entry_price=position.entry_price,
                stop_price=position.stop_price,
                target_price=position.target_price,
                r_value=position.r_value,
                position_size=position.position_size,
                quantity=position.quantity,
                r_multiplier=position.r_multiplier,
                trading_value=stock.trading_value,
                volume_ratio=score_details.get('volume_ratio', 0.0),
                status=SignalStatus.PENDING,
                created_at=datetime.now(),
                score_details=score_details,
                themes=themes or []
            )
        except Exception as e:
            print(f"    âš ï¸ ì‹œê·¸ë„ ìƒì„± ì˜¤ë¥˜ {stock.name}: {e}")
            return None

    async def _analyze_stock(self, stock: StockData, target_date: date) -> Optional[Signal]:
        """ë‹¨ì¼ ì¢…ëª© ë¶„ì„ (ê¸°ì¡´ í˜¸í™˜ìš© - Batch ë¯¸ì‚¬ìš©)"""
        # 1. Base Analysis
        base_data = await self._analyze_base(stock)
        if not base_data: return None
        
        # 2. News
        news_list = await self._news.get_stock_news(stock.code, 3, stock.name)
        
        # 3. LLM (Single)
        llm_result = None
        if news_list and self.llm_analyzer.client:
            print(f"    [LLM] Analyzing {stock.name} news...")
            news_dicts = [{"title": n.title, "summary": n.summary} for n in news_list]
            llm_result = await self.llm_analyzer.analyze_news_sentiment(stock.name, news_dicts)

        # 4. Finalize
        return self._create_final_signal(
            stock, target_date, news_list, llm_result, base_data['charts'], base_data['supply']
        )


    def get_summary(self, signals: List[Signal]) -> Dict:
        """ì‹œê·¸ë„ ìš”ì•½ ì •ë³´"""
        summary = {
            "total": len(signals),
            "by_grade": {g: 0 for g in ['S', 'A', 'B', 'C', 'D']},
            "by_market": {},
            "total_position": 0,
            "total_risk": 0,
        }

        for s in signals:
            if hasattr(s, 'grade'):
                grade_val = getattr(s.grade, 'value', s.grade)
                if grade_val in summary["by_grade"]:
                    summary["by_grade"][grade_val] += 1
            
            if hasattr(s, 'market'):
                summary["by_market"][s.market] = summary["by_market"].get(s.market, 0) + 1
            
            if hasattr(s, 'position_size'):
                summary["total_position"] += s.position_size
            
            if hasattr(s, 'r_value') and hasattr(s, 'r_multiplier'):
                summary["total_risk"] += s.r_value * s.r_multiplier

        return summary


async def run_screener(
    capital: float = 50_000_000,
    markets: List[str] = None,
    target_date: str = None,  # YYYY-MM-DD í˜•ì‹ (í…ŒìŠ¤íŠ¸ìš©)
    top_n: int = 300,
) -> ScreenerResult:
    """
    ìŠ¤í¬ë¦¬ë„ˆ ì‹¤í–‰ (ê°„í¸ í•¨ìˆ˜)
    """
    start_time = time.time()
    
    # target_date ë¬¸ìì—´ì„ date ê°ì²´ë¡œ ë³€í™˜
    parsed_date = None
    if target_date:
        try:
            parsed_date = datetime.strptime(target_date, '%Y-%m-%d').date()
            print(f"[í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì§€ì • ë‚ ì§œ ê¸°ì¤€ ë¶„ì„: {target_date}")
        except ValueError:
            print(f"[ê²½ê³ ] ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {target_date} (YYYY-MM-DD í•„ìš”)")
            parsed_date = None

    async with SignalGenerator(capital=capital) as generator:
        signals = await generator.generate(target_date=parsed_date, markets=markets, top_n=top_n)
        summary = generator.get_summary(signals)
        
        # 2. Market Gate ì‹¤í–‰
        print(f"\n[Market Gate] ì‹œì¥ ìƒíƒœ ë¶„ì„ ì¤‘...")
        market_status = {}
        try:
            market_gate = MarketGate()
            market_status = market_gate.analyze()
            market_gate.save_analysis(market_status)
            print(f"  -> ìƒíƒœ: {market_status.get('status')} (Score: {market_status.get('total_score')})")
        except Exception as e:
            logger.error(f"Market Gate Error: {e}")
        
        # 3. Final Market Summary (LLM)
        print(f"\n[Final Summary] ì‹œì¥ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        market_summary = ""
        try:
            market_summary = await generator.llm_analyzer.generate_market_summary(
                [s.to_dict() for s in signals]
            )
            print(f"  -> ìš”ì•½ ì™„ë£Œ ({len(market_summary)}ì)")
        except Exception as e:
            logger.error(f"Market Summary Error: {e}")

        # 4. Trending Themes ì§‘ê³„
        trending_themes = []
        try:
            from collections import Counter
            all_themes = []
            for s in signals:
                if s.themes:
                    all_themes.extend(s.themes)
            
            theme_counts = Counter(all_themes)
            trending_themes = [theme for theme, count in theme_counts.most_common(20)]
            print(f"  -> Trending Themes: {trending_themes[:5]}...")
        except Exception as e:
            logger.error(f"Themes Error: {e}")

        processing_time = (time.time() - start_time) * 1000

        result = ScreenerResult(
            date=parsed_date if parsed_date else date.today(),
            total_candidates=len(signals),
            filtered_count=generator.scan_stats.get("phase1", 0),
            scanned_count=generator.scan_stats.get("scanned", 0),
            signals=signals,
            by_grade=summary["by_grade"],
            by_market=summary["by_market"],
            processing_time_ms=processing_time,
            market_status=market_status,
            market_summary=market_summary,
            trending_themes=trending_themes
        )

        # ê²°ê³¼ ì €ì¥
        save_result_to_json(result)

        # ë©”ì‹ ì € ì•Œë¦¼ ë°œì†¡
        try:
            from engine.messenger import Messenger
            messenger = Messenger()
            messenger.send_screener_result(result)
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ë©”ì‹ ì € ë°œì†¡ ì‹¤íŒ¨: {e}")

        return result


async def analyze_single_stock_by_code(
    code: str,
    capital: float = 50_000_000,
) -> Optional[Signal]:
    """ë‹¨ì¼ ì¢…ëª© ì¬ë¶„ì„"""
    async with SignalGenerator(capital=capital) as generator:
        # ê¸°ë³¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        detail = await generator._collector.get_stock_detail(code)
        if not detail:
            return None

        # StockData ë³µì›
        stock = StockData(
            code=code,
            name=detail.get('name', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª©'),
            market='KOSPI',
            sector='ê¸°íƒ€',
            close=50000,
            change_pct=0,
            trading_value=100_000_000,
            volume=0,
            marcap=0
        )

        # ì¬ë¶„ì„ ì‹¤í–‰
        new_signal = await generator._analyze_stock(stock, date.today())

        if new_signal:
            # JSON ì—…ë°ì´íŠ¸
            update_single_signal_json(code, new_signal)

        return new_signal


def save_result_to_json(result: ScreenerResult):
    """ê²°ê³¼ JSON ì €ì¥"""
    data_dir = "data"
    os.makedirs(data_dir, exist_ok=True)

    data = {
        "date": result.date.isoformat(),
        "total_candidates": result.total_candidates,
        "filtered_count": result.filtered_count,
        "signals": [s.to_dict() for s in result.signals],
        "by_grade": result.by_grade,
        "by_market": result.by_market,
        "processing_time_ms": result.processing_time_ms,
        "market_status": result.market_status,
        "market_summary": result.market_summary,
        "trending_themes": result.trending_themes,
        "scanned_count": getattr(result, "scanned_count", 0),
        "updated_at": datetime.now().isoformat()
    }

    # Daily íŒŒì¼
    date_str = result.date.strftime("%Y%m%d")
    daily_path = os.path.join(data_dir, f"jongga_v2_results_{date_str}.json")

    with open(daily_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    # Latest íŒŒì¼
    latest_path = os.path.join(data_dir, "jongga_v2_latest.json")
    with open(latest_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"\n[ì €ì¥ ì™„ë£Œ] Daily: {daily_path}")
    print(f"[ì €ì¥ ì™„ë£Œ] Latest: {latest_path}")


def update_single_signal_json(code: str, signal: Signal):
    """ë‹¨ì¼ ì¢…ëª© ì‹œê·¸ë„ ì—…ë°ì´íŠ¸"""
    import glob

    data_dir = "data"
    latest_path = os.path.join(data_dir, "jongga_v2_latest.json")

    if not os.path.exists(latest_path):
        return

    with open(latest_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # í•´ë‹¹ ì¢…ëª© êµì²´
    updated_signals = [
        signal.to_dict() if s["stock_code"] == code else s
        for s in data["signals"]
    ]

    data["signals"] = updated_signals
    data["updated_at"] = datetime.now().isoformat()

    # ì €ì¥
    with open(latest_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    # Daily íŒŒì¼ë„ ì—…ë°ì´íŠ¸
    date_str = date.today().strftime("%Y%m%d")
    daily_path = os.path.join(data_dir, f"jongga_v2_results_{date_str}.json")
    if os.path.exists(daily_path):
        with open(daily_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸
async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 60)
    print("ì¢…ê°€ë² íŒ… ì‹œê·¸ë„ ìƒì„±ê¸° v2")
    print("=" * 60)

    capital = 50_000_000
    print(f"\nìë³¸ê¸ˆ: {capital:,}ì›")
    print(f"Rê°’: {capital * 0.005:,.0f}ì› (0.5%)")

    result = await run_screener(capital=capital)

    print(f"\nì²˜ë¦¬ ì‹œê°„: {result.processing_time_ms:.0f}ms")
    print(f"ìƒì„±ëœ ì‹œê·¸ë„: {len(result.signals)}ê°œ")
    print(f"ë“±ê¸‰ë³„: {result.by_grade}")

    print("\n" + "=" * 60)
    print("ì‹œê·¸ë„ ìƒì„¸")
    print("=" * 60)

    for i, signal in enumerate(result.signals, 1):
        print(f"\n[{i}] {signal.stock_name} ({signal.stock_code})")
        print(f"    ë“±ê¸‰: {getattr(signal.grade, 'value', signal.grade)}")
        print(f"    ì ìˆ˜: {signal.score.total}/12")
        print(f"    ë“±ë½ë¥ : {signal.change_pct:+.2f}%")
        print(f"    ì§„ì…ê°€: {signal.entry_price:,}ì›")
        print(f"    ì†ì ˆê°€: {signal.stop_price:,}ì›")
        print(f"    ëª©í‘œê°€: {signal.target_price:,}ì›")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nì¤‘ë‹¨ë¨")
