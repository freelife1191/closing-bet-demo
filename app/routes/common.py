#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³µí†µ API ë¼ìš°íŠ¸
"""
from flask import Blueprint, jsonify, request
import pandas as pd
import os
import json
import logging
import logging
import random
import threading
import sys
from datetime import datetime
from threading import Lock, Thread
import traceback
import re

# Add scripts directory to path for importing init_data
scripts_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'scripts')
if scripts_dir not in sys.path:
    sys.path.append(scripts_dir)

logger = logging.getLogger(__name__)

common_bp = Blueprint('common', __name__)


# ====== ADMIN ê¶Œí•œ í™•ì¸ API ======
@common_bp.route('/admin/check')
def check_admin():
    """
    ADMIN ê¶Œí•œ í™•ì¸ API
    - ì´ë©”ì¼ì´ ADMIN_EMAILS í™˜ê²½ë³€ìˆ˜ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    - í”„ë¡ íŠ¸ì—”ë“œì˜ useAdmin í›…ì—ì„œ í˜¸ì¶œ
    """
    email = request.args.get('email', '').strip().lower()
    
    if not email:
        return jsonify({'isAdmin': False, 'error': 'Email required'}), 400

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ADMIN ì´ë©”ì¼ ëª©ë¡ ë¡œë“œ
    admin_emails_str = os.environ.get('ADMIN_EMAILS', '')
    admin_emails = [e.strip().lower() for e in admin_emails_str.split(',') if e.strip()]
    
    is_admin = email in admin_emails
    
    logger.debug(f"Admin check: {email} -> {is_admin}")
    
    return jsonify({'isAdmin': is_admin})


try:
    import engine.shared as shared_state
except ImportError:
    # Fallback if engine package not found in path
    import sys, os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    import sys, os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    import engine.shared as shared_state

from services.paper_trading import paper_trading

# Status File Path
UPDATE_STATUS_FILE = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'data', 'update_status.json')
update_lock = Lock()

def load_update_status():
    """ìƒíƒœ íŒŒì¼ ë¡œë“œ"""
    default_status = {
        'isRunning': False,
        'startTime': None,
        'currentItem': None,
        'items': []
    }
    
    if os.path.exists(UPDATE_STATUS_FILE):
        try:
            with open(UPDATE_STATUS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load update status: {e}")
            return default_status
    return default_status

def save_update_status(status):
    """ìƒíƒœ íŒŒì¼ ì €ì¥ (Atomic Write)"""
    try:
        # Ensure directory exists
        os.makedirs(os.path.dirname(UPDATE_STATUS_FILE), exist_ok=True)
        
        # Write to temp file first
        tmp_file = UPDATE_STATUS_FILE + ".tmp"
        with open(tmp_file, 'w', encoding='utf-8') as f:
            json.dump(status, f, indent=2, ensure_ascii=False)
            f.flush()
            os.fsync(f.fileno()) # Ensure write to disk
            
        # Atomic replace
        os.replace(tmp_file, UPDATE_STATUS_FILE)
            
    except Exception as e:
        logger.error(f"Failed to save update status: {e}")

def start_update(items_list):
    """ì—…ë°ì´íŠ¸ ì‹œì‘"""
    with update_lock:
        shared_state.STOP_REQUESTED = False
        status = load_update_status()
        status['isRunning'] = True
        status['startTime'] = datetime.now().isoformat()
        status['items'] = [{'name': name, 'status': 'pending'} for name in items_list]
        status['currentItem'] = None
        save_update_status(status)

def update_item_status(name, status_code):
    """ì•„ì´í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    with update_lock:
        status = load_update_status()
        for item in status['items']:
            if item['name'] == name:
                item['status'] = status_code
                if status_code == 'running':
                    status['currentItem'] = name
                break
        save_update_status(status)

def stop_update():
    """ì—…ë°ì´íŠ¸ ì¤‘ë‹¨"""
    with update_lock:
        shared_state.STOP_REQUESTED = True
        status = load_update_status()
        status['isRunning'] = False
        status['currentItem'] = None
        
        # ëª…ì‹œì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì¸ í•­ëª©ì„ error/stoppedë¡œ ë³€ê²½
        for item in status['items']:
            if item['status'] == 'running':
                # ì‚¬ìš©ìê°€ ì¤‘ì§€í–ˆìœ¼ë¯€ë¡œ 'error'ë³´ë‹¤ëŠ” 'stopped'ê°€ ë§ìŒ (ë˜ëŠ” UIê°€ ì¸ì‹í•˜ëŠ” ì‹¤íŒ¨ ì½”ë“œë¡œ)
                item['status'] = 'error' 
            elif item['status'] == 'pending':
                item['status'] = 'cancelled' # ëŒ€ê¸° ì¤‘ì¸ ê±´ ì·¨ì†Œë¨ -> UIì—ì„œ ë©ˆì¶¤ ì²˜ë¦¬
        
        # [ì‚¬ìš©ì ìš”ì²­] ê¹”ë”í•˜ê²Œ ì¤‘ì§€ë˜ê³  UIê°€ ì²˜ìŒ ì‹œì‘í•˜ê¸° ì „ìœ¼ë¡œ ì´ˆê¸°í™”
        # í•˜ì§€ë§Œ ìƒíƒœ í™•ì¸ì„ ìœ„í•´ itemsëŠ” ë‚¨ê²¨ë‘ë˜, cancelled ì²˜ë¦¬ëœ ê²ƒì€ UIê°€ ì•Œì•„ì„œ ì²˜ë¦¬í•´ì•¼ í•¨.
        # ë§Œì•½ "ì™„ì „ ì´ˆê¸°í™”"ë¥¼ ì›í•œë‹¤ë©´ status['items'] = [] í•  ìˆ˜ë„ ìˆì§€ë§Œ, 
        # ì§ì „ ì‹¤íŒ¨ ë‚´ì—­ì€ ë³´ì—¬ì£¼ëŠ” ê²Œ UXìƒ ë‚˜ì„ ìˆ˜ ìˆìŒ. ì¼ë‹¨ ìƒíƒœ ì½”ë“œ ë³€ê²½ìœ¼ë¡œ ëŒ€ì‘.
        
        save_update_status(status)

def finish_update():
    """ì—…ë°ì´íŠ¸ ì™„ë£Œ"""
    with update_lock:
        status = load_update_status()
        status['isRunning'] = False
        status['currentItem'] = None
        # ì™„ë£Œ ì‹œ itemsë¥¼ ë‚¨ê²¨ë‘ì–´ UIì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆê²Œ í•¨ (ë‹¤ìŒ start ì‹œ ì´ˆê¸°í™”ë¨)
        # status['items'] = [] 
        save_update_status(status)

@common_bp.route('/system/update-status')
def get_update_status():
    """ì—…ë°ì´íŠ¸ ìƒíƒœë§Œ ì¡°íšŒ (ê°€ë²¼ìš´ í´ë§ìš©)"""
    # ì½ê¸° ì‹œì—ëŠ” Lockì„ ê±¸ì§€ ì•Šì•„ë„ ë¬´ë°© (íŒŒì¼ ì‹œìŠ¤í…œ ì›ìì„± ì˜ì¡´)
    # ë‹¤ë§Œ ì“°ê¸°ì™€ ê²¹ì¹˜ë©´ ë¹ˆ íŒŒì¼ ì½ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Lock ì‚¬ìš© ê¶Œì¥
    with update_lock:
        status = load_update_status()
        # DEBUG: ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸ìš©
        status['_debug_path'] = UPDATE_STATUS_FILE
        status['_debug_exists'] = os.path.exists(UPDATE_STATUS_FILE)
        return jsonify(status)


@common_bp.route('/system/start-update', methods=['POST'])
def api_start_update():
    """ì—…ë°ì´íŠ¸ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)"""
    data = request.get_json() or {}
    items_list = data.get('items', [])
    target_date = data.get('target_date') # YYYY-MM-DD or None
    force = data.get('force', False) # Force update flag
    
    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ê±°ë¶€
    current_status = load_update_status()
    if current_status['isRunning']:
        return jsonify({'status': 'error', 'message': 'Already running'}), 400

    # UI ìƒíƒœ ì´ˆê¸°í™”
    start_update(items_list)
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹¤í–‰
    thread = Thread(target=run_background_update, args=(target_date, items_list, force))
    thread.daemon = True
    thread.start()
    
    return jsonify({'status': 'ok'})


def run_background_update(target_date, selected_items=None, force=False):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
    import asyncio
    
    # Default to all items if not specified
    if selected_items is None:
        selected_items = ['Daily Prices', 'Institutional Trend', 'Market Gate', 'VCP Signals', 'AI Analysis', 'AI Jongga V2']

    try:
        from scripts import init_data

        # 1. Daily Prices
        if 'Daily Prices' in selected_items:
            if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
            update_item_status('Daily Prices', 'running')
            try:
                # Force parameter supported
                init_data.create_daily_prices(target_date, force=force)
                update_item_status('Daily Prices', 'done')
            except Exception as e:
                logger.error(f"Daily Prices Failed: {e}")
                update_item_status('Daily Prices', 'error')
                if shared_state.STOP_REQUESTED: raise e # ì¤‘ë‹¨ ìš”ì²­ì´ë©´ ì „ì²´ ì¤‘ë‹¨
            
        # 2. Institutional Trend
        if 'Institutional Trend' in selected_items:
            if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
            update_item_status('Institutional Trend', 'running')
            try:
                # Force parameter supported
                init_data.create_institutional_trend(target_date, force=force)
                update_item_status('Institutional Trend', 'done')
            except Exception as e:
                logger.error(f"Institutional Trend Failed: {e}")
                update_item_status('Institutional Trend', 'error')
                if shared_state.STOP_REQUESTED: raise e

        # 2.5 Market Gate Analysis
        if 'Market Gate' in selected_items:
            if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
            update_item_status('Market Gate', 'running')
            try:
                from engine.market_gate import MarketGate
                mg = MarketGate()
                result = mg.analyze(target_date)
                mg.save_analysis(result, target_date)
                update_item_status('Market Gate', 'done')
            except Exception as e:
                logger.error(f"Market Gate Failed: {e}")
                update_item_status('Market Gate', 'error')
                if shared_state.STOP_REQUESTED: raise e

        # 3. VCP Signals
        if 'VCP Signals' in selected_items:
            if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
            update_item_status('VCP Signals', 'running')
            vcp_df = None
            try:
                # 1. ì‹œê·¸ë„ ìƒì„± (ê¸°ì¡´ ë¡œì§)
                vcp_df = init_data.create_signals_log(target_date)
                
                # 2. [FIX] ê¸°ì¡´ ì—´ë¦° ì‹œê·¸ë„ ì„±ê³¼ ì—…ë°ì´íŠ¸ (Tracker ì—°ë™)
                try:
                    from engine.signal_tracker import SignalTracker
                    tracker = SignalTracker()
                    tracker.update_open_signals()
                    logger.info("SignalTracker: Open signals updated")
                except Exception as tracker_e:
                    logger.warning(f"SignalTracker update failed (non-critical): {tracker_e}")
                
                update_item_status('VCP Signals', 'done')
            except Exception as e:
                logger.error(f"VCP Signals Failed: {e}")
                update_item_status('VCP Signals', 'error')
                if shared_state.STOP_REQUESTED: raise e

        # 4. AI Analysis
        if 'AI Analysis' in selected_items:
            if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
            update_item_status('AI Analysis', 'running')
            try:
                from engine.kr_ai_analyzer import KrAiAnalyzer
                import pandas as pd
                import json
                
                # ê²½ë¡œ ì„¤ì •
                base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                data_dir = os.path.join(base_dir, 'data')
                signals_path = os.path.join(data_dir, 'signals_log.csv')
                
                if os.path.exists(signals_path):
                    # ìš°ì„  ë©”ëª¨ë¦¬ì— ìˆëŠ” vcp_df ì‚¬ìš© (ì‹¤ì‹œê°„ì„± ë³´ì¥)
                    target_df = pd.DataFrame()
                    analysis_date = target_date if target_date else datetime.now().strftime('%Y-%m-%d')
                    
                    if 'VCP Signals' in selected_items and 'vcp_df' in locals() and vcp_df is not None and hasattr(vcp_df, 'empty') and not vcp_df.empty:
                        logger.info("VCP ê²°ê³¼ ë©”ëª¨ë¦¬ì—ì„œ ë¡œë“œ")
                        target_df = vcp_df.copy()
                        if 'signal_date' in target_df.columns:
                            analysis_date = str(target_df['signal_date'].iloc[0])
                    else:
                        logger.info("VCP ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„")
                        df = pd.read_csv(signals_path)
                        if not df.empty and 'signal_date' in df.columns:
                            # ë¶„ì„ ë‚ ì§œ ê²°ì •
                            if not target_date:
                                analysis_date = str(df['signal_date'].max())
                                
                            # í•´ë‹¹ ë‚ ì§œ ë°ì´í„° í•„í„°ë§
                            target_df = df[df['signal_date'].astype(str) == analysis_date].copy()
                    
                    if not target_df.empty:
                            # í‹°ì»¤ ì •ê·œí™” ë° ì¤‘ë³µ ì œê±° (ë¶„ì„ ëŒ€ìƒ í™•ë³´)
                            target_df['ticker'] = target_df['ticker'].astype(str).str.zfill(6)
                            target_df = target_df.drop_duplicates(subset=['ticker'])
                            
                            # Score ìˆ«ìí˜• ë³€í™˜ (ì •ë ¬ ì˜¤ë¥˜ ë°©ì§€)
                            if 'score' in target_df.columns:
                                target_df['score'] = pd.to_numeric(target_df['score'], errors='coerce').fillna(0)
                            
                            # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 20ê°œ ë¶„ì„ (ì‚¬ìš©ì ìš”ì²­: ì „ì²´/ë‹¤ìˆ˜ ë¶„ì„)
                            target_df = target_df.sort_values('score', ascending=False).head(20)
                            tickers = target_df['ticker'].tolist()
                            
                            # [ì‚¬ìš©ì ìš”ì²­] ì¬ë¶„ì„ ì‹œ í•´ë‹¹ ë‚ ì§œì˜ ê¸°ì¡´ AI ê²°ê³¼ íŒŒì¼ ì‚­ì œ (ì°Œêº¼ê¸° ë°ì´í„° ë°©ì§€)
                            date_str_clean = analysis_date.replace('-', '')
                            target_filename = f'ai_analysis_results_{date_str_clean}.json'
                            target_filepath = os.path.join(data_dir, target_filename)
                            
                            if os.path.exists(target_filepath):
                                try:
                                    os.remove(target_filepath)
                                    logger.info(f"ê¸°ì¡´ AI ë¶„ì„ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {target_filename}")
                                except Exception as del_err:
                                    logger.warning(f"ê¸°ì¡´ AI íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {del_err}")

                            logger.info(f"AI ë¶„ì„ ì‹œì‘: {len(tickers)} ì¢…ëª© ({analysis_date})")
                            
                            analyzer = KrAiAnalyzer()
                            # ë¶„ì„ ì‹¤í–‰
                            results = analyzer.analyze_multiple_stocks(tickers)
                            
                            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                            results['generated_at'] = datetime.now().isoformat()
                            results['signal_date'] = analysis_date
                            
                            # 2. ë‚ ì§œë³„ íŒŒì¼ ì €ì¥
                            date_str = analysis_date.replace('-', '')
                            filename = f'ai_analysis_results_{date_str}.json'
                            filepath = os.path.join(data_dir, filename)
                            
                            with open(filepath, 'w', encoding='utf-8') as f:
                                json.dump(results, f, ensure_ascii=False, indent=2)
                            logger.info(f"AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
                                
                            # 3. ìµœì‹  ê²°ê³¼ ì—…ë°ì´íŠ¸ (target_dateê°€ ì—†ê±°ë‚˜ ì˜¤ëŠ˜ì¸ ê²½ìš°)
                            # ë˜ëŠ” ì‚¬ìš©ìê°€ ì¡°íšŒí•  ë•Œ í¸ì˜ë¥¼ ìœ„í•´ í•­ìƒ ìµœì‹  íŒŒì¼ë„ ê°±ì‹ í• ì§€?
                            # -> ì¼ë‹¨ target_date ëª¨ë“œì¼ ë•ŒëŠ” ìµœì‹  íŒŒì¼ ê±´ë“œë¦¬ì§€ ì•ŠëŠ” ê²Œ ì•ˆì „ (í˜¼ì„  ë°©ì§€)
                            is_today = analysis_date == datetime.now().strftime('%Y-%m-%d')
                            if not target_date or is_today:
                                 main_path = os.path.join(data_dir, 'ai_analysis_results.json')
                                 with open(main_path, 'w', encoding='utf-8') as f:
                                    json.dump(results, f, ensure_ascii=False, indent=2)
                            
                            update_item_status('AI Analysis', 'done')
                    else:
                        logger.info(f"[{analysis_date}] ì‹œê·¸ë„ ë°ì´í„°ê°€ ì—†ì–´ AI ë¶„ì„ ìƒëµ")
                        update_item_status('AI Analysis', 'done')

                else:
                    update_item_status('AI Analysis', 'done')

            except Exception as e:
                logger.error(f"AI Analysis Failed: {e}")
                update_item_status('AI Analysis', 'error')
                if shared_state.STOP_REQUESTED: raise e

        # 5. AI Jongga V2
        if 'AI Jongga V2' in selected_items:
            if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
            update_item_status('AI Jongga V2', 'running')
            try:
                # ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•´ asyncio run
                # run_screenerëŠ” engine.generatorì— ì •ì˜ë¨
                from engine.generator import run_screener
                
                async def run_async_screener():
                    await run_screener(capital=50000000, target_date=target_date)
                    
                asyncio.run(run_async_screener())
                update_item_status('AI Jongga V2', 'done')
                
                # AI Analysisë„ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ (run_screenerê°€ ë‹¤ í•¨)
                update_item_status('AI Analysis', 'done') 
                
            except Exception as e:
                logger.error(f"AI Jongga V2 Failed: {e}")
                update_item_status('AI Jongga V2', 'error')
                if shared_state.STOP_REQUESTED: raise e

    except Exception as e:
        if str(e) == "Stopped by user" or shared_state.STOP_REQUESTED:
            logger.info(f"Background Update Stopped: {e}")
        else:
            logger.error(f"Background Update Failed: {e}")
        # Stop Requestedë©´ ë¬´ì‹œ, ì•„ë‹ˆë©´ ì—ëŸ¬ ë¡œê¹…
    finally:
        finish_update()


@common_bp.route('/system/update-item-status', methods=['POST'])
def api_update_item_status():
    """ì•„ì´í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    data = request.get_json() or {}
    name = data.get('name')
    status = data.get('status')
    if name and status:
        update_item_status(name, status)
    return jsonify({'status': 'ok'})


@common_bp.route('/system/finish-update', methods=['POST'])
def api_finish_update():
    """ì—…ë°ì´íŠ¸ ì™„ë£Œ"""
    finish_update()
    return jsonify({'status': 'ok'})


@common_bp.route('/system/stop-update', methods=['POST'])
def api_stop_update():
    """ì—…ë°ì´íŠ¸ ì¤‘ë‹¨ ìš”ì²­"""
    stop_update()
    return jsonify({'status': 'stopped'})


@common_bp.route('/system/log-event', methods=['POST'])
def api_log_event():
    """í”„ë¡ íŠ¸ì—”ë“œ ì´ë²¤íŠ¸ ë¡œê¹… (Login, Profile Update ë“±)"""
    try:
        data = request.get_json() or {}
        action = data.get('action', 'FRONTEND_EVENT')
        details = data.get('details', {})
        
        # User ID extraction
        user_email = request.headers.get('X-User-Email')
        session_id = request.headers.get('X-Session-Id')
        user_id = user_email if (user_email and user_email != 'user@example.com') else session_id
        
        from services.activity_logger import activity_logger
        
        # Ensure session_id is in details
        if 'session_id' not in details and session_id:
            details['session_id'] = session_id
            
        activity_logger.log_action(
            user_id=user_id,
            action=action,
            details=details,
            ip_address=request.remote_addr
        )
        return jsonify({'status': 'ok'})
    except Exception as e:
        logger.error(f"Event Log Error: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/portfolio')
def get_portfolio_data():
    """í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° (Fast - Cached)"""
    try:
        # Start sync if not running (Lazy Start)
        paper_trading.start_background_sync()
        
        data = paper_trading.get_portfolio_valuation()
        return jsonify(data)
        
    except Exception as e:
        logger.error(f"Error fetching portfolio: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/portfolio/buy', methods=['POST'])
def buy_stock():
    """ëª¨ì˜ íˆ¬ì ë§¤ìˆ˜"""
    try:
        data = request.get_json()
        ticker = data.get('ticker')
        name = data.get('name')
        price = data.get('price')
        quantity = int(data.get('quantity', 0))
        
        if not all([ticker, name, price, quantity]):
             return jsonify({'status': 'error', 'message': 'Missing data'}), 400
             
        result = paper_trading.buy_stock(ticker, name, float(price), quantity)
        return jsonify(result)
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@common_bp.route('/portfolio/sell', methods=['POST'])
def sell_stock():
    """ëª¨ì˜ íˆ¬ì ë§¤ë„"""
    try:
        data = request.get_json()
        ticker = data.get('ticker')
        price = data.get('price')
        quantity = int(data.get('quantity', 0))
        
        if not all([ticker, price, quantity]):
             return jsonify({'status': 'error', 'message': 'Missing data'}), 400
             
        result = paper_trading.sell_stock(ticker, float(price), quantity)
        return jsonify(result)
    except Exception as e:
         return jsonify({'status': 'error', 'message': str(e)}), 500


@common_bp.route('/portfolio/reset', methods=['POST'])
def reset_portfolio():
    """ëª¨ì˜ íˆ¬ì ì´ˆê¸°í™”"""
    paper_trading.reset_account()
    return jsonify({'status': 'success', 'message': 'Account reset to 100M KRW'})


@common_bp.route('/portfolio/deposit', methods=['POST'])
def deposit_cash():
    """ì˜ˆìˆ˜ê¸ˆ ì¶©ì „"""
    try:
        data = request.get_json()
        amount = int(data.get('amount', 0))
        result = paper_trading.deposit_cash(amount)
        return jsonify(result)
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@common_bp.route('/portfolio/history')
def get_trade_history():
    """ê±°ë˜ ë‚´ì—­ ì¡°íšŒ"""
    try:
        limit = request.args.get('limit', 50, type=int)
        data = paper_trading.get_trade_history(limit)
        return jsonify(data)
    except Exception as e:
        logger.error(f"Error getting trade history: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/portfolio/history/asset')
def get_asset_history():
    """ìì‚° ë³€ë™ ë‚´ì—­ ì¡°íšŒ (ì°¨íŠ¸ìš©)"""
    try:
        limit = request.args.get('limit', 30, type=int)
        data = paper_trading.get_asset_history(limit)
        return jsonify({'history': data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500



@common_bp.route('/stock/<ticker>')
def get_stock_detail(ticker):
    """ê°œë³„ ì¢…ëª© ìƒì„¸ ì •ë³´"""
    try:
        # ìƒ˜í”Œ ì¢…ëª© ìƒì„¸
        stock_names = {
            '005930': 'ì‚¼ì„±ì „ì',
            '000270': 'ê¸°ì•„',
            '035420': 'NAVER',
            '005380': 'í˜„ëŒ€ì°¨'
        }

        name = stock_names.get(ticker, 'ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª©')
        price = random.randint(50000, 150000)
        change = random.randint(-5000, 5000)
        change_pct = (change / price) * 100

        return jsonify({
            'ticker': ticker.zfill(6),
            'name': name,
            'sector': 'ê¸°íƒ€',
            'price': price,
            'change': change,
            'change_pct': change_pct,
            'volume': random.randint(100000, 10000000),
            'market_cap': price * random.randint(100, 1000),
            'pe_ratio': round(random.uniform(5, 25), 2),
            'dividend_yield': round(random.uniform(0, 5), 2)
        })

    except Exception as e:
        logger.error(f"Error getting stock detail: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/realtime-prices', methods=['POST'])
def get_realtime_prices():
    """ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ"""
    try:
        data = request.get_json() or {}
        tickers = data.get('tickers', [])
        market = data.get('market', 'kr')

        if not tickers:
            return jsonify({'prices': {}})

        prices = {}
        for t in tickers:
            prices[str(t).zfill(6)] = random.randint(50000, 150000)

        return jsonify({'prices': prices})

    except Exception as e:
        logger.error(f"Error fetching realtime prices: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/system/data-status')
def get_data_status():
    """ë°ì´í„° íŒŒì¼ ìƒíƒœ ì¡°íšŒ"""
    import json
    
    # Check these data files
    data_files_to_check = [
        {
            'name': 'Daily Prices',
            'path': 'data/daily_prices.csv',
            'link': '/dashboard/kr/closing-bet',
            'menu': 'Closing Bet'
        },
        {
            'name': 'Institutional Trend',
            'path': 'data/all_institutional_trend_data.csv',
            'link': '/dashboard/kr/vcp',
            'menu': 'VCP Signals'
        },
        {
            'name': 'AI Analysis',
            'path': 'data/kr_ai_analysis.json',
            'link': '/dashboard/kr/vcp',
            'menu': 'VCP Signals'
        },
        {
            'name': 'VCP Signals',
            'path': 'data/signals_log.csv',
            'link': '/dashboard/kr/vcp',
            'menu': 'VCP Signals'
        },
        {
            'name': 'AI Jongga V2',
            'path': 'data/jongga_v2_latest.json',
            'link': '/dashboard/kr/closing-bet',
            'menu': 'Closing Bet'
        },
        {
            'name': 'Market Gate',
            'path': 'data/market_gate.json',
            'link': '/dashboard/kr',
            'menu': 'Market Overview'
        }

    ]
    
    files_status = []
    
    for file_info in data_files_to_check:
        path = file_info['path']
        exists = os.path.exists(path)
        
        if exists:
            stat = os.stat(path)
            size_bytes = stat.st_size
            mtime = datetime.fromtimestamp(stat.st_mtime)
            
            # Format size
            if size_bytes > 1024 * 1024:
                size_str = f"{size_bytes / (1024 * 1024):.1f} MB"
            elif size_bytes > 1024:
                size_str = f"{size_bytes / 1024:.1f} KB"
            else:
                size_str = f"{size_bytes} B"
            
            # Count rows if CSV
            row_count = None
            if path.endswith('.csv'):
                try:
                    row_count = sum(1 for _ in open(path)) - 1  # -1 for header
                except:
                    pass
            elif path.endswith('.json'):
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if 'signals' in data:
                        row_count = len(data['signals'])
                    elif isinstance(data, list):
                        row_count = len(data)
                except:
                    pass
            
            files_status.append({
                'name': file_info['name'],
                'path': path,
                'exists': True,
                'lastModified': mtime.isoformat(),
                'size': size_str,
                'rowCount': row_count,
                'link': file_info.get('link', ''),
                'menu': file_info.get('menu', '')
            })
        else:
            files_status.append({
                'name': file_info['name'],
                'path': path,
                'exists': False,
                'lastModified': '',
                'size': '-',
                'rowCount': None,
                'link': file_info.get('link', ''),
                'menu': file_info.get('menu', '')
            })
    
    current_status = load_update_status()
    update_status = {
        'isRunning': current_status['isRunning'],
        'lastRun': current_status['startTime'] or datetime.now().isoformat(),
        'progress': current_status['currentItem'] or ''
    }

    return jsonify({
        'files': files_status,
        'update_status': update_status
    })



@common_bp.route('/kr/backtest-summary')
def get_backtest_summary():
    """VCP ë° Closing Bet(Jongga V2) ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½ ë°˜í™˜"""
    try:
        # ìƒ˜í”Œ ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½
        summary = {
            'vcp': {
                'status': 'OK',
                'win_rate': 62.5,
                'avg_return': 4.2,
                'count': 16
            },
            'closing_bet': {
                'status': 'OK',
                'win_rate': 58.3,
                'avg_return': 3.8,
                'count': 12
            }
        }

        return jsonify(summary)

    except Exception as e:
        logger.error(f"Error getting backtest summary: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/system/env', methods=['GET', 'POST', 'DELETE'])
def manage_env():
    """í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (ì½ê¸° ë° ì“°ê¸°)"""
    env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), '.env')
    
    if request.method == 'GET':
        try:
            if not os.path.exists(env_path):
                return jsonify({})
                
            env_vars = {}
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    if '=' in line:
                        key, value = line.split('=', 1)
                        # [Fix] ë¹ˆ ê°’ì€ ì‘ë‹µì—ì„œ ì œì™¸ (ì“°ë ˆê¸°ê°’ ë°©ì§€)
                        if not value or value.strip() == '':
                            continue
                        # ì¤‘ìš” í‚¤ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ (ì„ íƒ)
                        # [Modified] ì‚¬ìš©ì ìš”ì²­: API Key ì™¸ì—ë„ ì´ë©”ì¼, ID ë“± ê°œì¸ì •ë³´ê°€ í¬í•¨ëœ ëª¨ë“  ì£¼ìš” ì„¤ì •ê°’ ë§ˆìŠ¤í‚¹
                        sensitive_keywords = ['KEY', 'SECRET', 'PASSWORD', 'TOKEN', 'USER', 'ID', 'URL', 'HOST', 'RECIPIENTS']
                        if any(k in key for k in sensitive_keywords):
                            if len(value) > 8:
                                value = value[:4] + '*' * (len(value) - 8) + value[-4:]
                            else:
                                value = '*' * len(value)
                        env_vars[key] = value
            return jsonify(env_vars)
        except Exception as e:
            logger.error(f"Error reading .env: {e}")
            return jsonify({'error': str(e)}), 500
            
    elif request.method == 'POST':
        try:
            data = request.get_json() or {}
            if not data:
                return jsonify({'status': 'ok'})
                
            # ê¸°ì¡´ ë‚´ìš© ì½ê¸°
            lines = []
            if os.path.exists(env_path):
                with open(env_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
            
            # ì—…ë°ì´íŠ¸í•  í‚¤ ì¶”ì 
            updated_keys = set()
            new_lines = []
            
            # 1. ê¸°ì¡´ ë¼ì¸ ìˆ˜ì •
            for line in lines:
                original_line = line
                line_stripped = line.strip()
                if not line_stripped or line_stripped.startswith('#'):
                    new_lines.append(original_line)
                    continue
                    
                if '=' in line_stripped:
                    key = line_stripped.split('=', 1)[0]
                    if key in data:
                        new_value = data[key]
                        # ë§ˆìŠ¤í‚¹ëœ ê°’ì´ ê·¸ëŒ€ë¡œ ë“¤ì–´ì˜¤ë©´ ì—…ë°ì´íŠ¸ ìƒëµ (ë³´ì•ˆ)
                        if '*' in new_value:
                             new_lines.append(original_line)
                             updated_keys.add(key)
                             continue
                        
                        # [Modified] ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ ë¼ì¸ ì‚­ì œ (ì™„ì „ ì‚­ì œ)
                        if not new_value:
                            updated_keys.add(key)
                            # ë©”ëª¨ë¦¬ì—ì„œë„ ì‚­ì œ
                            if key in os.environ:
                                del os.environ[key]
                            continue
                             
                        new_lines.append(f"{key}={new_value}\n")
                        updated_keys.add(key)
                    else:
                        new_lines.append(original_line)
                else:
                    new_lines.append(original_line)
            
            # 2. ìƒˆë¡œìš´ í‚¤ ì¶”ê°€
            for key, value in data.items():
                if key not in updated_keys and '*' not in value:
                    if not value: continue # ë¹ˆ ê°’ì€ ì¶”ê°€ ì•ˆ í•¨
                    
                     # ë§ˆì§€ë§‰ ì¤„ì´ ê°œí–‰ë¬¸ìë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
                    if new_lines and not new_lines[-1].endswith('\n'):
                        new_lines[-1] += '\n'
                    new_lines.append(f"{key}={value}\n")
            
            # íŒŒì¼ ì“°ê¸°
            with open(env_path, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)

            # 3. í™˜ê²½ë³€ìˆ˜ ë©”ëª¨ë¦¬ ì¦‰ì‹œ ë°˜ì˜ (ì¬ì‹œì‘ ì—†ì´ ì ìš©)
            for key, value in data.items():
                if '*' not in value:
                    os.environ[key] = value
                
            return jsonify({'status': 'ok'})
            
        except Exception as e:
            logger.error(f"Error updating .env: {e}")
            return jsonify({'error': str(e)}), 500

    elif request.method == 'DELETE':
        try:
            # ë¯¼ê° ì •ë³´ ì´ˆê¸°í™” (Factory Reset)
            sensitive_keys = [
                'GOOGLE_CLIENT_ID', 'GOOGLE_CLIENT_SECRET', 'GOOGLE_API_KEY',
                'OPENAI_API_KEY', 'ANTHROPIC_API_KEY', 'ZAI_API_KEY', 'PERPLEXITY_API_KEY',
                'TELEGRAM_BOT_TOKEN', 'TELEGRAM_CHAT_ID',
                'DISCORD_WEBHOOK_URL', 'SLACK_WEBHOOK_URL',
                'SMTP_USER', 'SMTP_PASSWORD', 'EMAIL_RECIPIENTS',
                'USER_PROFILE'
            ]
            
            lines = []
            if os.path.exists(env_path):
                with open(env_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
            
            new_lines = []
            for line in lines:
                line_stripped = line.strip()
                if not line_stripped or line_stripped.startswith('#'):
                    new_lines.append(line)
                    continue
                
                if '=' in line_stripped:
                    key = line_stripped.split('=', 1)[0]
                    if key in sensitive_keys:
                        new_lines.append(f"{key}=\n")
                        # ë©”ëª¨ë¦¬ì—ì„œë„ ì‚­ì œ
                        if key in os.environ:
                            os.environ[key] = ""
                    else:
                        new_lines.append(line)
                else:
                    new_lines.append(line)
            
            with open(env_path, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)

            # [New] ëª¨ë“  ì‚¬ìš©ì ë°ì´í„° íŒŒì¼ ì‚­ì œ
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            data_dir = os.path.join(base_dir, 'data')
            
            files_to_delete = [
                'user_quota.json', 
                'chatbot_history.json',
                'chatbot_memory.json',
                'chatbot_sessions.json'
            ]
            
            for fname in files_to_delete:
                path = os.path.join(data_dir, fname)
                if os.path.exists(path):
                    try:
                        os.remove(path)
                        logger.info(f"Factory Reset: Deleted {fname}")
                    except Exception as e:
                        logger.error(f"Failed to delete {fname}: {e}")
                
            return jsonify({'status': 'ok', 'message': 'All sensitive data and user history types wiped.'})
            
        except Exception as e:
            logger.error(f"Error resetting .env: {e}")
            return jsonify({'error': str(e)}), 500


@common_bp.route('/notification/send', methods=['POST'])
def send_test_notification():
    """ì•Œë¦¼ í…ŒìŠ¤íŠ¸ ë°œì†¡"""
    try:
        data = request.get_json() or {}
        platform = data.get('platform') # discord, telegram, email
        
        if not platform:
             return jsonify({'status': 'error', 'message': 'Platform not specified'}), 400
             
        from engine.messenger import Messenger
        messenger = Messenger()
        
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
        test_data = {
            "title": f"[Test] {platform.upper()} Notification",
            "gate_info": "System Status: Online",
            "summary_title": "í…ŒìŠ¤íŠ¸ ë°œì†¡ì…ë‹ˆë‹¤",
            "summary_desc": "ì„¤ì •ëœ ì •ë³´ë¡œ ì•Œë¦¼ì´ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì‹ ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.",
            "signals": [
                {
                    "index": 1,
                    "name": "í…ŒìŠ¤íŠ¸ì¢…ëª©",
                    "code": "005930",
                    "market_icon": "ğŸ”µ",
                    "grade": "A",
                    "score": 85.5,
                    "change_pct": 1.2,
                    "volume_ratio": 2.5,
                    "trading_value": 5000000000,
                    "f_buy": 1000000000,
                    "i_buy": 500000000,
                    "entry": 70000,
                    "target": 75000, 
                    "stop": 68000,
                    "ai_reason": "AI ë¶„ì„ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì •ìƒ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤."
                }
            ]
        }
        
        # ê°•ì œ ë°œì†¡ (Messenger ë‚´ë¶€ ì±„ë„ ë¦¬ìŠ¤íŠ¸ ë¬´ì‹œí•˜ê³  ê°œë³„ ë©”ì†Œë“œ í˜¸ì¶œ ì‹œë„ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì˜ì¡´)
        # Messenger í´ë˜ìŠ¤ëŠ” ì´ˆê¸°í™” ì‹œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì½ìœ¼ë¯€ë¡œ, ì§€ê¸ˆ í™˜ê²½ë³€ìˆ˜ê°€ ì˜ ì„¤ì •ë˜ì—ˆë‹¤ë©´ ë™ì‘í•¨.
        
        if platform == 'discord':
            if not messenger.discord_url:
                return jsonify({'status': 'error', 'message': 'Discord Webhook URL not set in server env'}), 400
            messenger._send_discord(test_data)
            
        elif platform == 'telegram':
            if not messenger.telegram_token or not messenger.telegram_chat_id:
                return jsonify({'status': 'error', 'message': 'Telegram Token or Chat ID not set'}), 400
            messenger._send_telegram(test_data)
            
        elif platform == 'email':
             if not messenger.smtp_user:
                return jsonify({'status': 'error', 'message': 'SMTP settings not configured'}), 400
             messenger._send_email(test_data)
             
        else:
            return jsonify({'status': 'error', 'message': f'Unknown platform: {platform}'}), 400
            
        return jsonify({'status': 'success', 'message': f'{platform} test message sent'})

    except Exception as e:
        logger.error(f"Test notification failed: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500
