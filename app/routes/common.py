#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³µí†µ API ë¼ìš°íŠ¸
"""
from flask import Blueprint, jsonify, request
import pandas as pd
import os
import logging
import logging
import random
import threading
import sys
from datetime import datetime
from threading import Lock, Thread
import traceback
import re

# Add scripts directory to path for importing init_data
scripts_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), 'scripts')
if scripts_dir not in sys.path:
    sys.path.append(scripts_dir)

logger = logging.getLogger(__name__)

common_bp = Blueprint('common', __name__)


# ====== ADMIN ê¶Œí•œ í™•ì¸ API ======
@common_bp.route('/admin/check')
def check_admin():
    """
    ADMIN ê¶Œí•œ í™•ì¸ API
    - ì´ë©”ì¼ì´ ADMIN_EMAILS í™˜ê²½ë³€ìˆ˜ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    - í”„ë¡ íŠ¸ì—”ë“œì˜ useAdmin í›…ì—ì„œ í˜¸ì¶œ
    """
    email = request.args.get('email', '').strip().lower()
    
    if not email:
        return jsonify({'isAdmin': False, 'error': 'Email required'}), 400

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ADMIN ì´ë©”ì¼ ëª©ë¡ ë¡œë“œ
    admin_emails_str = os.environ.get('ADMIN_EMAILS', '')
    admin_emails = [e.strip().lower() for e in admin_emails_str.split(',') if e.strip()]
    
    is_admin = email in admin_emails
    
    logger.debug(f"Admin check: {email} -> {is_admin}")
    
    return jsonify({'isAdmin': is_admin})


try:
    import engine.shared as shared_state
except ImportError:
    # Fallback if engine package not found in path
    import sys, os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    import sys, os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    import engine.shared as shared_state

from services.paper_trading import paper_trading

# ê¸€ë¡œë²Œ ì—…ë°ì´íŠ¸ ìƒíƒœ ì¶”ì  (ë©”ëª¨ë¦¬)
update_tracker = {
    'isRunning': False,
    'startTime': None,
    'currentItem': None,
    'items': [],  # [{'name': 'Daily Prices', 'status': 'pending|running|done|error'}]
}
update_lock = Lock()


def start_update(items_list):
    """ì—…ë°ì´íŠ¸ ì‹œì‘"""
    with update_lock:
        shared_state.STOP_REQUESTED = False
        update_tracker['isRunning'] = True
        update_tracker['startTime'] = datetime.now().isoformat()
        update_tracker['items'] = [{'name': name, 'status': 'pending'} for name in items_list]
        update_tracker['currentItem'] = None


def update_item_status(name, status):
    """ì•„ì´í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    with update_lock:
        for item in update_tracker['items']:
            if item['name'] == name:
                item['status'] = status
                if status == 'running':
                    update_tracker['currentItem'] = name
                break


def stop_update():
    """ì—…ë°ì´íŠ¸ ì¤‘ë‹¨"""
    with update_lock:
        shared_state.STOP_REQUESTED = True
        update_tracker['isRunning'] = False
        update_tracker['currentItem'] = None
        # ì¤‘ë‹¨ ì‹œì—ë„ ê¸°ì¡´ ìƒíƒœ ìœ ì§€ ë˜ëŠ” ì´ˆê¸°í™”? 
        # UIì—ì„œ 'Stopped' ìƒíƒœë¥¼ ì²˜ë¦¬í•˜ë ¤ë©´ ë‚¨ê²¨ë‘ëŠ” ê²Œ ì¢‹ì§€ë§Œ, 
        # ì—¬ê¸°ì„œëŠ” update_tracker['items']ë¥¼ ë¹„ìš°ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë‘ì–´ ì—ëŸ¬ í‘œì‹œ ë“±ì´ ê°€ëŠ¥í•˜ê²Œ í•¨.
        # ë‹¤ë§Œ ì¬ì‹œì‘ ì‹œ start_updateì—ì„œ ì´ˆê¸°í™”ë¨.
        
        # ëª…ì‹œì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì¸ í•­ëª©ì„ error/stoppedë¡œ ë³€ê²½
        for item in update_tracker['items']:
            if item['status'] == 'running':
                item['status'] = 'error' # ì¤‘ë‹¨ë¨


def finish_update():
    """ì—…ë°ì´íŠ¸ ì™„ë£Œ"""
    with update_lock:
        update_tracker['isRunning'] = False
        update_tracker['currentItem'] = None
        # ì™„ë£Œ ì‹œ itemsë¥¼ ë¹„ì›Œì„œ ì˜¤ë˜ëœ ì—ëŸ¬ ìƒíƒœê°€ ë‚¨ì§€ ì•Šë„ë¡ í•¨
        update_tracker['items'] = []


@common_bp.route('/system/update-status')
def get_update_status():
    """ì—…ë°ì´íŠ¸ ìƒíƒœë§Œ ì¡°íšŒ (ê°€ë²¼ìš´ í´ë§ìš©)"""
    with update_lock:
        return jsonify({
            'isRunning': update_tracker['isRunning'],
            'startTime': update_tracker['startTime'],
            'currentItem': update_tracker['currentItem'],
            'items': update_tracker['items'].copy()
        })


@common_bp.route('/system/start-update', methods=['POST'])
def api_start_update():
    """ì—…ë°ì´íŠ¸ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)"""
    data = request.get_json() or {}
    items_list = data.get('items', [])
    target_date = data.get('target_date') # YYYY-MM-DD or None
    
    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ê±°ë¶€
    if update_tracker['isRunning']:
        return jsonify({'status': 'error', 'message': 'Already running'}), 400

    # UI ìƒíƒœ ì´ˆê¸°í™”
    start_update(items_list)
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹¤í–‰
    thread = Thread(target=run_background_update, args=(target_date,))
    thread.daemon = True
    thread.start()
    
    return jsonify({'status': 'ok'})


def run_background_update(target_date):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
    import asyncio
    
    try:
        from scripts import init_data

        # 1. Daily Prices
        if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
        update_item_status('Daily Prices', 'running')
        try:
            init_data.create_daily_prices(target_date)
            update_item_status('Daily Prices', 'done')
        except Exception as e:
            logger.error(f"Daily Prices Failed: {e}")
            update_item_status('Daily Prices', 'error')
            if shared_state.STOP_REQUESTED: raise e # ì¤‘ë‹¨ ìš”ì²­ì´ë©´ ì „ì²´ ì¤‘ë‹¨
            
        # 2. Institutional Trend
        if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
        update_item_status('Institutional Trend', 'running')
        try:
            init_data.create_institutional_trend(target_date)
            update_item_status('Institutional Trend', 'done')
        except Exception as e:
            logger.error(f"Institutional Trend Failed: {e}")
            update_item_status('Institutional Trend', 'error')
            if shared_state.STOP_REQUESTED: raise e

        # 2.5 Market Gate Analysis
        if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
        update_item_status('Market Gate', 'running')
        try:
            from engine.market_gate import MarketGate
            mg = MarketGate()
            result = mg.analyze(target_date)
            mg.save_analysis(result, target_date)
            update_item_status('Market Gate', 'done')
        except Exception as e:
            logger.error(f"Market Gate Failed: {e}")
            update_item_status('Market Gate', 'error')
            if shared_state.STOP_REQUESTED: raise e

        # 3. VCP Signals
        if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
        update_item_status('VCP Signals', 'running')
        vcp_df = None
        try:
            # VCPëŠ” ìŠ¤í¬ë¦½íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ ëŒ€ì‹  ê¸°ì¡´ ë¡œì§ í™œìš© (init_data.create_signals_logëŠ” ìƒ˜í”Œìš©ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜)
            # init_data.create_signals_log() ëŒ€ì‹  kr_market.run_vcp_signals_screener ë¡œì§ì„ ì‚¬ìš©í•´ì•¼ í•¨.
            # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ init_data.create_signals_log() ì‚¬ìš© (ê¸°ì¡´ init-data APIë„ ê·¸ë¬ìŒ)
            vcp_df = init_data.create_signals_log(target_date)
            update_item_status('VCP Signals', 'done')
        except Exception as e:
            logger.error(f"VCP Signals Failed: {e}")
            update_item_status('VCP Signals', 'error')
            if shared_state.STOP_REQUESTED: raise e

        # 4. AI Analysis
        if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
        update_item_status('AI Analysis', 'running')
        try:
            from engine.kr_ai_analyzer import KrAiAnalyzer
            import pandas as pd
            import json
            
            # ê²½ë¡œ ì„¤ì •
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            data_dir = os.path.join(base_dir, 'data')
            signals_path = os.path.join(data_dir, 'signals_log.csv')
            
            if os.path.exists(signals_path):
                # ìš°ì„  ë©”ëª¨ë¦¬ì— ìˆëŠ” vcp_df ì‚¬ìš© (ì‹¤ì‹œê°„ì„± ë³´ì¥)
                target_df = pd.DataFrame()
                analysis_date = target_date if target_date else datetime.now().strftime('%Y-%m-%d')
                
                if vcp_df is not None and hasattr(vcp_df, 'empty') and not vcp_df.empty:
                    logger.info("VCP ê²°ê³¼ ë©”ëª¨ë¦¬ì—ì„œ ë¡œë“œ")
                    target_df = vcp_df.copy()
                    if 'signal_date' in target_df.columns:
                        analysis_date = str(target_df['signal_date'].iloc[0])
                else:
                    logger.info("VCP ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„")
                    df = pd.read_csv(signals_path)
                    if not df.empty and 'signal_date' in df.columns:
                        # ë¶„ì„ ë‚ ì§œ ê²°ì •
                        if not target_date:
                            analysis_date = str(df['signal_date'].max())
                            
                        # í•´ë‹¹ ë‚ ì§œ ë°ì´í„° í•„í„°ë§
                        target_df = df[df['signal_date'].astype(str) == analysis_date].copy()
                
                if not target_df.empty:
                        # í‹°ì»¤ ì •ê·œí™” ë° ì¤‘ë³µ ì œê±° (ë¶„ì„ ëŒ€ìƒ í™•ë³´)
                        target_df['ticker'] = target_df['ticker'].astype(str).str.zfill(6)
                        target_df = target_df.drop_duplicates(subset=['ticker'])
                        
                        # Score ìˆ«ìí˜• ë³€í™˜ (ì •ë ¬ ì˜¤ë¥˜ ë°©ì§€)
                        if 'score' in target_df.columns:
                            target_df['score'] = pd.to_numeric(target_df['score'], errors='coerce').fillna(0)
                        
                        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 20ê°œ ë¶„ì„ (ì‚¬ìš©ì ìš”ì²­: ì „ì²´/ë‹¤ìˆ˜ ë¶„ì„)
                        target_df = target_df.sort_values('score', ascending=False).head(20)
                        tickers = target_df['ticker'].tolist()
                        
                        # [ì‚¬ìš©ì ìš”ì²­] ì¬ë¶„ì„ ì‹œ í•´ë‹¹ ë‚ ì§œì˜ ê¸°ì¡´ AI ê²°ê³¼ íŒŒì¼ ì‚­ì œ (ì°Œêº¼ê¸° ë°ì´í„° ë°©ì§€)
                        date_str_clean = analysis_date.replace('-', '')
                        target_filename = f'ai_analysis_results_{date_str_clean}.json'
                        target_filepath = os.path.join(data_dir, target_filename)
                        
                        if os.path.exists(target_filepath):
                            try:
                                os.remove(target_filepath)
                                logger.info(f"ê¸°ì¡´ AI ë¶„ì„ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {target_filename}")
                            except Exception as del_err:
                                logger.warning(f"ê¸°ì¡´ AI íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {del_err}")

                        logger.info(f"AI ë¶„ì„ ì‹œì‘: {len(tickers)} ì¢…ëª© ({analysis_date})")
                        
                        analyzer = KrAiAnalyzer()
                        # ë¶„ì„ ì‹¤í–‰
                        results = analyzer.analyze_multiple_stocks(tickers)
                        
                        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                        results['generated_at'] = datetime.now().isoformat()
                        results['signal_date'] = analysis_date
                        
                        # 2. ë‚ ì§œë³„ íŒŒì¼ ì €ì¥
                        date_str = analysis_date.replace('-', '')
                        filename = f'ai_analysis_results_{date_str}.json'
                        filepath = os.path.join(data_dir, filename)
                        
                        with open(filepath, 'w', encoding='utf-8') as f:
                            json.dump(results, f, ensure_ascii=False, indent=2)
                        logger.info(f"AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
                            
                        # 3. ìµœì‹  ê²°ê³¼ ì—…ë°ì´íŠ¸ (target_dateê°€ ì—†ê±°ë‚˜ ì˜¤ëŠ˜ì¸ ê²½ìš°)
                        # ë˜ëŠ” ì‚¬ìš©ìê°€ ì¡°íšŒí•  ë•Œ í¸ì˜ë¥¼ ìœ„í•´ í•­ìƒ ìµœì‹  íŒŒì¼ë„ ê°±ì‹ í• ì§€?
                        # -> ì¼ë‹¨ target_date ëª¨ë“œì¼ ë•ŒëŠ” ìµœì‹  íŒŒì¼ ê±´ë“œë¦¬ì§€ ì•ŠëŠ” ê²Œ ì•ˆì „ (í˜¼ì„  ë°©ì§€)
                        is_today = analysis_date == datetime.now().strftime('%Y-%m-%d')
                        if not target_date or is_today:
                             main_path = os.path.join(data_dir, 'ai_analysis_results.json')
                             with open(main_path, 'w', encoding='utf-8') as f:
                                json.dump(results, f, ensure_ascii=False, indent=2)
                        
                        update_item_status('AI Analysis', 'done')
                else:
                    logger.info(f"[{analysis_date}] ì‹œê·¸ë„ ë°ì´í„°ê°€ ì—†ì–´ AI ë¶„ì„ ìƒëµ")
                    update_item_status('AI Analysis', 'done')

            else:
                update_item_status('AI Analysis', 'done')

        except Exception as e:
            logger.error(f"AI Analysis Failed: {e}")
            update_item_status('AI Analysis', 'error')
            if shared_state.STOP_REQUESTED: raise e

        # 5. AI Jongga V2
        if shared_state.STOP_REQUESTED: raise Exception("Stopped by user")
        update_item_status('AI Jongga V2', 'running')
        try:
            # ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•´ asyncio run
            # run_screenerëŠ” engine.generatorì— ì •ì˜ë¨
            from engine.generator import run_screener
            
            async def run_async_screener():
                await run_screener(capital=50000000, target_date=target_date)
                
            asyncio.run(run_async_screener())
            update_item_status('AI Jongga V2', 'done')
            
            # AI Analysisë„ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ (run_screenerê°€ ë‹¤ í•¨)
            update_item_status('AI Analysis', 'done') 
            
        except Exception as e:
            logger.error(f"AI Jongga V2 Failed: {e}")
            update_item_status('AI Jongga V2', 'error')
            if shared_state.STOP_REQUESTED: raise e

    except Exception as e:
        logger.error(f"Background Update Failed: {e}")
        # Stop Requestedë©´ ë¬´ì‹œ, ì•„ë‹ˆë©´ ì—ëŸ¬ ë¡œê¹…
    finally:
        finish_update()


@common_bp.route('/system/update-item-status', methods=['POST'])
def api_update_item_status():
    """ì•„ì´í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    data = request.get_json() or {}
    name = data.get('name')
    status = data.get('status')
    if name and status:
        update_item_status(name, status)
    return jsonify({'status': 'ok'})


@common_bp.route('/system/finish-update', methods=['POST'])
def api_finish_update():
    """ì—…ë°ì´íŠ¸ ì™„ë£Œ"""
    finish_update()
    return jsonify({'status': 'ok'})


@common_bp.route('/system/stop-update', methods=['POST'])
def api_stop_update():
    """ì—…ë°ì´íŠ¸ ì¤‘ë‹¨ ìš”ì²­"""
    stop_update()
    return jsonify({'status': 'stopped'})


@common_bp.route('/portfolio')
def get_portfolio_data():
    """í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° (Fast - Cached)"""
    try:
        # Start sync if not running (Lazy Start)
        paper_trading.start_background_sync()
        
        data = paper_trading.get_portfolio_valuation()
        return jsonify(data)
        
    except Exception as e:
        logger.error(f"Error fetching portfolio: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/portfolio/buy', methods=['POST'])
def buy_stock():
    """ëª¨ì˜ íˆ¬ì ë§¤ìˆ˜"""
    try:
        data = request.get_json()
        ticker = data.get('ticker')
        name = data.get('name')
        price = data.get('price')
        quantity = int(data.get('quantity', 0))
        
        if not all([ticker, name, price, quantity]):
             return jsonify({'status': 'error', 'message': 'Missing data'}), 400
             
        result = paper_trading.buy_stock(ticker, name, float(price), quantity)
        return jsonify(result)
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@common_bp.route('/portfolio/sell', methods=['POST'])
def sell_stock():
    """ëª¨ì˜ íˆ¬ì ë§¤ë„"""
    try:
        data = request.get_json()
        ticker = data.get('ticker')
        price = data.get('price')
        quantity = int(data.get('quantity', 0))
        
        if not all([ticker, price, quantity]):
             return jsonify({'status': 'error', 'message': 'Missing data'}), 400
             
        result = paper_trading.sell_stock(ticker, float(price), quantity)
        return jsonify(result)
    except Exception as e:
         return jsonify({'status': 'error', 'message': str(e)}), 500


@common_bp.route('/portfolio/reset', methods=['POST'])
def reset_portfolio():
    """ëª¨ì˜ íˆ¬ì ì´ˆê¸°í™”"""
    paper_trading.reset_account()
    return jsonify({'status': 'success', 'message': 'Account reset to 100M KRW'})


@common_bp.route('/portfolio/deposit', methods=['POST'])
def deposit_cash():
    """ì˜ˆìˆ˜ê¸ˆ ì¶©ì „"""
    try:
        data = request.get_json()
        amount = int(data.get('amount', 0))
        result = paper_trading.deposit_cash(amount)
        return jsonify(result)
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@common_bp.route('/portfolio/history')
def get_trade_history():
    """ê±°ë˜ ë‚´ì—­ ì¡°íšŒ"""
    try:
        limit = request.args.get('limit', 50, type=int)
        data = paper_trading.get_trade_history(limit)
        return jsonify(data)
    except Exception as e:
        logger.error(f"Error getting trade history: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/portfolio/history/asset')
def get_asset_history():
    """ìì‚° ë³€ë™ ë‚´ì—­ ì¡°íšŒ (ì°¨íŠ¸ìš©)"""
    try:
        limit = request.args.get('limit', 30, type=int)
        data = paper_trading.get_asset_history(limit)
        return jsonify({'history': data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500



@common_bp.route('/stock/<ticker>')
def get_stock_detail(ticker):
    """ê°œë³„ ì¢…ëª© ìƒì„¸ ì •ë³´"""
    try:
        # ìƒ˜í”Œ ì¢…ëª© ìƒì„¸
        stock_names = {
            '005930': 'ì‚¼ì„±ì „ì',
            '000270': 'ê¸°ì•„',
            '035420': 'NAVER',
            '005380': 'í˜„ëŒ€ì°¨'
        }

        name = stock_names.get(ticker, 'ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª©')
        price = random.randint(50000, 150000)
        change = random.randint(-5000, 5000)
        change_pct = (change / price) * 100

        return jsonify({
            'ticker': ticker.zfill(6),
            'name': name,
            'sector': 'ê¸°íƒ€',
            'price': price,
            'change': change,
            'change_pct': change_pct,
            'volume': random.randint(100000, 10000000),
            'market_cap': price * random.randint(100, 1000),
            'pe_ratio': round(random.uniform(5, 25), 2),
            'dividend_yield': round(random.uniform(0, 5), 2)
        })

    except Exception as e:
        logger.error(f"Error getting stock detail: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/realtime-prices', methods=['POST'])
def get_realtime_prices():
    """ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ"""
    try:
        data = request.get_json() or {}
        tickers = data.get('tickers', [])
        market = data.get('market', 'kr')

        if not tickers:
            return jsonify({'prices': {}})

        prices = {}
        for t in tickers:
            prices[str(t).zfill(6)] = random.randint(50000, 150000)

        return jsonify({'prices': prices})

    except Exception as e:
        logger.error(f"Error fetching realtime prices: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/system/data-status')
def get_data_status():
    """ë°ì´í„° íŒŒì¼ ìƒíƒœ ì¡°íšŒ"""
    import json
    
    # Check these data files
    data_files_to_check = [
        {
            'name': 'Daily Prices',
            'path': 'data/daily_prices.csv',
            'link': '/dashboard/kr/closing-bet',
            'menu': 'Closing Bet'
        },
        {
            'name': 'Institutional Trend',
            'path': 'data/all_institutional_trend_data.csv',
            'link': '/dashboard/kr/vcp',
            'menu': 'VCP Signals'
        },
        {
            'name': 'AI Analysis',
            'path': 'data/kr_ai_analysis.json',
            'link': '/dashboard/kr/vcp',
            'menu': 'VCP Signals'
        },
        {
            'name': 'VCP Signals',
            'path': 'data/signals_log.csv',
            'link': '/dashboard/kr/vcp',
            'menu': 'VCP Signals'
        },
        {
            'name': 'AI Jongga V2',
            'path': 'data/jongga_v2_latest.json',
            'link': '/dashboard/kr/closing-bet',
            'menu': 'Closing Bet'
        },
        {
            'name': 'Market Gate',
            'path': 'data/market_gate.json',
            'link': '/dashboard/kr',
            'menu': 'Market Overview'
        }

    ]
    
    files_status = []
    
    for file_info in data_files_to_check:
        path = file_info['path']
        exists = os.path.exists(path)
        
        if exists:
            stat = os.stat(path)
            size_bytes = stat.st_size
            mtime = datetime.fromtimestamp(stat.st_mtime)
            
            # Format size
            if size_bytes > 1024 * 1024:
                size_str = f"{size_bytes / (1024 * 1024):.1f} MB"
            elif size_bytes > 1024:
                size_str = f"{size_bytes / 1024:.1f} KB"
            else:
                size_str = f"{size_bytes} B"
            
            # Count rows if CSV
            row_count = None
            if path.endswith('.csv'):
                try:
                    row_count = sum(1 for _ in open(path)) - 1  # -1 for header
                except:
                    pass
            elif path.endswith('.json'):
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if 'signals' in data:
                        row_count = len(data['signals'])
                    elif isinstance(data, list):
                        row_count = len(data)
                except:
                    pass
            
            files_status.append({
                'name': file_info['name'],
                'path': path,
                'exists': True,
                'lastModified': mtime.isoformat(),
                'size': size_str,
                'rowCount': row_count,
                'link': file_info.get('link', ''),
                'menu': file_info.get('menu', '')
            })
        else:
            files_status.append({
                'name': file_info['name'],
                'path': path,
                'exists': False,
                'lastModified': '',
                'size': '-',
                'rowCount': None,
                'link': file_info.get('link', ''),
                'menu': file_info.get('menu', '')
            })
    
    update_status = {
        'isRunning': False,
        'lastRun': datetime.now().isoformat(),
        'progress': ''
    }

    return jsonify({
        'files': files_status,
        'update_status': update_status
    })



@common_bp.route('/kr/backtest-summary')
def get_backtest_summary():
    """VCP ë° Closing Bet(Jongga V2) ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½ ë°˜í™˜"""
    try:
        # ìƒ˜í”Œ ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½
        summary = {
            'vcp': {
                'status': 'OK',
                'win_rate': 62.5,
                'avg_return': 4.2,
                'count': 16
            },
            'closing_bet': {
                'status': 'OK',
                'win_rate': 58.3,
                'avg_return': 3.8,
                'count': 12
            }
        }

        return jsonify(summary)

    except Exception as e:
        logger.error(f"Error getting backtest summary: {e}")
        return jsonify({'error': str(e)}), 500


@common_bp.route('/system/env', methods=['GET', 'POST', 'DELETE'])
def manage_env():
    """í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (ì½ê¸° ë° ì“°ê¸°)"""
    env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), '.env')
    
    if request.method == 'GET':
        try:
            if not os.path.exists(env_path):
                return jsonify({})
                
            env_vars = {}
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    if '=' in line:
                        key, value = line.split('=', 1)
                        # [Fix] ë¹ˆ ê°’ì€ ì‘ë‹µì—ì„œ ì œì™¸ (ì“°ë ˆê¸°ê°’ ë°©ì§€)
                        if not value or value.strip() == '':
                            continue
                        # ì¤‘ìš” í‚¤ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ (ì„ íƒ)
                        # [Modified] ì‚¬ìš©ì ìš”ì²­: API Key ì™¸ì—ë„ ì´ë©”ì¼, ID ë“± ê°œì¸ì •ë³´ê°€ í¬í•¨ëœ ëª¨ë“  ì£¼ìš” ì„¤ì •ê°’ ë§ˆìŠ¤í‚¹
                        sensitive_keywords = ['KEY', 'SECRET', 'PASSWORD', 'TOKEN', 'USER', 'ID', 'URL', 'HOST', 'RECIPIENTS']
                        if any(k in key for k in sensitive_keywords):
                            if len(value) > 8:
                                value = value[:4] + '*' * (len(value) - 8) + value[-4:]
                            else:
                                value = '*' * len(value)
                        env_vars[key] = value
            return jsonify(env_vars)
        except Exception as e:
            logger.error(f"Error reading .env: {e}")
            return jsonify({'error': str(e)}), 500
            
    elif request.method == 'POST':
        try:
            data = request.get_json() or {}
            if not data:
                return jsonify({'status': 'ok'})
                
            # ê¸°ì¡´ ë‚´ìš© ì½ê¸°
            lines = []
            if os.path.exists(env_path):
                with open(env_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
            
            # ì—…ë°ì´íŠ¸í•  í‚¤ ì¶”ì 
            updated_keys = set()
            new_lines = []
            
            # 1. ê¸°ì¡´ ë¼ì¸ ìˆ˜ì •
            for line in lines:
                original_line = line
                line_stripped = line.strip()
                if not line_stripped or line_stripped.startswith('#'):
                    new_lines.append(original_line)
                    continue
                    
                if '=' in line_stripped:
                    key = line_stripped.split('=', 1)[0]
                    if key in data:
                        new_value = data[key]
                        # ë§ˆìŠ¤í‚¹ëœ ê°’ì´ ê·¸ëŒ€ë¡œ ë“¤ì–´ì˜¤ë©´ ì—…ë°ì´íŠ¸ ìƒëµ (ë³´ì•ˆ)
                        if '*' in new_value:
                             new_lines.append(original_line)
                             updated_keys.add(key)
                             continue
                        
                        # [Modified] ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ ë¼ì¸ ì‚­ì œ (ì™„ì „ ì‚­ì œ)
                        if not new_value:
                            updated_keys.add(key)
                            # ë©”ëª¨ë¦¬ì—ì„œë„ ì‚­ì œ
                            if key in os.environ:
                                del os.environ[key]
                            continue
                             
                        new_lines.append(f"{key}={new_value}\n")
                        updated_keys.add(key)
                    else:
                        new_lines.append(original_line)
                else:
                    new_lines.append(original_line)
            
            # 2. ìƒˆë¡œìš´ í‚¤ ì¶”ê°€
            for key, value in data.items():
                if key not in updated_keys and '*' not in value:
                    if not value: continue # ë¹ˆ ê°’ì€ ì¶”ê°€ ì•ˆ í•¨
                    
                     # ë§ˆì§€ë§‰ ì¤„ì´ ê°œí–‰ë¬¸ìë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
                    if new_lines and not new_lines[-1].endswith('\n'):
                        new_lines[-1] += '\n'
                    new_lines.append(f"{key}={value}\n")
            
            # íŒŒì¼ ì“°ê¸°
            with open(env_path, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)

            # 3. í™˜ê²½ë³€ìˆ˜ ë©”ëª¨ë¦¬ ì¦‰ì‹œ ë°˜ì˜ (ì¬ì‹œì‘ ì—†ì´ ì ìš©)
            for key, value in data.items():
                if '*' not in value:
                    os.environ[key] = value
                
            return jsonify({'status': 'ok'})
            
        except Exception as e:
            logger.error(f"Error updating .env: {e}")
            return jsonify({'error': str(e)}), 500

    elif request.method == 'DELETE':
        try:
            # ë¯¼ê° ì •ë³´ ì´ˆê¸°í™” (Factory Reset)
            sensitive_keys = [
                'GOOGLE_CLIENT_ID', 'GOOGLE_CLIENT_SECRET', 'GOOGLE_API_KEY',
                'OPENAI_API_KEY', 'ANTHROPIC_API_KEY', 'ZAI_API_KEY', 'PERPLEXITY_API_KEY',
                'TELEGRAM_BOT_TOKEN', 'TELEGRAM_CHAT_ID',
                'DISCORD_WEBHOOK_URL', 'SLACK_WEBHOOK_URL',
                'SMTP_USER', 'SMTP_PASSWORD', 'EMAIL_RECIPIENTS',
                'USER_PROFILE'
            ]
            
            lines = []
            if os.path.exists(env_path):
                with open(env_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
            
            new_lines = []
            for line in lines:
                line_stripped = line.strip()
                if not line_stripped or line_stripped.startswith('#'):
                    new_lines.append(line)
                    continue
                
                if '=' in line_stripped:
                    key = line_stripped.split('=', 1)[0]
                    if key in sensitive_keys:
                        new_lines.append(f"{key}=\n")
                        # ë©”ëª¨ë¦¬ì—ì„œë„ ì‚­ì œ
                        if key in os.environ:
                            os.environ[key] = ""
                    else:
                        new_lines.append(line)
                else:
                    new_lines.append(line)
            
            with open(env_path, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)

            # [New] ëª¨ë“  ì‚¬ìš©ì ë°ì´í„° íŒŒì¼ ì‚­ì œ
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            data_dir = os.path.join(base_dir, 'data')
            
            files_to_delete = [
                'user_quota.json', 
                'chatbot_history.json',
                'chatbot_memory.json',
                'chatbot_sessions.json'
            ]
            
            for fname in files_to_delete:
                path = os.path.join(data_dir, fname)
                if os.path.exists(path):
                    try:
                        os.remove(path)
                        logger.info(f"Factory Reset: Deleted {fname}")
                    except Exception as e:
                        logger.error(f"Failed to delete {fname}: {e}")
                
            return jsonify({'status': 'ok', 'message': 'All sensitive data and user history types wiped.'})
            
        except Exception as e:
            logger.error(f"Error resetting .env: {e}")
            return jsonify({'error': str(e)}), 500


@common_bp.route('/notification/send', methods=['POST'])
def send_test_notification():
    """ì•Œë¦¼ í…ŒìŠ¤íŠ¸ ë°œì†¡"""
    try:
        data = request.get_json() or {}
        platform = data.get('platform') # discord, telegram, email
        
        if not platform:
             return jsonify({'status': 'error', 'message': 'Platform not specified'}), 400
             
        from engine.messenger import Messenger
        messenger = Messenger()
        
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°
        test_data = {
            "title": f"[Test] {platform.upper()} Notification",
            "gate_info": "System Status: Online",
            "summary_title": "í…ŒìŠ¤íŠ¸ ë°œì†¡ì…ë‹ˆë‹¤",
            "summary_desc": "ì„¤ì •ëœ ì •ë³´ë¡œ ì•Œë¦¼ì´ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì‹ ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.",
            "signals": [
                {
                    "index": 1,
                    "name": "í…ŒìŠ¤íŠ¸ì¢…ëª©",
                    "code": "005930",
                    "market_icon": "ğŸ”µ",
                    "grade": "A",
                    "score": 85.5,
                    "change_pct": 1.2,
                    "volume_ratio": 2.5,
                    "trading_value": 5000000000,
                    "f_buy": 1000000000,
                    "i_buy": 500000000,
                    "entry": 70000,
                    "target": 75000, 
                    "stop": 68000,
                    "ai_reason": "AI ë¶„ì„ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì •ìƒ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤."
                }
            ]
        }
        
        # ê°•ì œ ë°œì†¡ (Messenger ë‚´ë¶€ ì±„ë„ ë¦¬ìŠ¤íŠ¸ ë¬´ì‹œí•˜ê³  ê°œë³„ ë©”ì†Œë“œ í˜¸ì¶œ ì‹œë„ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì˜ì¡´)
        # Messenger í´ë˜ìŠ¤ëŠ” ì´ˆê¸°í™” ì‹œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì½ìœ¼ë¯€ë¡œ, ì§€ê¸ˆ í™˜ê²½ë³€ìˆ˜ê°€ ì˜ ì„¤ì •ë˜ì—ˆë‹¤ë©´ ë™ì‘í•¨.
        
        if platform == 'discord':
            if not messenger.discord_url:
                return jsonify({'status': 'error', 'message': 'Discord Webhook URL not set in server env'}), 400
            messenger._send_discord(test_data)
            
        elif platform == 'telegram':
            if not messenger.telegram_token or not messenger.telegram_chat_id:
                return jsonify({'status': 'error', 'message': 'Telegram Token or Chat ID not set'}), 400
            messenger._send_telegram(test_data)
            
        elif platform == 'email':
             if not messenger.smtp_user:
                return jsonify({'status': 'error', 'message': 'SMTP settings not configured'}), 400
             messenger._send_email(test_data)
             
        else:
            return jsonify({'status': 'error', 'message': f'Unknown platform: {platform}'}), 400
            
        return jsonify({'status': 'success', 'message': f'{platform} test message sent'})

    except Exception as e:
        logger.error(f"Test notification failed: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500
