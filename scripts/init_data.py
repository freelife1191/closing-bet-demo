#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„° ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸ (Data Initialization Script)
- ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ (yfinance)
- í•„ìš”í•œ ë°ì´í„° íŒŒì¼ ìƒì„±
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì§„í–‰ë¥  í‘œì‹œ ê°œì„ 
"""

import os
import sys
import pandas as pd
import numpy as np
import json
import socket
import time
import random
import logging
from datetime import datetime, timedelta

# [FIX] Filter out pykrx's broken logging calls
class PykrxFilter(logging.Filter):
    def filter(self, record):
        # pykrx.website.comm.util calls logging.info(args, kwargs) which causes TypeError
        if 'pykrx' in record.pathname and 'util.py' in record.pathname:
            return False
        return True

# Apply filter to root logger (Logger.filter runs before handlers/formatting)
logging.getLogger().addFilter(PykrxFilter())
# If no handlers yet (basicConfig not called), we might need to add it later or rely on basicConfig


# ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ) - ë¬´í•œ ëŒ€ê¸° ë°©ì§€
socket.setdefaulttimeout(30)

# Import shared state for stop logic
try:
    import engine.shared as shared_state
except ImportError:
    import sys, os
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if root_dir not in sys.path:
        sys.path.append(root_dir)
    try:
        import engine.shared as shared_state
    except ImportError:
        class MockShared:
            STOP_REQUESTED = False
        shared_state = MockShared()

# Custom JSON encoder for numpy types
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)

# yfinance for real market data
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False

# ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, BASE_DIR)
import asyncio

from engine.config import config, app_config
from engine.collectors import EnhancedNewsCollector
from engine.llm_analyzer import LLMAnalyzer
from engine.market_gate import MarketGate

# =====================================================
# ì£¼ë§/íœ´ì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =====================================================

def get_last_trading_date(reference_date=None):
    """
    ë§ˆì§€ë§‰ ê°œì¥ì¼ ë‚ ì§œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ì£¼ë§(í† /ì¼)ì¸ ê²½ìš° ê¸ˆìš”ì¼ë¡œ ì´ë™
    - ê¸ˆìš”ì¼ì´ íœ´ì¼ì¸ ê²½ìš° pykrxë¥¼ í†µí•´ ì‹¤ì œ ë§ˆì§€ë§‰ ê°œì¥ì¼ í™•ì¸
    
    Args:
        reference_date: ê¸°ì¤€ ë‚ ì§œ (datetime ê°ì²´). Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©.
    
    Returns:
        tuple: (last_trading_date_str, last_trading_date_obj)
               - last_trading_date_str: 'YYYYMMDD' í˜•ì‹ì˜ ë¬¸ìì—´
               - last_trading_date_obj: datetime ê°ì²´
    """
    if reference_date is None:
        reference_date = datetime.now()
    
    target_date = reference_date
    
    # 1ì°¨: ì£¼ë§ ì²˜ë¦¬ (í† /ì¼ â†’ ê¸ˆìš”ì¼ë¡œ ì´ë™)
    if target_date.weekday() == 5:  # í† ìš”ì¼
        target_date -= timedelta(days=1)
    elif target_date.weekday() == 6:  # ì¼ìš”ì¼
        target_date -= timedelta(days=2)
    
    # 2ì°¨: pykrxë¥¼ í†µí•´ ì‹¤ì œ ê°œì¥ì¼ í™•ì¸
    try:
        from pykrx import stock
        
        # ìµœê·¼ 10ì¼ê°„ ê±°ë˜ì¼ ì¡°íšŒ (íœ´ì¼ ì—°ì† ëŒ€ë¹„)
        start_check = (target_date - timedelta(days=10)).strftime('%Y%m%d')
        end_check = target_date.strftime('%Y%m%d')
        
        # KOSPI ì§€ìˆ˜ì˜ OHLCVë¡œ ê°œì¥ì¼ í™•ì¸
        kospi_data = stock.get_index_ohlcv_by_date(start_check, end_check, "1001")
        
        if not kospi_data.empty:
            # ë§ˆì§€ë§‰ ê±°ë˜ì¼ì„ ê°€ì ¸ì˜´
            last_trading_date = kospi_data.index[-1]
            last_trading_date_str = last_trading_date.strftime('%Y%m%d')
            log(f"ë§ˆì§€ë§‰ ê°œì¥ì¼ í™•ì¸: {last_trading_date_str}", "SUCCESS")
            return last_trading_date_str, last_trading_date
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê³„ì‚°ëœ ë‚ ì§œ ì‚¬ìš©
            log(f"pykrx ë°ì´í„° ì—†ìŒ, ê³„ì‚°ëœ ë‚ ì§œ ì‚¬ìš©: {target_date.strftime('%Y%m%d')}", "WARNING")
            
    except ImportError:
        log("pykrx ë¯¸ì„¤ì¹˜ - ì£¼ë§ ì²˜ë¦¬ë§Œ ì ìš©", "WARNING")
    except Exception as e:
        log(f"ê°œì¥ì¼ í™•ì¸ ì‹¤íŒ¨: {e} - ì£¼ë§ ì²˜ë¦¬ë§Œ ì ìš©", "WARNING")
    
    # í´ë°±: ì£¼ë§ ì²˜ë¦¬ë§Œ ëœ ë‚ ì§œ ë°˜í™˜
    return target_date.strftime('%Y%m%d'), target_date


# =====================================================
# ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
# =====================================================

def fetch_market_indices():
    """KOSPI/KOSDAQ ì‹¤ì‹œê°„ ì§€ìˆ˜ ìˆ˜ì§‘"""
    indices = {
        'kospi': {'value': 2650.0, 'change_pct': 0.0, 'prev_close': 2650.0},
        'kosdaq': {'value': 850.0, 'change_pct': 0.0, 'prev_close': 850.0}
    }
    
    if not YFINANCE_AVAILABLE:
        log("yfinance ë¯¸ì„¤ì¹˜ - ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©", "WARNING")
        return indices
    
    try:
        # KOSPI (^KS11)
        kospi = yf.Ticker('^KS11')
        kospi_hist = kospi.history(period='5d')
        if not kospi_hist.empty:
            current = kospi_hist['Close'].iloc[-1]
            prev = kospi_hist['Close'].iloc[-2] if len(kospi_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['kospi'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
        
        # KOSDAQ (^KQ11)
        kosdaq = yf.Ticker('^KQ11')
        kosdaq_hist = kosdaq.history(period='5d')
        if not kosdaq_hist.empty:
            current = kosdaq_hist['Close'].iloc[-1]
            prev = kosdaq_hist['Close'].iloc[-2] if len(kosdaq_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['kosdaq'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
            
        # KRX Gold (411060.KS - ACE KRXê¸ˆí˜„ë¬¼)
        gold = yf.Ticker('411060.KS')
        gold_hist = gold.history(period='5d')
        if not gold_hist.empty:
            current = gold_hist['Close'].iloc[-1]
            prev = gold_hist['Close'].iloc[-2] if len(gold_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['kr_gold'] = {
                'value': round(current, 0), # ì›í™”ëŠ” ì •ìˆ˜
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 0)
            }
        else:
            indices['kr_gold'] = {'value': 0, 'change_pct': 0, 'prev_close': 0}

        # KRX Silver (144600.KS - KODEX ì€ì„ ë¬¼(H))
        silver = yf.Ticker('144600.KS')
        silver_hist = silver.history(period='5d')
        if not silver_hist.empty:
            current = silver_hist['Close'].iloc[-1]
            prev = silver_hist['Close'].iloc[-2] if len(silver_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['kr_silver'] = {
                'value': round(current, 0),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 0)
            }
        else:
             indices['kr_silver'] = {'value': 0, 'change_pct': 0, 'prev_close': 0}
             
        # US Gold Futures (GC=F)
        us_gold = yf.Ticker('GC=F')
        us_gold_hist = us_gold.history(period='5d')
        if not us_gold_hist.empty:
            current = us_gold_hist['Close'].iloc[-1]
            prev = us_gold_hist['Close'].iloc[-2] if len(us_gold_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['us_gold'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
            
        # US Silver Futures (SI=F)
        us_silver = yf.Ticker('SI=F')
        us_silver_hist = us_silver.history(period='5d')
        if not us_silver_hist.empty:
            current = us_silver_hist['Close'].iloc[-1]
            prev = us_silver_hist['Close'].iloc[-2] if len(us_silver_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['us_silver'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
        
        log(f"ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘ ì™„ë£Œ: KOSPI {indices['kospi']['value']}, Gold {indices.get('gold', {}).get('value')}", "SUCCESS")
        
        # S&P 500 (^GSPC)
        sp500 = yf.Ticker('^GSPC')
        sp500_hist = sp500.history(period='5d')
        if not sp500_hist.empty:
            current = sp500_hist['Close'].iloc[-1]
            prev = sp500_hist['Close'].iloc[-2] if len(sp500_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['sp500'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
            
        # Nasdaq (^IXIC)
        nasdaq = yf.Ticker('^IXIC')
        nasdaq_hist = nasdaq.history(period='5d')
        if not nasdaq_hist.empty:
            current = nasdaq_hist['Close'].iloc[-1]
            prev = nasdaq_hist['Close'].iloc[-2] if len(nasdaq_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['nasdaq'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }

        # Bitcoin (BTC-USD)
        btc = yf.Ticker('BTC-USD')
        btc_hist = btc.history(period='5d')
        if not btc_hist.empty:
            current = btc_hist['Close'].iloc[-1]
            prev = btc_hist['Close'].iloc[-2] if len(btc_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['btc'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
            
        # Ethereum (ETH-USD)
        eth = yf.Ticker('ETH-USD')
        eth_hist = eth.history(period='5d')
        if not eth_hist.empty:
            current = eth_hist['Close'].iloc[-1]
            prev = eth_hist['Close'].iloc[-2] if len(eth_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['eth'] = {
                'value': round(current, 2),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 2)
            }
            
        # Ripple (XRP-USD)
        xrp = yf.Ticker('XRP-USD')
        xrp_hist = xrp.history(period='5d')
        if not xrp_hist.empty:
            current = xrp_hist['Close'].iloc[-1]
            prev = xrp_hist['Close'].iloc[-2] if len(xrp_hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            indices['xrp'] = {
                'value': round(current, 4),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 4)
            }
            
    except Exception as e:
        log(f"ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e} - ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©", "WARNING")
    
    return indices


def fetch_sector_indices():
    """pykrxë¥¼ ì‚¬ìš©í•˜ì—¬ KOSPI ì„¹í„° ì§€ìˆ˜ ìˆ˜ì§‘"""
    # ì„¹í„° ì½”ë“œ ë§¤í•‘ (KOSPI ì—…ì¢… ì§€ìˆ˜ - KRX ê³µì‹ ì½”ë“œ)
    sector_codes = {
        '1012': 'ì² ê°•',       # ì² ê°•Â·ê¸ˆì†
        '1027': '2ì°¨ì „ì§€',   # ì „ê¸°Â·ì „ì (2ì°¨ì „ì§€, ë°˜ë„ì²´ í¬í•¨)
        '1024': 'ë°˜ë„ì²´',     # ë°˜ë„ì²´
        '1016': 'ìë™ì°¨',     # ìš´ìˆ˜ì¥ë¹„
        '1020': 'ì¦ê¶Œ',       # ê¸ˆìœµì—…
        '1018': 'ITì„œë¹„ìŠ¤',   # ì„œë¹„ìŠ¤ì—… (IT)
        '1001': 'KOSPI200',   # KOSPI 200
        '1026': 'ì€í–‰',       # ì€í–‰
    }
    
    sectors = []
    
    try:
        from pykrx import stock
        # from datetime import datetime, timedelta
        
        today = datetime.now().strftime('%Y%m%d')
        yesterday = (datetime.now() - timedelta(days=3)).strftime('%Y%m%d')
        
        for code, name in sector_codes.items():
            try:
                df = stock.get_index_ohlcv_by_date(yesterday, today, code)
                if not df.empty and len(df) >= 2:
                    current = df['ì¢…ê°€'].iloc[-1]
                    prev = df['ì¢…ê°€'].iloc[-2]
                    change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
                    
                    # ê°•ì„¸/ì•½ì„¸ íŒë‹¨
                    if change_pct > 1.0:
                        signal = 'bullish'
                    elif change_pct < -1.0:
                        signal = 'bearish'
                    else:
                        signal = 'neutral'
                    
                    # ì ìˆ˜ ê³„ì‚° (ë“±ë½ë¥  ê¸°ë°˜)
                    score = min(max(50 + int(change_pct * 10), 0), 100)
                    
                    sectors.append({
                        'name': name,
                        'signal': signal,
                        'change_pct': round(change_pct, 2),
                        'score': score
                    })
            except Exception as e:
                pass
        
        if sectors:
            log(f"ì„¹í„° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(sectors)}ê°œ ì„¹í„°", "SUCCESS")
        
    except ImportError:
        log("pykrx ë¯¸ì„¤ì¹˜ - ìƒ˜í”Œ ì„¹í„° ë°ì´í„° ì‚¬ìš©", "WARNING")
    except Exception as e:
        log(f"pykrx ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e} - ìƒ˜í”Œ ë°ì´í„° ìƒì„±", "WARNING")
        
        
        return False
    
    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ë°˜í™˜
    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ìƒ˜í”Œ ê¸ˆì§€)
    if not sectors:
        return []
    
    return sectors


def fetch_stock_price(ticker):
    """ê°œë³„ ì¢…ëª© ì‹¤ì‹œê°„ ê°€ê²© ìˆ˜ì§‘"""
    if not YFINANCE_AVAILABLE:
        return None
    
    try:
        # í•œêµ­ ì¢…ëª©ì€ .KS (KOSPI) ë˜ëŠ” .KQ (KOSDAQ) ì ‘ë¯¸ì‚¬ í•„ìš”
        yahoo_ticker = f"{ticker}.KS"
        stock = yf.Ticker(yahoo_ticker)
        hist = stock.history(period='5d')
        
        if hist.empty:
            # KOSDAQ ì‹œë„
            yahoo_ticker = f"{ticker}.KQ"
            stock = yf.Ticker(yahoo_ticker)
            hist = stock.history(period='5d')
        
        if not hist.empty:
            current = hist['Close'].iloc[-1]
            prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
            change_pct = ((current - prev) / prev) * 100 if prev > 0 else 0
            return {
                'price': round(current, 0),
                'change_pct': round(change_pct, 2),
                'prev_close': round(prev, 0)
            }
    except Exception as e:
        pass
    
    return None


# ì „ì—­ ìºì‹œ (ì—¬ëŸ¬ í•¨ìˆ˜ì—ì„œ ê³µìœ )
_market_indices_cache = None
_sector_indices_cache = None

def get_market_indices():
    """ìºì‹œëœ ì‹œì¥ ì§€ìˆ˜ ë°˜í™˜"""
    global _market_indices_cache
    if _market_indices_cache is None:
        _market_indices_cache = fetch_market_indices()
    return _market_indices_cache

def get_sector_indices():
    """ìºì‹œëœ ì„¹í„° ì§€ìˆ˜ ë°˜í™˜"""
    global _sector_indices_cache
    if _sector_indices_cache is None:
        _sector_indices_cache = fetch_sector_indices()
    return _sector_indices_cache

def reset_cache():
    """ìºì‹œ ì´ˆê¸°í™” (Refresh ì‹œ í˜¸ì¶œ)"""
    global _market_indices_cache, _sector_indices_cache
    _market_indices_cache = None
    _sector_indices_cache = None
    log("ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ", "SUCCESS")



# ìƒ‰ìƒ ì½”ë“œ (í„°ë¯¸ë„)
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def log(message, level="INFO"):
    if level == "SUCCESS":
        print(f"{Colors.OKGREEN}âœ… {message}{Colors.ENDC}", flush=True)
    elif level == "ERROR":
        print(f"{Colors.FAIL}âŒ {message}{Colors.ENDC}", flush=True)
    elif level == "WARNING":
        print(f"{Colors.WARNING}âš ï¸  {message}{Colors.ENDC}", flush=True)
    elif level == "HEADER":
        print(f"\n{Colors.HEADER}{Colors.BOLD}{'='*60}{Colors.ENDC}", flush=True)
        print(f"{Colors.HEADER}{message}{Colors.ENDC}", flush=True)
        print(f"{Colors.HEADER}{'='*60}{Colors.ENDC}", flush=True)
    else:
        print(f"ğŸ“Œ {message}", flush=True)

def ensure_directory(dir_path):
    """ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
        log(f"ë””ë ‰í† ë¦¬ ìƒì„±ë¨: {dir_path}", "SUCCESS")
    else:
        log(f"ë””ë ‰í† ë¦¬ í™•ì¸ë¨: {dir_path}")

def create_korean_stocks_list():
    """í•œêµ­ ì£¼ì‹ ëª©ë¡ ìƒì„± - pykrxë¡œ ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì¡°íšŒ"""
    log("í•œêµ­ ì£¼ì‹ ëª©ë¡ ìƒì„± ì¤‘ (pykrx ì‹œê°€ì´ì•¡ ìƒìœ„)...")
    try:
        from pykrx import stock
        # from datetime import datetime
        
        today = datetime.now().strftime('%Y%m%d')
        
        all_data = []
        
        # KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì¡°íšŒ
        try:
            kospi_cap = stock.get_market_cap(today, market="KOSPI")
            if not kospi_cap.empty:
                # ì‹œê°€ì´ì•¡ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 300ê°œ (VCP ë°œêµ´ í™•ë¥  í™•ëŒ€ë¥¼ ìœ„í•´ ì¦ê°€)
                kospi_cap = kospi_cap.sort_values('ì‹œê°€ì´ì•¡', ascending=False).head(300)
                for ticker in kospi_cap.index:
                    try:
                        name = stock.get_market_ticker_name(ticker)
                        all_data.append({
                            'ticker': ticker,
                            'name': name,
                            'market': 'KOSPI',
                            'sector': ''
                        })
                    except:
                        pass
                log(f"KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ {len(kospi_cap)} ì¢…ëª© ìˆ˜ì§‘", "SUCCESS")
        except Exception as e:
            log(f"KOSPI ì‹œê°€ì´ì•¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", "WARNING")
        
        # KOSDAQ ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª© ì¡°íšŒ
        try:
            kosdaq_cap = stock.get_market_cap(today, market="KOSDAQ")
            if not kosdaq_cap.empty:
                # ì‹œê°€ì´ì•¡ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 300ê°œ (ì½”ìŠ¤ë‹¥ í¬í•¨ ìš”ì²­ ë°˜ì˜)
                kosdaq_cap = kosdaq_cap.sort_values('ì‹œê°€ì´ì•¡', ascending=False).head(300)
                for ticker in kosdaq_cap.index:
                    try:
                        name = stock.get_market_ticker_name(ticker)
                        all_data.append({
                            'ticker': ticker,
                            'name': name,
                            'market': 'KOSDAQ',
                            'sector': ''
                        })
                    except:
                        pass
                log(f"KOSDAQ ì‹œê°€ì´ì•¡ ìƒìœ„ {len(kosdaq_cap)} ì¢…ëª© ìˆ˜ì§‘", "SUCCESS")
        except Exception as e:
            log(f"KOSDAQ ì‹œê°€ì´ì•¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", "WARNING")
        
        if all_data:
            df = pd.DataFrame(all_data)
            file_path = os.path.join(BASE_DIR, 'data', 'korean_stocks_list.csv')
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            log(f"ì¢…ëª© ëª©ë¡ ìƒì„± ì™„ë£Œ: {file_path} ({len(df)} ì¢…ëª©)", "SUCCESS")
            return True
        else:
            raise Exception("ì‹œê°€ì´ì•¡ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        
    except Exception as e:
        log(f"pykrx ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ì¢…ëª© ì‚¬ìš©", "WARNING")
        # í´ë°±: ì‹œê°€ì´ì•¡ ìƒìœ„ ì£¼ìš” ì¢…ëª© (KOSPI + KOSDAQ)
        data = {
            'ticker': [
                # KOSPI ìƒìœ„ 15ê°œ
                '005930', '000660', '005380', '373220', '207940', '000270', '035420', '068270', '105560', '055550',
                '035720', '003550', '015760', '028260', '017670',
                # KOSDAQ ìƒìœ„ 10ê°œ
                '247540', '086520', '196170', '263750', '145020', '403870', '328130', '091990', '336370', '058470'
            ],
            'name': [
                # KOSPI
                'ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'í˜„ëŒ€ì°¨', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'ê¸°ì•„', 'NAVER', 'ì…€íŠ¸ë¦¬ì˜¨', 'KBê¸ˆìœµ', 'ì‹ í•œì§€ì£¼',
                'ì¹´ì¹´ì˜¤', 'LG', 'í•œêµ­ì „ë ¥', 'ì‚¼ì„±ë¬¼ì‚°', 'SKí…”ë ˆì½¤',
                # KOSDAQ
                'ì—ì½”í”„ë¡œë¹„ì— ', 'ì—ì½”í”„ë¡œ', 'ì•Œí…Œì˜¤ì  ', 'í„ì–´ë¹„ìŠ¤', 'íœ´ì ¤', 'í”¼ì—ì´ì¹˜ì—ì´', 'ë£¨ë‹›', 'ì…€íŠ¸ë¦¬ì˜¨ì œì•½', 'ì†”ë¸Œë ˆì¸', 'ë¦¬ë…¸ê³µì—…'
            ],
            'market': [
                'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI',
                'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI', 'KOSPI',
                'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ', 'KOSDAQ'
            ],
            'sector': [
                'ë°˜ë„ì²´', 'ë°˜ë„ì²´', 'ìë™ì°¨', '2ì°¨ì „ì§€', 'ë°”ì´ì˜¤', 'ìë™ì°¨', 'ì¸í„°ë„·', 'ë°”ì´ì˜¤', 'ê¸ˆìœµ', 'ê¸ˆìœµ',
                'ì¸í„°ë„·', 'ì§€ì£¼', 'ì—ë„ˆì§€', 'ê±´ì„¤', 'í†µì‹ ',
                '2ì°¨ì „ì§€', '2ì°¨ì „ì§€', 'ë°”ì´ì˜¤', 'ê²Œì„', 'ë°”ì´ì˜¤', 'ìë™ì°¨ë¶€í’ˆ', 'AI/ì˜ë£Œ', 'ë°”ì´ì˜¤', 'ë°˜ë„ì²´ì†Œì¬', 'ë°˜ë„ì²´ì¥ë¹„'
            ],
        }
        df = pd.DataFrame(data)
        file_path = os.path.join(BASE_DIR, 'data', 'korean_stocks_list.csv')
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        log(f"ê¸°ë³¸ ì¢…ëª© ëª©ë¡ ìƒì„± ì™„ë£Œ: {file_path} ({len(df)} ì¢…ëª© - KOSPI 15ê°œ + KOSDAQ 10ê°œ)", "SUCCESS")
        return True



def fetch_prices_yfinance(start_date, end_date, existing_df, file_path):
    """yfinanceë¥¼ ì´ìš©í•œ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ í´ë°±"""
    try:
        import yfinance as yf
        log("yfinance ë°±ì—… ìˆ˜ì§‘ ëª¨ë“œ ê°€ë™...", "INFO")
        
        # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        stocks_file = os.path.join(BASE_DIR, 'data', 'korean_stocks_list.csv')
        if not os.path.exists(stocks_file):
            log("ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ì–´ yfinance ìˆ˜ì§‘ ë¶ˆê°€", "ERROR")
            return False
            
        stocks_df = pd.read_csv(stocks_file, dtype={'ticker': str})
        tickers = stocks_df['ticker'].tolist()
        
        new_data_list = []
        
        total = len(tickers)
        for idx, ticker in enumerate(tickers):
            try:
                # ë§ˆì¼“ í™•ì¸
                market_info = stocks_df[stocks_df['ticker'] == ticker]['market'].values
                suffix = ".KS" if len(market_info) > 0 and market_info[0] == 'KOSPI' else ".KQ"
                yf_ticker = f"{ticker}{suffix}"
                
                # ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì§„í–‰ë¥  í‘œì‹œ ì—†ì´)
                df = yf.download(yf_ticker, start=start_date.strftime('%Y-%m-%d'), end=(end_date + timedelta(days=1)).strftime('%Y-%m-%d'), progress=False)
                
                if not df.empty:
                    # MultiIndex ì»¬ëŸ¼ ì²˜ë¦¬
                    if isinstance(df.columns, pd.MultiIndex):
                         # yfinance 0.2.x+ returns MultiIndex if configured or sometimes by default
                         # It usually is (Price, Ticker) or just Price.
                         # Dropping level if it exists
                        try:
                            df.columns = df.columns.droplevel(1)
                        except:
                            pass
                        
                    df = df.reset_index()
                    # ì»¬ëŸ¼ ì´ë¦„ì´ Date, Open, High ...
                    
                    # Rename columns to standard lowercase
                    df = df.rename(columns={
                        'Date': 'date', 'Open': 'open', 'High': 'high', 
                        'Low': 'low', 'Close': 'close', 'Volume': 'volume'
                    })
                    
                    # Ensure columns exist
                    required_cols = ['date', 'open', 'high', 'low', 'close', 'volume']
                    if not all(col in df.columns for col in required_cols):
                         continue

                    df['date'] = df['date'].dt.strftime('%Y-%m-%d')
                    df['ticker'] = ticker
                    
                    # Type conversion
                    df['open'] = df['open'].astype(int)
                    df['high'] = df['high'].astype(int)
                    df['low'] = df['low'].astype(int)
                    df['close'] = df['close'].astype(int)
                    df['volume'] = df['volume'].astype(int)
                    
                    subset = df[['date', 'ticker', 'open', 'high', 'low', 'close', 'volume']]
                    new_data_list.append(subset)
                    
            except Exception as e:
                continue
                
            if idx % 50 == 0:
                print(f"  -> yfinance ì§„í–‰: {idx}/{total}")

        if new_data_list:
            new_df = pd.concat(new_data_list)
            
            if not existing_df.empty:
                if 'date' in existing_df.columns and not pd.api.types.is_string_dtype(existing_df['date']):
                     existing_df['date'] = existing_df['date'].dt.strftime('%Y-%m-%d')
                     
                final_df = pd.concat([existing_df, new_df])
                final_df = final_df.drop_duplicates(subset=['ticker', 'date'], keep='last')
            else:
                final_df = new_df
                
            final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
            log(f"yfinance ë°±ì—… ìˆ˜ì§‘ ì™„ë£Œ ({len(final_df)}í–‰)", "SUCCESS")
            return True
        else:
            log("yfinance ìˆ˜ì§‘ ë°ì´í„° ì—†ìŒ", "WARNING")
            return True
            
    except Exception as e:
        log(f"yfinance í´ë°± ì‹¤íŒ¨: {e}", "ERROR")
        return False


def create_daily_prices(target_date=None):
    """ì¼ë³„ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ - pykrx ë‚ ì§œë³„ ì¼ê´„ ì¡°íšŒ (ì†ë„ ìµœì í™”)"""
    log("ì¼ë³„ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì¤‘ (Date-based Fast Mode)...")
    try:
        from pykrx import stock
        import time
        from datetime import datetime, timedelta

        # ë‚ ì§œ ì„¤ì •
        if target_date:
            if isinstance(target_date, str):
                end_date_obj = datetime.strptime(target_date, '%Y-%m-%d')
            else:
                end_date_obj = target_date
        else:
            end_date_obj = datetime.now()

        # ë§ˆì§€ë§‰ ê°œì¥ì¼ í™•ì¸
        end_date_str, end_date_obj = get_last_trading_date(reference_date=end_date_obj)
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ë° ì‹œì‘ì¼ ê²°ì •
        file_path = os.path.join(BASE_DIR, 'data', 'daily_prices.csv')
        existing_df = pd.DataFrame()
        start_date_obj = end_date_obj - timedelta(days=90) # ê¸°ë³¸ 90ì¼

        if os.path.exists(file_path):
            try:
                existing_df = pd.read_csv(file_path, dtype={'ticker': str})
                if not existing_df.empty and 'date' in existing_df.columns:
                    max_date_str = existing_df['date'].max()
                    max_date_dt = datetime.strptime(max_date_str, '%Y-%m-%d')
                    # ë§ˆì§€ë§‰ ì €ì¥ì¼ ë‹¤ìŒë‚ ë¶€í„° ìˆ˜ì§‘
                    start_date_obj = max_date_dt + timedelta(days=1)
                    log(f"ê¸°ì¡´ ë°ì´í„° í™•ì¸: {max_date_str}ê¹Œì§€ ì¡´ì¬. ì´í›„ë¶€í„° ìˆ˜ì§‘.", "INFO")
                else:
                    log("ê¸°ì¡´ ë°ì´í„° ë¹„ì–´ìˆìŒ.", "INFO")
            except Exception as e:
                log(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}", "WARNING")

        # ìˆ˜ì§‘ ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ë¯¸ë˜ë©´ ìˆ˜ì§‘ ë¶ˆí•„ìš” (ë‹¨, ë‹¹ì¼ì¬ìˆ˜ì§‘ ì˜µì…˜ ê³ ë ¤ ë“±ì€ ìƒëµ, 'ìµœì‹ 'ì´ë©´ pass)
        if start_date_obj.date() > end_date_obj.date():
             log("ì´ë¯¸ ìµœì‹  ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.", "SUCCESS")
             return True
             
        req_start_date_str = start_date_obj.strftime('%Y%m%d')
        log(f"ìˆ˜ì§‘ êµ¬ê°„: {req_start_date_str} ~ {end_date_str}", "INFO")

        # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        date_range = pd.date_range(start=start_date_obj, end=end_date_obj)
        total_days = len(date_range)
        
        new_data_list = []
        processed_days = 0
        
        for dt in date_range:
            if shared_state.STOP_REQUESTED:
                log("â›”ï¸ ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì¤‘ë‹¨", "WARNING")
                break
                
            cur_date_str = dt.strftime('%Y%m%d')
            cur_date_fmt = dt.strftime('%Y-%m-%d')
            
            # ì£¼ë§ ì²´í¬ (í† /ì¼) - pykrxê°€ ì•Œì•„ì„œ ë¹ˆê°’ ì¤„ ìˆ˜ ìˆìœ¼ë‚˜ ë¯¸ë¦¬ ê±´ë„ˆë›°ë©´ ë¹ ë¦„
            if dt.weekday() >= 5: 
                processed_days += 1
                continue
                
            try:
                # í•´ë‹¹ ë‚ ì§œì˜ ì „ ì¢…ëª© ì‹œì„¸ ì¡°íšŒ (1íšŒ ìš”ì²­)
                df = stock.get_market_ohlcv(cur_date_str, market="ALL")
                
                if df is None or df.empty:
                    # íœ´ì¥ì¼ ê°€ëŠ¥ì„±
                    processed_days += 1
                    continue
                    
                # DataFrame ì •ë¦¬
                # indexëŠ” ticker, columns: ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€, ê±°ë˜ëŸ‰, ê±°ë˜ëŒ€ê¸ˆ, ë“±ë½ë¥ 
                df = df.reset_index() # tickerê°€ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ì˜´ ('í‹°ì»¤')
                
                # ì»¬ëŸ¼ ë§¤í•‘
                # pykrx ë²„ì „ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ 'í‹°ì»¤'ì¼ìˆ˜ë„, indexì¼ìˆ˜ë„ ìˆìŒ. 
                # get_market_ohlcv("YYYYMMDD") returns index=í‹°ì»¤.
                if 'í‹°ì»¤' in df.columns:
                    df = df.rename(columns={'í‹°ì»¤': 'ticker'})
                else: 
                    # reset_index() í–ˆì„ ë•Œ ê¸°ì¡´ index ì´ë¦„ì´ 'í‹°ì»¤'ì˜€ë‹¤ë©´ ê·¸ê²Œ ì»¬ëŸ¼ëª…ì´ ë¨
                    # ë§Œì•½ ì´ë¦„ì´ ì—†ì—ˆë‹¤ë©´ 'index'
                    if 'index' in df.columns:
                        df = df.rename(columns={'index': 'ticker'})
                
                # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
                rename_map = {
                    'ì‹œê°€': 'open', 'ê³ ê°€': 'high', 'ì €ê°€': 'low', 
                    'ì¢…ê°€': 'close', 'ê±°ë˜ëŸ‰': 'volume', 'ê±°ë˜ëŒ€ê¸ˆ': 'trading_value'
                }
                
                # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ rename
                available_map = {k: v for k, v in rename_map.items() if k in df.columns}
                df = df.rename(columns=available_map)
                
                df['ticker'] = df['ticker'].astype(str).str.zfill(6)
                df['date'] = cur_date_fmt
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
                cols = ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume', 'trading_value']
                # ê±°ë˜ëŒ€ê¸ˆ ì—†ì„ ê²½ìš° ì²˜ë¦¬
                if 'trading_value' not in df.columns:
                    df['trading_value'] = df['volume'] * df['close']
                    
                df_final = df[cols].copy()
                
                # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë©”ëª¨ë¦¬ ê³ ë ¤: ë°”ë¡œë°”ë¡œ ëª¨ìŒ)
                # DataFrame to dict list is slow? append DF to list then concat.
                new_data_list.append(df_final)
                
                processed_days += 1
                progress = (processed_days / total_days) * 100
                log(f"[Daily Prices] {cur_date_fmt} ìˆ˜ì§‘ ì™„ë£Œ ({len(df_final)}ì¢…ëª©) - {progress:.1f}%", "INFO")
                
                # Rate Limit ë°©ì§€
                time.sleep(random.uniform(0.3, 0.7))
                
            except Exception as e:
                log(f"ë‚ ì§œë³„ ìˆ˜ì§‘ ì‹¤íŒ¨ ({cur_date_str}): {e}", "WARNING")
                processed_days += 1
                
        # ë³‘í•© ë° ì €ì¥
        if new_data_list:
            log("ë°ì´í„° ë³‘í•© ì¤‘...", "INFO")
            new_chunk_df = pd.concat(new_data_list, ignore_index=True)
            
            if not existing_df.empty:
                final_df = pd.concat([existing_df, new_chunk_df])
                final_df = final_df.drop_duplicates(subset=['date', 'ticker'], keep='last')
            else:
                final_df = new_chunk_df
                
            final_df = final_df.sort_values(['ticker', 'date'])
            final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
            log(f"ì¼ë³„ ê°€ê²© ì €ì¥ ì™„ë£Œ: ì´ {len(final_df)}í–‰ (ì‹ ê·œ {len(new_chunk_df)}í–‰)", "SUCCESS")
        else:
             log("pykrx ìˆ˜ì§‘ ë°ì´í„° ì—†ìŒ. yfinance í´ë°± ì‹œë„...", "WARNING")
             return fetch_prices_yfinance(start_date_obj, end_date_obj, existing_df, file_path)
                 
        return True

    except Exception as e:
        log(f"pykrx ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e} -> yfinance í´ë°± ì‹œë„", "WARNING")
        return fetch_prices_yfinance(start_date_obj, end_date_obj, existing_df, file_path)


def create_institutional_trend(target_date=None):
    """ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ - pykrx ê¸°ê´€/ì™¸êµ­ì¸ ìˆœë§¤ë§¤"""
    log("ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ (pykrx ì‹¤ì œ ë°ì´í„°)...")
    try:
        from pykrx import stock
        
        # ì¢…ëª© ëª©ë¡ ë¡œë“œ
        stocks_file = os.path.join(BASE_DIR, 'data', 'korean_stocks_list.csv')
        if os.path.exists(stocks_file):
            stocks_df = pd.read_csv(stocks_file)
            tickers = stocks_df['ticker'].astype(str).str.zfill(6).tolist()
            # Market Gate ë¶„ì„ì„ ìœ„í•´ KODEX 200 (069500) í•„ìˆ˜ ì¶”ê°€
            if '069500' not in tickers:
                tickers.insert(0, '069500')
        else:
            tickers = ['069500', '005930', '000660', '000270', '051910', '006400']
        
        if target_date:
            # from datetime import datetime
            if isinstance(target_date, str):
                target_date_obj = datetime.strptime(target_date, '%Y-%m-%d')
            else:
                target_date_obj = target_date
        else:
            target_date_obj = datetime.now()

        # ë§ˆì§€ë§‰ ê°œì¥ì¼ í™•ì¸ (ì£¼ë§/íœ´ì¼ ìë™ ì²˜ë¦¬)
        end_date, end_date_obj = get_last_trading_date(reference_date=target_date_obj)
        start_date = (end_date_obj - timedelta(days=30)).strftime('%Y%m%d')
        
        log(f"ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ êµ¬ê°„(ê¸°ë³¸): {start_date} ~ {end_date} (ì¦ë¶„ ìˆ˜ì§‘ ì ìš©)")
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        file_path = os.path.join(BASE_DIR, 'data', 'all_institutional_trend_data.csv')
        existing_df = pd.DataFrame()
        last_updates = {}
        
        if os.path.exists(file_path):
            try:
                existing_df = pd.read_csv(file_path)
                if not existing_df.empty and 'date' in existing_df.columns and 'ticker' in existing_df.columns:
                    existing_df['ticker'] = existing_df['ticker'].astype(str).str.zfill(6)
                    last_updates = existing_df.groupby('ticker')['date'].max().to_dict()
            except:
                pass

        all_data = []
        success_count = 0
        skipped_count = 0
        
        from concurrent.futures import ThreadPoolExecutor, as_completed

        def fetch_inst(ticker):
            if shared_state.STOP_REQUESTED: return None
            
            # ì¦ë¶„ ë¡œì§
            req_start_date = start_date
            last_date_str = last_updates.get(ticker)
            if last_date_str:
                try:
                    last_dt = datetime.strptime(last_date_str, '%Y-%m-%d')
                    if last_dt.date() >= end_date_obj.date():
                        return 'SKIPPED'
                    req_start_date = (last_dt + timedelta(days=1)).strftime('%Y%m%d')
                except:
                    pass
            
            if req_start_date > end_date:
                return 'SKIPPED'
                
            # Random sleep
            time.sleep(random.uniform(0.2, 0.5))

            try:
                df = stock.get_market_trading_value_by_date(req_start_date, end_date, ticker)
                if not df.empty:
                    local_data = []
                    for date, row in df.iterrows():
                        foreign_net = row.get('ì™¸êµ­ì¸í•©ê³„', 0)
                        inst_net = row.get('ê¸°ê´€í•©ê³„', 0)
                        local_data.append({
                            'date': date.strftime('%Y-%m-%d'),
                            'ticker': ticker,
                            'foreign_buy': int(foreign_net) if pd.notna(foreign_net) else 0,
                            'inst_buy': int(inst_net) if pd.notna(inst_net) else 0
                        })
                    return local_data
            except ValueError:
                # pykrx Length mismatch error (ë°ì´í„° ì—†ìŒ) - ì¡°ìš©íˆ ë¬´ì‹œ
                return None
            except Exception as e:
                log(f"[Trend Fail] {ticker}: {str(e)}", "WARNING")
            return None

        total_tickers = len(tickers[:600])
        processed_count = 0

        with ThreadPoolExecutor(max_workers=2) as executor:
            future_to_ticker = {executor.submit(fetch_inst, t): t for t in tickers[:600]}
            
            for future in as_completed(future_to_ticker):
                if shared_state.STOP_REQUESTED:
                    log("â›”ï¸ ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ë‹¨", "WARNING")
                    executor.shutdown(wait=False, cancel_futures=True)
                    raise Exception("ì‚¬ìš©ì ìš”ì²­ ì¤‘ë‹¨")
                
                processed_count += 1
                
                # ì§„í–‰ë¥  ë¡œê·¸ (10ê±´ë§ˆë‹¤)
                if processed_count % 10 == 0 or processed_count == total_tickers:
                    progress = (processed_count / total_tickers) * 100
                    log(f"[Institutional Trend] ì§„í–‰ë¥ : {processed_count}/{total_tickers} ({progress:.1f}%)", "INFO")
                
                result = future.result()
                if result == 'SKIPPED':
                    skipped_count += 1
                elif result:
                    all_data.extend(result)
                    success_count += 1
                    
                    # [ì¤‘ê°„ ì €ì¥] 30ê°œ ì¢…ëª©ë§ˆë‹¤ ì €ì¥
                    if success_count % 30 == 0:
                        try:
                            temp_new_df = pd.DataFrame(all_data)
                            if not existing_df.empty:
                                temp_final = pd.concat([existing_df, temp_new_df])
                                temp_final = temp_final.drop_duplicates(subset=['date', 'ticker'], keep='last')
                            else:
                                temp_final = temp_new_df
                            temp_final.to_csv(file_path, index=False, encoding='utf-8-sig')
                            log(f"[Auto-Save] ìˆ˜ê¸‰ ë°ì´í„° ì¤‘ê°„ ì €ì¥ ({success_count}ê°œ)", "INFO")
                        except Exception as e:
                            log(f"ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}", "WARNING")
        
        # ë³‘í•© ì €ì¥
        if all_data:
            new_df = pd.DataFrame(all_data)
            if not existing_df.empty:
                final_df = pd.concat([existing_df, new_df])
                final_df = final_df.drop_duplicates(subset=['date', 'ticker'], keep='last')
                # final_df = final_df.sort_values(['ticker', 'date']) # ìˆ˜ê¸‰ ë°ì´í„°ëŠ” êµ³ì´ ì •ë ¬ ì•ˆí•´ë„? íŒŒì¼ë§Œ ì»¤ì§€ë‚˜. ì •ë ¬ í•˜ëŠ”ê²Œ ì¢‹ìŒ.
            else:
                final_df = new_df
                
            final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
            log(f"ìˆ˜ê¸‰ ë°ì´í„°: {success_count}ê°œ ì—…ë°ì´íŠ¸, {skipped_count}ê°œ ìµœì‹  ìœ ì§€. ì´ {len(final_df)}í–‰", "SUCCESS")
            return True
        elif skipped_count > 0:
            log(f"ìˆ˜ê¸‰ ë°ì´í„°: ëª¨ë‘ ìµœì‹  ìƒíƒœì„ ({skipped_count}ê°œ ì¢…ëª©)", "SUCCESS")
            return True
        else:
             if not existing_df.empty:
                log("ìˆ˜ê¸‰ ë°ì´í„°: ì‹ ê·œ ìˆ˜ì§‘ ì‹¤íŒ¨í•˜ì˜€ìœ¼ë‚˜ ê¸°ì¡´ ë°ì´í„° ìœ ì§€", "WARNING")
                return True
             
             # íŒŒì¼ë„ ì—†ê³  ë°ì´í„°ë„ ì—†ìœ¼ë©´ ë¹ˆ íŒŒì¼ ìƒì„±
             log("ìˆ˜ê¸‰ ë°ì´í„°: ìˆ˜ì§‘ ë°ì´í„° ì—†ìŒ - ë¹ˆ íŒŒì¼ ìƒì„±", "WARNING")
             df = pd.DataFrame(columns=['date', 'ticker', 'foreign_buy', 'inst_buy'])
             df.to_csv(file_path, index=False, encoding='utf-8-sig')
             return True
            
    except Exception as e:
        log(f"pykrx ìˆ˜ê¸‰ ìˆ˜ì§‘ ì‹¤íŒ¨: {e} (ìƒ˜í”Œ ìƒì„± ì•ˆí•¨)", "WARNING")
        
        # ë¹ˆ íŒŒì¼ ìƒì„±
        df = pd.DataFrame(columns=['date', 'ticker', 'foreign_buy', 'inst_buy'])
        file_path = os.path.join(BASE_DIR, 'data', 'all_institutional_trend_data.csv')
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        return True


def calculate_vcp_score(df: pd.DataFrame) -> dict:
    """
    VCP íŒ¨í„´ ì ìˆ˜ ê³„ì‚° (0~100)
    - ë³€ë™ì„± ìˆ˜ì¶•: ìµœê·¼ 5ì¼ ê³ ì €í­ < 20ì¼ í‰ê·  ê³ ì €í­
    - ê±°ë˜ëŸ‰ ê°ì†Œ: ìµœê·¼ 5ì¼ ê±°ë˜ëŸ‰ < 20ì¼ í‰ê·  ê±°ë˜ëŸ‰
    - ì´í‰ì„  ì •ë°°ì—´: ì¢…ê°€ > 5MA > 20MA
    """
    if len(df) < 20:
        return {'score': 0, 'contraction_ratio': 0, 'reasons': []}
    
    try:
        df = df.sort_index()
        
        # ë³€ë™ì„± ìˆ˜ì¶• ê³„ì‚°
        df['range'] = df['high'] - df['low']
        recent_range = df['range'].tail(5).mean()
        avg_range = df['range'].tail(20).mean()
        contraction_ratio = recent_range / avg_range if avg_range > 0 else 1
        
        # ê±°ë˜ëŸ‰ ê°ì†Œ ê³„ì‚°
        recent_vol = df['volume'].tail(5).mean()
        avg_vol = df['volume'].tail(20).mean()
        vol_ratio = recent_vol / avg_vol if avg_vol > 0 else 1
        
        # ì´í‰ì„  ì •ë°°ì—´
        ma5 = df['close'].tail(5).mean()
        ma20 = df['close'].tail(20).mean()
        current_price = df['close'].iloc[-1]
        
        score = 0
        reasons = []
        
        # ë³€ë™ì„± ìˆ˜ì¶• (ìµœëŒ€ 40ì )
        if contraction_ratio < 0.5:
            score += 40
            reasons.append("ê°•í•œ ë³€ë™ì„± ìˆ˜ì¶•")
        elif contraction_ratio < 0.7:
            score += 30
            reasons.append("ë³€ë™ì„± ìˆ˜ì¶•")
        elif contraction_ratio < 0.9:
            score += 15
        
        # ê±°ë˜ëŸ‰ ê°ì†Œ (ìµœëŒ€ 30ì )
        if vol_ratio < 0.5:
            score += 30
            reasons.append("ê±°ë˜ëŸ‰ ê¸‰ê°")
        elif vol_ratio < 0.7:
            score += 20
            reasons.append("ê±°ë˜ëŸ‰ ê°ì†Œ")
        elif vol_ratio < 0.9:
            score += 10
        
        # ì´í‰ì„  ì •ë°°ì—´ (ìµœëŒ€ 30ì )
        if current_price > ma5 > ma20:
            score += 30
            reasons.append("ì´í‰ì„  ì •ë°°ì—´")
        elif current_price > ma20:
            score += 15
        
        return {'score': score, 'contraction_ratio': round(contraction_ratio, 2), 'reasons': reasons}
    except:
        return {'score': 0, 'contraction_ratio': 0, 'reasons': []}


def calculate_supply_score(ticker: str, inst_df: pd.DataFrame) -> dict:
    """
    ìˆ˜ê¸‰ ì ìˆ˜ ê³„ì‚° (0~100)
    - ì™¸êµ­ì¸ 5ì¼ ìˆœë§¤ìˆ˜: 25ì 
    - ê¸°ê´€ 5ì¼ ìˆœë§¤ìˆ˜: 20ì 
    - ì—°ì† ë§¤ìˆ˜ì¼: 15ì 
    """
    try:
        # ticker ë¹„êµ ì‹œ zfill(6) ì ìš©í•˜ì—¬ í˜•ì‹ ë§ì¶¤
        df = inst_df[inst_df['ticker'].astype(str).str.zfill(6) == ticker].sort_values('date')
        if len(df) < 5:
            return {'score': 0, 'foreign_5d': 0, 'inst_5d': 0}
        
        recent = df.tail(5)
        foreign_5d = recent['foreign_buy'].sum()
        inst_5d = recent['inst_buy'].sum()
        
        score = 0
        
        # ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ (ìµœëŒ€ 40ì )
        if foreign_5d > 1000000000:  # 10ì–µ
            score += 40
        elif foreign_5d > 500000000:  # 5ì–µ
            score += 25
        elif foreign_5d > 0:
            score += 10
        
        # ê¸°ê´€ ìˆœë§¤ìˆ˜ (ìµœëŒ€ 30ì )
        if inst_5d > 500000000:  # 5ì–µ
            score += 30
        elif inst_5d > 200000000:  # 2ì–µ
            score += 20
        elif inst_5d > 0:
            score += 10
        
        # ì—°ì† ë§¤ìˆ˜ì¼ (ìµœëŒ€ 30ì )
        consecutive = 0
        for val in reversed(recent['foreign_buy'].values):
            if val > 0:
                consecutive += 1
            else:
                break
        score += min(consecutive * 6, 30)
        
        return {'score': score, 'foreign_5d': int(foreign_5d), 'inst_5d': int(inst_5d)}
    except:
        return {'score': 0, 'foreign_5d': 0, 'inst_5d': 0}


def create_signals_log(target_date=None, run_ai=False):
    """VCP ì‹œê·¸ë„ ë¡œê·¸ ìƒì„± - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„"""
    log("VCP ì‹œê·¸ë„ ë¶„ì„ ì¤‘ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)...")
    try:
        from pykrx import stock
        
        # ë°ì´í„° ë¡œë“œ
        prices_file = os.path.join(BASE_DIR, 'data', 'daily_prices.csv')
        inst_file = os.path.join(BASE_DIR, 'data', 'all_institutional_trend_data.csv')
        stocks_file = os.path.join(BASE_DIR, 'data', 'korean_stocks_list.csv')
        
        if not all(os.path.exists(f) for f in [prices_file, inst_file, stocks_file]):
            raise Exception("í•„ìš”í•œ ë°ì´í„° íŒŒì¼ ì—†ìŒ")
        
        prices_df = pd.read_csv(prices_file)
        inst_df = pd.read_csv(inst_file)
        stocks_df = pd.read_csv(stocks_file)
        
        # (ì¤‘ìš”) íƒ€ê²Ÿ ë‚ ì§œ ê¸°ì¤€ ë°ì´í„° í•„í„°ë§ (Look-ahead Bias ë°©ì§€ ë° ì‹œì  ì •í™•ë„ í™•ë³´)
        if target_date:
            log(f"[{target_date}] ê¸°ì¤€ ê³¼ê±° ë°ì´í„°ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤...", "INFO")
            prices_df = prices_df[prices_df['date'] <= target_date]
            inst_df = inst_df[inst_df['date'] <= target_date]
        
        
        signals = []
        
        analyzed_count = 0
        total_stocks = len(stocks_df)
        log(f"ì´ {total_stocks}ê°œ ì¢…ëª©ì— ëŒ€í•œ VCP ë¶„ì„ ì‹œì‘... (KOSPI+KOSDAQ)", "INFO")
        
        for _, row in stocks_df.iterrows():
            ticker = str(row['ticker']).zfill(6)
            name = row['name']
            market = row['market']
            
            # ê°€ê²© ë°ì´í„° í•„í„°ë§
            ticker_prices = prices_df[prices_df['ticker'].astype(str).str.zfill(6) == ticker].copy()
            if len(ticker_prices) < 20:
                continue
            
            # ì¸ë±ìŠ¤ë¥¼ ë‚ ì§œë¡œ ì„¤ì •
            ticker_prices['date'] = pd.to_datetime(ticker_prices['date'])
            ticker_prices = ticker_prices.set_index('date')
            
            # VCP ì ìˆ˜ ê³„ì‚°
            vcp = calculate_vcp_score(ticker_prices)
            
            # ìˆ˜ê¸‰ ì ìˆ˜ ê³„ì‚°
            supply = calculate_supply_score(ticker, inst_df)
            
            # ì¢…í•© ì ìˆ˜ (VCP 60% + ìˆ˜ê¸‰ 40%) - ìˆ˜ê¸‰ ë°ì´í„° ëˆ„ë½ ì‹œ ë³´ì • ë¡œì§ ì¶”ê°€
            # ìˆ˜ê¸‰ ë°ì´í„°ê°€ ì—†ìœ¼ë©´(0ì ), VCP ì ìˆ˜ë§Œìœ¼ë¡œ 100% í™˜ì‚° (55/60 -> 91ì )
            if supply['score'] == 0 and vcp['score'] > 0:
                total_score = (vcp['score'] / 60) * 100
            else:
                total_score = vcp['score'] * 0.6 + supply['score'] * 0.4
            
            analyzed_count += 1
            
            # ë””ë²„ê·¸ ë¡œê·¸: ìƒìœ„ ì ìˆ˜ ì¢…ëª© ë˜ëŠ” ì¼ë¶€ ì¢…ëª© ì¶œë ¥
            if total_score >= 40 or analyzed_count <= 5:
                log(f"  [{name}] VCP={vcp['score']}, Supply={supply['score']}, Total={total_score:.1f} (CR={vcp['contraction_ratio']})")
            
            # ìµœì†Œ ì ìˆ˜ í•„í„°ë§ (60ì  ê¸°ì¤€ ë³µêµ¬)
            if total_score < 60:
                continue
            
            current_price = ticker_prices['close'].iloc[-1]
            
            signals.append({
                'ticker': ticker,
                'name': name,
                'signal_date': target_date if target_date else datetime.now().strftime('%Y-%m-%d'),
                'market': market,
                'status': 'OPEN',
                'score': round(total_score, 1),
                'contraction_ratio': vcp['contraction_ratio'],
                'entry_price': int(current_price),
                'foreign_5d': supply['foreign_5d'],
                'inst_5d': supply['inst_5d'],
                'vcp_score': vcp['score'], # AI ë¶„ì„ìš© ì¶”ê°€ ì •ë³´
                'current_price': int(current_price)
            })
        
        log(f"ì´ {analyzed_count}ê°œ ì¢…ëª© ë¶„ì„ ì™„ë£Œ, {len(signals)}ê°œ ì‹œê·¸ë„ ê°ì§€")
        
        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬, ìµœëŒ€ 20ê°œ
        signals = sorted(signals, key=lambda x: x['score'], reverse=True)[:20]
        
        # AI ë¶„ì„ ì‹¤í–‰ (ì˜µì…˜)
        if run_ai and signals:
            try:
                log(f"[AI Analysis] ê°ì§€ëœ {len(signals)}ê°œ ì‹œê·¸ë„ì— ëŒ€í•´ AI ì •ë°€ ë¶„ì„ ìˆ˜í–‰...", "INFO")
                from engine.vcp_ai_analyzer import get_vcp_analyzer
                analyzer = get_vcp_analyzer()
                
                # ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•œ ë£¨í”„ ê°€ì ¸ì˜¤ê¸°
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                # ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰
                ai_results = loop.run_until_complete(analyzer.analyze_batch(signals))
                
                # ê²°ê³¼ ì €ì¥
                if ai_results:
                    date_str = signals[0]['signal_date'].replace('-', '')
                    
                    # 1. ai_analysis_results.jsonì— ì €ì¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                    ai_filename = f'ai_analysis_results_{date_str}.json'
                    ai_filepath = os.path.join(BASE_DIR, 'data', ai_filename)
                    
                    save_data = {
                        'generated_at': datetime.now().isoformat(),
                        'signal_date': signals[0]['signal_date'],
                        'signals': list(ai_results.values())
                    }
                    
                    with open(ai_filepath, 'w', encoding='utf-8') as f:
                        json.dump(save_data, f, ensure_ascii=False, indent=2)
                        
                    latest_path = os.path.join(BASE_DIR, 'data', 'ai_analysis_results.json')
                    with open(latest_path, 'w', encoding='utf-8') as f:
                         json.dump(save_data, f, ensure_ascii=False, indent=2)
                    
                    # 2. kr_ai_analysis.jsonì—ë„ ì €ì¥ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ í˜•ì‹)
                    # VCP ì‹œê·¸ë„ ì •ë³´ + AI ë¶„ì„ ê²°ê³¼ + ë‰´ìŠ¤ í†µí•©
                    kr_ai_signals = []
                    
                    # ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
                    news_collector = None
                    try:
                        from engine.collectors import EnhancedNewsCollector
                        from engine.config import app_config
                        news_collector = EnhancedNewsCollector(app_config)
                        log("[AI Analysis] ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ", "INFO")
                    except Exception as news_init_err:
                        log(f"[AI Analysis] ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {news_init_err}", "WARNING")
                    
                    for signal in signals:
                        ticker = signal.get('ticker', '')
                        name = signal.get('name', '')
                        ai_data = ai_results.get(ticker, {})
                        
                        # ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœëŒ€ 5ê°œ)
                        news_items = []
                        if news_collector:
                            try:
                                news_list = asyncio.get_event_loop().run_until_complete(
                                    news_collector.get_stock_news(ticker, limit=5, name=name)
                                )
                                for news in news_list:
                                    news_items.append({
                                        'title': getattr(news, 'title', str(news)),
                                        'url': getattr(news, 'url', ''),
                                        'source': getattr(news, 'source', 'Naver'),
                                        'date': getattr(news, 'date', '')
                                    })
                            except Exception as news_err:
                                log(f"[AI Analysis] {name} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {news_err}", "WARNING")
                        
                        kr_signal = {
                            'ticker': ticker,
                            'name': name,
                            'market': signal.get('market', 'KOSPI'),
                            'score': signal.get('score', 0),
                            'contraction_ratio': signal.get('contraction_ratio', 0),
                            'foreign_5d': signal.get('foreign_5d', 0),
                            'inst_5d': signal.get('inst_5d', 0),
                            'entry_price': signal.get('entry_price', 0),
                            'current_price': signal.get('current_price', signal.get('entry_price', 0)),
                            'return_pct': 0,
                            'vcp_score': signal.get('vcp_score', 0),
                            # AI ë¶„ì„ ê²°ê³¼ í†µí•©
                            'gemini_recommendation': ai_data.get('gemini_recommendation'),
                            'gpt_recommendation': ai_data.get('gpt_recommendation'),
                            'perplexity_recommendation': ai_data.get('perplexity_recommendation'),
                            # ë‰´ìŠ¤ ë°ì´í„° ì¶”ê°€
                            'news': news_items,
                        }
                        kr_ai_signals.append(kr_signal)
                    
                    # ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
                    market_indices = {}
                    try:
                        from pykrx import stock
                        today_str = datetime.now().strftime('%Y%m%d')
                        kospi = stock.get_index_ohlcv(today_str, today_str, "1001")  # KOSPI
                        kosdaq = stock.get_index_ohlcv(today_str, today_str, "2001")  # KOSDAQ
                        
                        if not kospi.empty:
                            market_indices['kospi'] = {
                                'value': float(kospi['ì¢…ê°€'].iloc[-1]) if len(kospi) > 0 else 0,
                                'change_pct': float(kospi['ë“±ë½ë¥ '].iloc[-1]) if len(kospi) > 0 and 'ë“±ë½ë¥ ' in kospi.columns else 0
                            }
                        if not kosdaq.empty:
                            market_indices['kosdaq'] = {
                                'value': float(kosdaq['ì¢…ê°€'].iloc[-1]) if len(kosdaq) > 0 else 0,
                                'change_pct': float(kosdaq['ë“±ë½ë¥ '].iloc[-1]) if len(kosdaq) > 0 and 'ë“±ë½ë¥ ' in kosdaq.columns else 0
                            }
                    except Exception as idx_e:
                        log(f"[AI Analysis] ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {idx_e}", "WARNING")
                    
                    kr_ai_data = {
                        'market_indices': market_indices,
                        'signals': kr_ai_signals,
                        'generated_at': datetime.now().isoformat(),
                        'signal_date': signals[0]['signal_date']
                    }
                    
                    kr_ai_path = os.path.join(BASE_DIR, 'data', 'kr_ai_analysis.json')
                    with open(kr_ai_path, 'w', encoding='utf-8') as f:
                        json.dump(kr_ai_data, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
                    
                    # ë‚ ì§œë³„ íˆìŠ¤í† ë¦¬ë„ ì €ì¥
                    kr_ai_history_path = os.path.join(BASE_DIR, 'data', f'kr_ai_analysis_{date_str}.json')
                    with open(kr_ai_history_path, 'w', encoding='utf-8') as f:
                        json.dump(kr_ai_data, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
                         
                    log(f"[AI Analysis] ë¶„ì„ ì™„ë£Œ ë° ì €ì¥: {ai_filename}, kr_ai_analysis.json", "SUCCESS")
                
            except Exception as e:
                log(f"[AI Analysis] ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "ERROR")
                import traceback
                traceback.print_exc()
        
        if signals:
            df_new = pd.DataFrame(signals)
            file_path = os.path.join(BASE_DIR, 'data', 'signals_log.csv')
            
            # ê¸°ì¡´ ë¡œê·¸ê°€ ìˆìœ¼ë©´ ë¡œë“œí•˜ì—¬ ë³‘í•© (Append & Deduplicate)
            if os.path.exists(file_path):
                try:
                    # íƒ€ì… ëª…ì‹œí•˜ì—¬ ë¡œë“œ (ì¤‘ë³µ ë°©ì§€ í•µì‹¬)
                    df_old = pd.read_csv(file_path, dtype={'ticker': str, 'signal_date': str})
                    df_old['ticker'] = df_old['ticker'].str.zfill(6)
                    
                    # ìƒˆ ë°ì´í„° í¬ë§· í†µì¼
                    df_new['ticker'] = df_new['ticker'].astype(str).str.zfill(6)
                    df_new['signal_date'] = df_new['signal_date'].astype(str)

                    # [ìˆ˜ì •] í•´ë‹¹ ë‚ ì§œì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì¬ì‹¤í–‰ ì‹œ ì¤‘ë³µ ë°©ì§€)
                    current_date = str(df_new['signal_date'].iloc[0])
                    df_old = df_old[df_old['signal_date'] != current_date]

                    # ë³‘í•©
                    if df_old.empty and df_new.empty:
                         df_combined = pd.DataFrame()
                    elif df_old.empty:
                         df_combined = df_new
                    elif df_new.empty:
                         df_combined = df_old
                    else:
                         df_combined = pd.concat([df_old, df_new])
                         
                    # ì¤‘ë³µ ì œê±° (ì•ˆì „ì¥ì¹˜)
                    if not df_combined.empty:
                        df_combined = df_combined.drop_duplicates(subset=['signal_date', 'ticker'], keep='last')
                        # ì •ë ¬ (ìµœì‹  ë‚ ì§œ ìš°ì„ , ì ìˆ˜ ë†’ì€ ìˆœ)
                        df_combined = df_combined.sort_values(by=['signal_date', 'score'], ascending=[False, False])
                    
                    df_combined.to_csv(file_path, index=False, encoding='utf-8-sig')
                    # í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ë°˜í™˜ (common.py ì—°ë™ìš©) -> init_data.pyì—ì„œëŠ” True ë°˜í™˜í•´ì•¼ í•¨
                    return True
                except Exception as e:
                    log(f"ê¸°ì¡´ ë¡œê·¸ ë³‘í•© ì‹¤íŒ¨: {e}, ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤(ë®ì–´ì“°ê¸°).", "WARNING")
                    df_new.to_csv(file_path, index=False, encoding='utf-8-sig')
                    return True
            else:
                df_new.to_csv(file_path, index=False, encoding='utf-8-sig')
                return True
                
            log(f"VCP ì‹œê·¸ë„ ë¶„ì„ ì™„ë£Œ: {len(signals)} ì¢…ëª© ê°ì§€ (ëˆ„ì  ì €ì¥)", "SUCCESS")
            return True
        else:
            log("VCP ì¡°ê±´ ì¶©ì¡± ì¢…ëª© ì—†ìŒ", "WARNING")
            # ë¹ˆ ê²°ê³¼ íŒŒì¼ ìƒì„± (ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì•ˆí•¨)
            df = pd.DataFrame(columns=['ticker', 'name', 'signal_date', 'market', 'status', 'score', 'contraction_ratio', 'entry_price', 'foreign_5d', 'inst_5d'])
            file_path = os.path.join(BASE_DIR, 'data', 'signals_log.csv')
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            log("VCP ì¡°ê±´ ì¶©ì¡± ì¢…ëª© ì—†ìŒ - ë¹ˆ ê²°ê³¼ ì €ì¥", "INFO")
            return True
            
    except Exception as e:
        log(f"VCP ë¶„ì„ ì‹¤íŒ¨: {e}", "WARNING")
        # ë¹ˆ ê²°ê³¼ íŒŒì¼ ìƒì„± (ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì•ˆí•¨)
        df = pd.DataFrame(columns=['ticker', 'name', 'signal_date', 'market', 'status', 'score', 'contraction_ratio', 'entry_price', 'foreign_5d', 'inst_5d'])
        file_path = os.path.join(BASE_DIR, 'data', 'signals_log.csv')
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        log("VCP ë¶„ì„ ì˜¤ë¥˜ - ë¹ˆ ê²°ê³¼ ì €ì¥", "INFO")
        return True



def calculate_advanced_score(ticker: str, prices_df: pd.DataFrame, inst_df: pd.DataFrame) -> dict:
    """
    ì¢…ê°€ë² íŒ… ì‹œìŠ¤í…œ ê³ ë„í™” (Advanced Closing Bet)
    ê¸°ë³¸ í•„í„°: ìµœì†Œí•œì˜ ê¸°ì¤€ë§Œ ì ìš© (í•„í„°ë§ì€ í”„ë¡ íŠ¸ì—”ë“œ/APIì—ì„œ ì²˜ë¦¬)
    """
    try:
        ticker_prices = prices_df[prices_df['ticker'].astype(str).str.zfill(6) == ticker].copy()
        if len(ticker_prices) < 20:
            return {'total': 0, 'passed_filter': False}
        
        ticker_prices = ticker_prices.sort_values('date')
        current = ticker_prices.iloc[-1]
        prev = ticker_prices.iloc[-2]
        
        # --- ìµœì†Œí•œì˜ ë°ì´í„° ìœ íš¨ì„± ì²´í¬ ---
        trading_value = current['volume'] * current['close']
        volume_ratio = current['volume'] / prev['volume'] if prev['volume'] > 0 else 0
        
        # ë‹¹ì¼ ë“±ë½ë¥  ê³„ì‚°
        prev_close = prev['close']
        change_pct = ((current['close'] - prev_close) / prev_close * 100) if prev_close > 0 else 0
        
        # ìµœì†Œ ê¸°ì¤€: ê±°ë˜ëŒ€ê¸ˆ 300ì–µ ë¯¸ë§Œ ì œì™¸ (2026-01-31 ì—…ë°ì´íŠ¸)
        if trading_value < 30_000_000_000:  # 300ì–µ
            return {'total': 0, 'passed_filter': False, 'reason': 'ê±°ë˜ëŒ€ê¸ˆ ê³¼ì†Œ (300ì–µ ë¯¸ë§Œ)'}
        
        if change_pct <= 0:
             return {'total': 0, 'passed_filter': False, 'reason': 'ìƒìŠ¹ë¥  ë¯¸ë‹¬'}
        
        # ì¢…ê°€ >= ë‹¹ì¼ê³  * 0.9 ì²´í¬
        day_high = current['high']
        close_ratio = current['close'] / day_high if day_high > 0 else 0

        # ì ìˆ˜ ìƒì„¸ ë‚´ì—­ ì´ˆê¸°í™”
        details = {
            'news': 0,
            'volume': 0,
            'chart': 0,
            'candle': 0,
            'consolidation': 0,
            'supply': 0,
            'rise_pct': round(change_pct, 2),
            'volume_ratio': round(volume_ratio, 2)
        }
        
        base_score = 0
        
        # 1. ë‰´ìŠ¤ & ëª¨ë©˜í…€ (3ì ) - ê±°ë˜ëŒ€ê¸ˆ ê¸°ë°˜ í´ë°±
        # ë‰´ìŠ¤ëŠ” ë³„ë„ APIê°€ ì—†ìœ¼ë¯€ë¡œ ê±°ë˜ëŒ€ê¸ˆ ê·œëª¨ë¡œ ëª¨ë©˜í…€ ì¶”ì •
        if trading_value > 500_000_000_000: 
            details['news'] = 3
        elif trading_value > 100_000_000_000: 
            details['news'] = 2
        else: 
            details['news'] = 1
        base_score += details['news']
        
        # 2. ê±°ë˜ëŒ€ê¸ˆ/ê±°ë˜ëŸ‰ í­ë°œ (3ì )
        # 3000ì–µ ì´ìƒì´ë©´ ë§Œì 
        if trading_value >= 300_000_000_000: 
            details['volume'] = 3
        elif trading_value >= 100_000_000_000: 
            details['volume'] = 2
        else: 
            details['volume'] = 1
        base_score += details['volume']
        
        # 3. ì°¨íŠ¸ ìœ„ì¹˜ (2ì )
        high_20d = ticker_prices.tail(20)['high'].max()
        if current['close'] >= high_20d * 0.98: 
            details['chart'] = 2
        elif current['close'] > ticker_prices['close'].tail(20).mean(): 
            details['chart'] = 1
        base_score += details['chart']
        
        # 4. ìˆ˜ê¸‰ (2ì )
        inst_data = inst_df[inst_df['ticker'].astype(str).str.zfill(6) == ticker]
        if not inst_data.empty:
            recent_inst = inst_data.tail(5)
            f_buy = recent_inst['foreign_buy'].sum()
            i_buy = recent_inst['inst_buy'].sum()
            if f_buy > 0 and i_buy > 0: 
                details['supply'] = 2
            elif f_buy > 0 or i_buy > 0: 
                details['supply'] = 1
        base_score += details['supply']
        
        # 5. ìº”ë“¤/ì¡°ì • (2ì )
        if current['close'] > current['open']: 
            details['candle'] = 1
        base_score += details['candle']

        recent_range = (ticker_prices.tail(5)['high'] - ticker_prices.tail(5)['low']).mean()
        avg_range = (ticker_prices.tail(20)['high'] - ticker_prices.tail(20)['low']).mean()
        if recent_range < avg_range * 0.8: # ë³€ë™ì„± ì¶•ì†Œ
            details['consolidation'] = 1
        base_score += details['consolidation']
        
        # --- ê°€ì‚°ì  (Bonus Score) ---
        bonus = 0
        
        # 1. ê±°ë˜ëŸ‰ ê¸‰ì¦ (Volume Surge) - detailsì— ë°˜ì˜í•˜ê¸°ì—ëŠ” ì• ë§¤í•˜ë¯€ë¡œ ì´ì ì—ë§Œ ê°€ì‚°
        if volume_ratio >= 10: bonus += 4
        elif volume_ratio >= 5: bonus += 3
        elif volume_ratio >= 3: bonus += 2
        elif volume_ratio >= 2: bonus += 1
        
        # 2. ì¥ëŒ€ì–‘ë´‰ (Long Body)
        pct = change_pct
        if pct >= 25: bonus += 5
        elif pct >= 20: bonus += 4
        elif pct >= 15: bonus += 3
        elif pct >= 10: bonus += 2
        elif pct >= 5: bonus += 1
        
        score_total = base_score + bonus
        
        # ìˆ˜ê¸‰ ë°ì´í„° (ì™¸ì¸+ê¸°ê´€ ë™ì‹œ ìˆœë§¤ìˆ˜ ì²´í¬)
        inst_data = inst_df[inst_df['ticker'].astype(str).str.zfill(6) == ticker]
        foreign_positive = False
        inst_positive = False
        foreign_net_buy = 0
        inst_net_buy = 0
        
        if not inst_data.empty:
            recent_inst = inst_data.tail(5)
            foreign_net_buy = int(recent_inst['foreign_buy'].sum())
            inst_net_buy = int(recent_inst['inst_buy'].sum())
            foreign_positive = foreign_net_buy > 0
            inst_positive = inst_net_buy > 0
        
        return {
            'base': base_score,
            'bonus': bonus, 
            'total': score_total, 
            'passed_filter': True,
            'details': details,
            'volume_ratio': volume_ratio,
            'close_ratio': close_ratio,
            'foreign_positive': foreign_positive,
            'inst_positive': inst_positive,
            'foreign_net_buy': foreign_net_buy,
            'inst_net_buy': inst_net_buy,
            'rise_pct': round(change_pct, 2),
            'trading_value': trading_value
        }

    except Exception as e:
        return {'total': 0, 'passed_filter': False, 'reason': str(e)}


def assign_grade(score_data: dict) -> str:
    """
    ë“±ê¸‰ ë¶„ë¥˜ (2026-01-31 ìˆ˜ì •)
    
    Sê¸‰: 1ì¡°ì›+ AND 10%+ ìƒìŠ¹ AND ì™¸ì¸+ê¸°ê´€ ë™ë°˜ AND ê±°ë˜ëŸ‰ 5ë°°
    Aê¸‰: 5000ì–µ+ AND 5%+ ìƒìŠ¹ AND (ì™¸ì¸ OR ê¸°ê´€) AND ê±°ë˜ëŸ‰ 3ë°°
    Bê¸‰: 1000ì–µ+ AND 4%+ ìƒìŠ¹ AND (ì™¸ì¸ OR ê¸°ê´€) AND ê±°ë˜ëŸ‰ 2ë°°
    Cê¸‰: 500ì–µ+ AND 5%+ ìƒìŠ¹ AND ì ìˆ˜ 8ì  ì´ìƒ AND ê±°ë˜ëŸ‰ 3ë°°
    Dê¸‰: 500ì–µ+ AND 4%+ ìƒìŠ¹ AND ì ìˆ˜ 6ì  ì´ìƒ
    """
    trading_value = score_data.get('trading_value', 0)
    volume_ratio = score_data.get('volume_ratio', 0)
    close_ratio = score_data.get('close_ratio', 0)
    foreign_positive = score_data.get('foreign_positive', False)
    inst_positive = score_data.get('inst_positive', False)
    rise_pct = score_data.get('rise_pct', 0)
    
    # ê¸°ë³¸ ì¡°ê±´: ìƒìŠ¹ ì¢…ëª©ë§Œ
    if rise_pct <= 0:
        return None
    
    # ì™¸ì¸+ê¸°ê´€ ë™ë°˜ ì²´í¬
    both_positive = foreign_positive and inst_positive
    either_positive = foreign_positive or inst_positive
    
    # Sê¸‰: 1ì¡° ì› ì´ìƒ AND 10% ì´ìƒ ìƒìŠ¹ AND ì™¸ì¸+ê¸°ê´€ ë™ë°˜ ìˆœë§¤ìˆ˜ AND ê±°ë˜ëŸ‰ 5ë°°
    if trading_value >= 1_000_000_000_000 and rise_pct >= 10.0 and both_positive and volume_ratio >= 5.0:
        return 'S'
    
    # Aê¸‰: 5,000ì–µ ì› ì´ìƒ AND 5% ì´ìƒ ìƒìŠ¹ AND (ì™¸ì¸ or ê¸°ê´€) AND ê±°ë˜ëŸ‰ 3ë°°
    if trading_value >= 500_000_000_000 and rise_pct >= 5.0:
        if either_positive and volume_ratio >= 3.0:
             return 'A'

    # Bê¸‰: 1,000ì–µ ì› ì´ìƒ AND 4% ì´ìƒ ìƒìŠ¹ AND (ì™¸ì¸ or ê¸°ê´€) AND ê±°ë˜ëŸ‰ 2ë°°
    if trading_value >= 100_000_000_000 and rise_pct >= 4.0:
        if volume_ratio >= 2.0 and either_positive:
            return 'B'
    
    # Cê¸‰: 500ì–µ ì´ìƒ AND 5% ì´ìƒ ìƒìŠ¹ AND ì™¸ì¸+ê¸°ê´€ ë™ë°˜ AND ê±°ë˜ëŸ‰ 3ë°°
    if trading_value >= 50_000_000_000 and rise_pct >= 5.0 and both_positive and volume_ratio >= 3.0:
        return 'C'
        
    # Dê¸‰: 500ì–µ ì´ìƒ AND 4% ì´ìƒ ìƒìŠ¹ AND (ì™¸ì¸ or ê¸°ê´€) AND ê±°ë˜ëŸ‰ 2ë°°
    if trading_value >= 50_000_000_000 and rise_pct >= 4.0 and volume_ratio >= 2.0:
        return 'D'
    
    # ê·¸ ì™¸ëŠ” ë“±ê¸‰ ì—†ìŒ
    return None 

def get_themes_by_sector(sector: str, name: str) -> list:
    """ì—…ì¢… ë° ì¢…ëª©ëª… ê¸°ë°˜ ë‹¨ìˆœ í…Œë§ˆ ë§¤í•‘"""
    themes = []
    if not sector:
        return []
    
    # Simple Keywords Mapping
    if 'ë°˜ë„ì²´' in sector or 'ì „ê¸°ì „ì' in sector:
        themes.append('ë°˜ë„ì²´')
        if 'ì‚¼ì„±' in name or 'SK' in name:
            themes.append('HBM')
            themes.append('AI')
    elif 'ì œì•½' in sector or 'ë°”ì´ì˜¤' in sector:
        themes.append('ë°”ì´ì˜¤')
        themes.append('ì‹ ì•½ê°œë°œ')
    elif 'ìë™ì°¨' in sector:
        themes.append('ìë™ì°¨')
        themes.append('ì „ê¸°ì°¨')
    elif 'ê¸ˆìœµ' in sector:
        themes.append('ê¸ˆìœµ')
        themes.append('ì €PBR')
        
    return themes


def get_expert_advice(grade: str, score: int, trading_value: int, market: str) -> dict:
    """ì ìˆ˜, ë“±ê¸‰, ê±°ë˜ëŒ€ê¸ˆ ê¸°ë°˜ ì „ë¬¸ê°€ ì¡°ì–¸ ìƒì„¸ ìƒì„±"""
    advice = {
        "trading_tip": "15:10~15:30 ì‚¬ì´ ë¶„ë´‰ìƒ ëˆŒë¦¼ëª© ì§€ì§€(20ì„ ) í™•ì¸ í›„ ì¢…ê°€ ë¶€ê·¼ ì§„ì….",
        "selling_strategy": "ìµì¼ ì‹œì´ˆ 30ë¶„ ë‚´ 3% ì´ìƒ ìƒìŠ¹ ì‹œ 50% ë¶„í•  ìµì ˆ, ë‚˜ë¨¸ì§€ëŠ” ë³¸ì ˆê°€ ìœ„í˜‘ ì‹œ ì „ëŸ‰ ë§¤ë„ (íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘).",
        "market_context": "ìˆ˜ê¸‰ì´ ê°•í•˜ê²Œ ë“¤ì–´ì˜¨ ì¢…ëª©ì…ë‹ˆë‹¤. ê°­ìƒìŠ¹ ì¶œë°œ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
    }
    
    # 1. ë“±ê¸‰ë³„ ì „ëµ ì°¨ë³„í™”
    if grade == 'S':
        advice["market_context"] = "ğŸš€ ê°•ë ¥í•œ ì£¼ë„ì£¼ (Së“±ê¸‰). ì½”ìŠ¤í”¼ 5000 ëŒíŒŒì¥ì²˜ëŸ¼ ê³µê²©ì ìœ¼ë¡œ ë¹„ì¤‘ì„ ì‹¤ì–´ë„ ì¢‹ì€ êµ¬ê°„ì…ë‹ˆë‹¤."
        advice["selling_strategy"] = "ìƒìŠ¹ íƒ„ë ¥ì´ ê°•í•˜ë¯€ë¡œ 5%~10% ì´ìƒ ìŠˆíŒ… ì‹œ 50% ìµì ˆ, ë‚˜ë¨¸ì§€ëŠ” 3ì¼ì„ /5ì¼ì„  ì´íƒˆê¹Œì§€ í™€ë”©."
    elif grade == 'A':
        advice["market_context"] = "ìˆ˜ê¸‰ê³¼ ì°¨íŠ¸ê°€ ìš°ìˆ˜í•œ Aë“±ê¸‰ ì¢…ëª©ì…ë‹ˆë‹¤. ëˆŒë¦¼ ì‹œ ì ê·¹ ë§¤ìˆ˜ ìœ íš¨."
    else: # B, C
        advice["trading_tip"] = "ìƒìŠ¹íƒ„ë ¥ì´ ë‹¤ì†Œ ì•½í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì² ì €íˆ ì§€ì§€ì„  ê·¼ì²˜ì—ì„œë§Œ ì§„ì…í•˜ì„¸ìš”. ì¶”ê²©ë§¤ìˆ˜ ê¸ˆì§€."
        advice["selling_strategy"] = "ì§§ê²Œ 3% ë‚´ì™¸ì—ì„œ ì „ëŸ‰ ìµì ˆí•˜ê±°ë‚˜, ë³¸ì ˆ ë¡œìŠ¤ì»·ì„ íƒ€ì´íŠ¸í•˜ê²Œ ì¡ìœ¼ì„¸ìš”."

    # 2. ê±°ë˜ëŒ€ê¸ˆ ê·œëª¨ë³„ íŒ (ì‹œì¥ ì ì‘)
    if market == 'KOSPI':
        if trading_value >= 100_000_000_000: # 1000ì–µ ì´ìƒ
            advice["market_context"] += " (ì½”ìŠ¤í”¼ ëŒ€í˜•ì£¼ íŠ¹ì„±: ë¬´ê±°ìš´ ë§Œí¼ ì¶”ì„¸ ì§€ì†ë ¥ì´ ì¢‹ìŠµë‹ˆë‹¤)"
        else:
            advice["market_context"] += " (ì½”ìŠ¤í”¼ ì¤‘ì†Œí˜•: ë³€ë™ì„±ì— ìœ ì˜í•˜ì„¸ìš”)"
    elif market == 'KOSDAQ':
        if trading_value >= 500_000_000_000: # 500ì–µ -> 5000 (User said 200~500, but logic usually higher is better)
             advice["market_context"] += " (ì½”ìŠ¤ë‹¥ ì£¼ë„ì£¼: ë³€ë™ì„±ì´ ë§¤ìš° í½ë‹ˆë‹¤)"
        elif trading_value >= 20_000_000_000:
             advice["market_context"] += " (ì½”ìŠ¤ë‹¥ ì•Œì§œ ì¤‘ì†Œí˜•ì£¼: 200~500ì–µ êµ¬ê°„)"

    # 3. ì¶”ê°€ ë§¤ìˆ˜ ê°€ì´ë“œ
    if score >= 15: # ë§¤ìš° ë†’ì€ ì ìˆ˜
        advice["buy_strategy"] = "í™•ì‹ ì´ ë“œëŠ” ìë¦¬ì…ë‹ˆë‹¤. ë¹„ì¤‘ 50% ì¶”ê°€ ë§¤ìˆ˜ ê³ ë ¤ ê°€ëŠ¥ (ë‹¨, ë¶„í• ë¡œ ì ‘ê·¼)."
    else:
        advice["buy_strategy"] = "ë¬´ë¦¬í•œ ì¶”ê°€ ë§¤ìˆ˜ëŠ” ìì œí•˜ê³ , 1ì°¨ ì§„ì… ë¬¼ëŸ‰ë§Œ ìš´ì˜í•˜ì„¸ìš”."

    return advice


def create_jongga_v2_latest():
    """ì¢…ê°€ë² íŒ… V2 ìµœì‹  ê²°ê³¼ ìƒì„± - ê³ ë„í™”ëœ ë¡œì§ ì ìš©"""
    log("ì¢…ê°€ë² íŒ… V2 ë¶„ì„ ì¤‘ (Advanced System)...")
    try:
        # ë°ì´í„° ë¡œë“œ
        prices_file = os.path.join(BASE_DIR, 'data', 'daily_prices.csv')
        inst_file = os.path.join(BASE_DIR, 'data', 'all_institutional_trend_data.csv')
        stocks_file = os.path.join(BASE_DIR, 'data', 'korean_stocks_list.csv')
        
        if not all(os.path.exists(f) for f in [prices_file, inst_file, stocks_file]):
            raise Exception("í•„ìš”í•œ ë°ì´í„° íŒŒì¼ ì—†ìŒ")
        
        prices_df = pd.read_csv(prices_file)
        inst_df = pd.read_csv(inst_file)
        stocks_df = pd.read_csv(stocks_file)
        
        signals = []
        
        for _, row in stocks_df.iterrows():
            ticker = str(row['ticker']).zfill(6)
            name = row['name']
            
            # ê³ ë„í™”ëœ í‰ê°€ ë¡œì§ ìˆ˜í–‰
            score_data = calculate_advanced_score(ticker, prices_df, inst_df)
            
            if not score_data['passed_filter']:
                continue
                
            # ìµœì†Œ 10ì (ê¸°ë³¸+ë³´ë„ˆìŠ¤ í¬í•¨) ì´ìƒë§Œ í•„í„°ë§ (í•„í„°ê°€ ê°•ë ¥í•˜ë¯€ë¡œ ì ìˆ˜ ì»·ì€ ë‚®ì¶¤)
            if score_data['total'] < 10:
                continue
            
            ticker_prices = prices_df[prices_df['ticker'].astype(str).str.zfill(6) == ticker]
            current = ticker_prices.iloc[-1]
            current_price = int(current['close'])
            trading_value = int(current['volume'] * current['close'])
            
            # ë“±ê¸‰ ë¶„ë¥˜ - ìƒˆë¡œìš´ ê¸°ì¤€ (2026-01-31)
            grade = assign_grade(score_data)
            
            # ë“±ê¸‰ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ì¡°ê±´ ë¯¸ì¶©ì¡±)
            if grade is None:
                continue

            log(f"  [Jongga V2 Catch] {name} ({ticker}) - Grade: {grade}, Score: {score_data['total']}, TradingVal: {trading_value//100000000}ì–µ")
            
            # ì „ë¬¸ê°€ ì¡°ì–¸ ìƒì„±
            advice = get_expert_advice(grade, score_data['total'], trading_value, row['market'])
            
            # ë¯¸ë‹ˆ ì°¨íŠ¸ ë°ì´í„° (ìµœê·¼ 10ì¼)
            mini_chart = ticker_prices.tail(10)[['date', 'open', 'high', 'low', 'close', 'volume']].to_dict(orient='records')
            
            # ë§¤ìˆ˜/ë§¤ë„/ì†ì ˆ ê°€ê²© ê³„ì‚° (í˜„ì¬ê°€ ê¸°ì¤€)
            buy_price = current_price
            target_price_1 = int(current_price * 1.025)  # +2.5% ê³µê²© ìµì ˆ
            target_price_2 = int(current_price * 1.05)   # +5% ìˆ˜ê¸‰ ê°•ì„¸ ìµì ˆ
            stop_price = int(current_price * 0.97)       # -3% ì†ì ˆ
            
            signals.append({
                "stock_code": ticker,
                "stock_name": name,
                "market": row['market'],
                "grade": grade,
                "total_score": score_data['total'],
                "score_details": score_data,
                "current_price": current_price,
                "trading_value": trading_value,
                "change_pct": float(score_data.get('rise_pct', 0)),
                "volume_ratio": score_data.get('volume_ratio', 0),
                "advice": advice,
                "mini_chart": mini_chart,
                
                # ë§¤ìˆ˜/ë§¤ë„/ì†ì ˆ ì „ëµ ê°€ê²©
                "buy_price": buy_price,
                "target_price_1": target_price_1,  # +2.5%
                "target_price_2": target_price_2,  # +5%
                "stop_price": stop_price,          # -3%
                
                # ê¸°ì¡´ í•„ë“œ í˜¸í™˜ì„± ìœ ì§€
                "score": {
                    "total": score_data['base'],
                    "news": score_data['details'].get('news', 0),
                    "volume": score_data['details'].get('volume', 0),
                    "chart": score_data['details'].get('chart', 0),
                    "supply": score_data['details'].get('supply', 0),
                    "timing": score_data['details'].get('consolidation', 0),
                    "candle": score_data['details'].get('candle', 0),
                    "llm_reason": f"ì¢…í•© ì ìˆ˜ {score_data['total']}ì  (ê¸°ë³¸ {score_data['base']} + ë³´ë„ˆìŠ¤ {score_data['bonus']})"
                },
                "checklist": {
                    "has_news": True,
                    "is_new_high": score_data.get('close_ratio', 0) >= 0.9,
                    "supply_positive": score_data.get('foreign_positive', False) and score_data.get('inst_positive', False)
                },
                "entry_price": buy_price,
                "foreign_net_buy": score_data.get('foreign_net_buy', 0),
                "inst_net_buy": score_data.get('inst_net_buy', 0),
                "themes": get_themes_by_sector(row.get('sector', ''), name), 
                "news_items": [],
                # Default AI Evaluation (Rule-based Fallback)
                "ai_evaluation": {
                    "action": "BUY" if grade in ['S', 'A'] else "HOLD",
                    "confidence": score_data['total'] * 5 + (20 if grade == 'S' else 10 if grade == 'A' else 0),
                    "model": "Rule-based (Pending AI)"
                }
            })
        
        # ë“±ê¸‰ ìš°ì„ , ì´ì  ìˆœ ì •ë ¬
        grade_order = {'S': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4}
        signals = sorted(signals, key=lambda x: (grade_order.get(x['grade'], 9), -x['total_score']))[:10]
        
        # --- Gemini 3.0 Analysis Integration ---
        # signalsê°€ ì—†ìœ¼ë©´ Gemini ë¶„ì„ ìŠ¤í‚µ (API í• ë‹¹ëŸ‰ ì ˆì•½)
        if not signals:
            log("ë¶„ì„ ëŒ€ìƒ ì‹œê·¸ë„ ì—†ìŒ - Gemini ë¶„ì„ ìŠ¤í‚µ", "WARNING")
        else:
            # --- Gemini 3.0 Analysis Integration ---
            try:
                async def run_batch_analysis(target_signals):
                    log(f"Gemini 3.0 Analysis ì‹œì‘ ({len(target_signals)} ì¢…ëª©)...")
                    news_collector = EnhancedNewsCollector(config)
                    llm_analyzer = LLMAnalyzer()
                    market_gate = MarketGate()
                    
                    # 1. Market Status
                    market_status = market_gate.analyze()

                    # 2. News Collection & Preparation
                    items_for_llm = []
                    
                    async with news_collector:
                        for signal in target_signals:
                            code = signal['stock_code']
                            name = signal['stock_name']
                            
                            # ë‰´ìŠ¤ ìˆ˜ì§‘
                            news_items = await news_collector.get_stock_news(code, 3, name)
                            
                            # LLM Input êµ¬ì„±
                            items_for_llm.append({
                                'stock': signal, 
                                'news': news_items,
                                'supply': None 
                            })
                            
                            # UIìš© ë‰´ìŠ¤ ì €ì¥
                            signal['news_items'] = [{
                                "title": n.title,
                                "url": n.url,
                                "published_at": n.published_at.isoformat() if n.published_at else "",
                                "source": n.source
                            } for n in news_items]
                    
                    # 3. Batch LLM Execution (Chunking + Parallel)
                    if items_for_llm:
                        # ì²­í‚¹ ì„¤ì •
                        chunk_size = app_config.ANALYSIS_LLM_CHUNK_SIZE
                        concurrency = app_config.ANALYSIS_LLM_CONCURRENCY
                        chunks = [items_for_llm[i:i + chunk_size] for i in range(0, len(items_for_llm), chunk_size)]
                        
                        log(f"  -> {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í•  (ì²­í¬ë‹¹ {chunk_size}ì¢…ëª©, ë™ì‹œ {concurrency}ê°œ)")
                        
                        # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ Semaphore
                        semaphore = asyncio.Semaphore(concurrency)
                        
                        async def process_chunk(chunk_idx, chunk_data):
                            async with semaphore:
                                try:
                                    result = await llm_analyzer.analyze_news_batch(chunk_data, market_status)
                                    log(f"  -> ì²­í¬ {chunk_idx + 1}/{len(chunks)} ì™„ë£Œ")
                                    return result
                                except Exception as e:
                                    log(f"  -> ì²­í¬ {chunk_idx + 1} ì˜¤ë¥˜: {e}", "ERROR")
                                    return {}
                        
                        # ëª¨ë“  ì²­í¬ ë³‘ë ¬ ì‹¤í–‰
                        tasks = [process_chunk(i, chunk) for i, chunk in enumerate(chunks)]
                        chunk_results = await asyncio.gather(*tasks)
                        
                        # ê²°ê³¼ ë³‘í•©
                        results_map = {}
                        for res in chunk_results:
                            if res:
                                results_map.update(res)
                        
                        # 4. Merge Results
                        for signal in target_signals:
                            name = signal['stock_name']
                            if name in results_map:
                                llm_res = results_map[name]
                                if llm_res.get('reason'):
                                    signal['score']['llm_reason'] = llm_res.get('reason')
                                
                                # AI Recommendation Mapping (UI í‘œì‹œìš©)
                                # Providerì— ìƒê´€ì—†ì´ UIì˜ ë‘ ì»¬ëŸ¼ ëª¨ë‘ì— í‘œì‹œë˜ë„ë¡ ì„¤ì • (ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜)
                                recommendation = {
                                    "action": llm_res.get('action', 'HOLD'),
                                    "confidence": llm_res.get('confidence', 0),
                                    "reason": llm_res.get('reason', ''),
                                    "model": llm_res.get('model', 'Unknown')
                                }
                                signal['gemini_recommendation'] = recommendation
                                signal['gpt_recommendation'] = recommendation
                                signal['ai_evaluation'] = recommendation
                                    
                                log(f"  -> {name}: AI ë¶„ì„ ì™„ë£Œ ({recommendation['action']})")

                # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                try:
                    loop = asyncio.get_running_loop()
                except RuntimeError:
                    loop = None
                
                if loop and loop.is_running():
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as pool:
                        pool.submit(asyncio.run, run_batch_analysis(signals)).result()
                else:
                    asyncio.run(run_batch_analysis(signals))
                        
            except Exception as e:
                log(f"Gemini ë¶„ì„ ë‹¨ê³„ ì¤‘ ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {e}", "ERROR")

        # ---------------------------------------
        
        # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ ë‚ ì§œë¡œ ì„¤ì • (ë°ì´í„° ì •í•©ì„±)
        now = datetime.now()
        target_date = now
        if now.weekday() == 5: # Sat
            target_date = now - timedelta(days=1)
        elif now.weekday() == 6: # Sun
            target_date = now - timedelta(days=2)
            
        result = {
            'date': target_date.strftime('%Y-%m-%d'),
            'total_candidates': len(stocks_df),
            'filtered_count': len(signals),
            'signals': signals,
            'updated_at': datetime.now().isoformat()
        }
        
        file_path = os.path.join(BASE_DIR, 'data', 'jongga_v2_latest.json')
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
            
        log(f"ì¢…ê°€ë² íŒ… V2 ê³ ë„í™” ë¶„ì„ ì™„ë£Œ: {len(signals)} ì¢…ëª©", "SUCCESS")
        return True
            
    except Exception as e:
        log(f"ì¢…ê°€ë² íŒ… ë¶„ì„ ì‹¤íŒ¨: {e}", "ERROR")
        return False


def create_market_gate(target_date=None):
    """Market Gate ë°ì´í„° ìƒì„± (8ê°œ ì„¹í„°, KOSPI/KOSDAQ ì§€ìˆ˜ í¬í•¨) - ì‹¤ì‹œê°„ ë°ì´í„°"""
    log("Market Gate ë°ì´í„° ìƒì„± ì¤‘...")
    try:
        # ì‹¤ì‹œê°„ ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘
        indices = get_market_indices()
        kospi = indices['kospi']
        kosdaq = indices['kosdaq']
        
        # Market Gate ì ìˆ˜ ê³„ì‚° (KOSPI ë“±ë½ë¥  ê¸°ë°˜ ì„¸ë¶„í™”)
        change = kospi['change_pct']
        
        if change >= 2.0:
            gate_status = 'GREEN'
            gate_label = 'VERY BULLISH'
            gate_score = 90
        elif change >= 1.0:
            gate_status = 'GREEN'
            gate_label = 'BULLISH'
            gate_score = 75
        elif change >= 0.5:
            gate_status = 'YELLOW'
            gate_label = 'SLIGHTLY BULLISH'
            gate_score = 60
        elif change >= 0:
            gate_status = 'YELLOW'
            gate_label = 'NEUTRAL'
            gate_score = 50
        elif change >= -0.5:
            gate_status = 'YELLOW'
            gate_label = 'SLIGHTLY BEARISH'
            gate_score = 40
        elif change >= -1.0:
            gate_status = 'RED'
            gate_label = 'BEARISH'
            gate_score = 25
        else:
            gate_status = 'RED'
            gate_label = 'VERY BEARISH'
            gate_score = 10
        
        gate_data = {
            'status': gate_status,
            'score': gate_score,
            'label': gate_label,
            'reasons': [
                f"KOSPI {kospi['change_pct']:+.2f}% ë³€ë™",
                'ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì§€ì†',
                'ë°˜ë„ì²´ ì„¹í„° ê°•ì„¸ ì§€ì†'
            ],
            'sectors': get_sector_indices(),  # ì‹¤ì œ ì„¹í„° ë°ì´í„° ì‚¬ìš©
            'indices': {
                'kospi': {'value': kospi['value'], 'change_pct': kospi['change_pct']},
                'kosdaq': {'value': kosdaq['value'], 'change_pct': kosdaq['change_pct']}
            },
            'commodities': {
                'gold': indices.get('kr_gold', {'value': 0, 'change_pct': 0}),
                'silver': indices.get('kr_silver', {'value': 0, 'change_pct': 0}),
                'us_gold': indices.get('us_gold', {'value': 0, 'change_pct': 0}),
                'us_silver': indices.get('us_silver', {'value': 0, 'change_pct': 0})
            },
            'global_indices': {
                'sp500': indices.get('sp500', {'value': 0, 'change_pct': 0}),
                'nasdaq': indices.get('nasdaq', {'value': 0, 'change_pct': 0})
            },
            'crypto': {
                'btc': indices.get('btc', {'value': 0, 'change_pct': 0}),
                'eth': indices.get('eth', {'value': 0, 'change_pct': 0}),
                'xrp': indices.get('xrp', {'value': 0, 'change_pct': 0})
            },
            'metrics': {
                'kospi': kospi['value'],
                'kospi_ma20': kospi['value'] * 0.98,  # ê·¼ì‚¬ê°’
                'kospi_ma60': kospi['value'] * 0.96,  # ê·¼ì‚¬ê°’
                'kosdaq': kosdaq['value'],
                'kosdaq_ma20': kosdaq['value'] * 0.98,
                'usd_krw': 1345.5,
                'foreign_net_total': 1200000000000,
                'rsi': 62.5
            },
            'updated_at': datetime.now().isoformat()
        }

        file_path = os.path.join(BASE_DIR, 'data', 'market_gate.json')
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(gate_data, f, indent=2, ensure_ascii=False)
            
        # ë‚ ì§œë³„ ì•„ì¹´ì´ë¸Œ ì €ì¥
        if target_date:
             date_str = target_date.replace('-', '') if isinstance(target_date, str) else target_date.strftime('%Y%m%d')
        else:
             date_str = datetime.now().strftime('%Y%m%d')
        
        archive_path = os.path.join(BASE_DIR, 'data', f'market_gate_{date_str}.json')
        with open(archive_path, 'w', encoding='utf-8') as f:
             json.dump(gate_data, f, indent=2, ensure_ascii=False)
             
        log(f"Market Gate ë°ì´í„° ìƒì„± ì™„ë£Œ: {file_path}", "SUCCESS")
        return True

    except Exception as e:
        log(f"Market Gate ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}", "ERROR")
        return False

def create_kr_ai_analysis(target_date=None):
    """AI ë¶„ì„ ê²°ê³¼ ìƒì„± (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)"""
    log("AI ë¶„ì„ ì‹œì‘ (Real Mode)...")
    try:
        import sys
        # Root path ì¶”ê°€
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if root_dir not in sys.path:
            sys.path.append(root_dir)
            
        from engine.kr_ai_analyzer import KrAiAnalyzer
        import pandas as pd
        import json
        
        # ë‚ ì§œ ì„¤ì •
        if not target_date:
            target_date = datetime.now().strftime('%Y-%m-%d')
            
        data_dir = os.path.join(BASE_DIR, 'data')
        signals_path = os.path.join(data_dir, 'signals_log.csv')
        
        if not os.path.exists(signals_path):
            log("VCP ì‹œê·¸ë„ íŒŒì¼ì´ ì—†ì–´ AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.", "WARNING")
            return
            
        # VCP ê²°ê³¼ ë¡œë“œ
        df = pd.read_csv(signals_path, dtype={'ticker': str, 'signal_date': str})
        if df.empty:
            log("VCP ì‹œê·¸ë„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.", "WARNING")
            return

        # í•´ë‹¹ ë‚ ì§œ ë°ì´í„° í•„í„°ë§
        target_df = df[df['signal_date'] == str(target_date)].copy()
        
        if target_df.empty:
            # ë‚ ì§œ í¬ë§· ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„± ì²´í¬ (YYYY-MM-DD vs YYYYMMDD)
            alt_date = target_date.replace('-', '')
            target_df = df[df['signal_date'] == alt_date].copy()
            
        if target_df.empty:
            log(f"í•´ë‹¹ ë‚ ì§œ({target_date})ì˜ VCP ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤.", "WARNING")
            return

        # [í•„ìˆ˜] ê¸°ì¡´ ë¶„ì„ íŒŒì¼ ì‚­ì œ (ì´ˆê¸°í™”)
        date_str_clean = str(target_date).replace('-', '')
        filename = f'ai_analysis_results_{date_str_clean}.json'
        filepath = os.path.join(data_dir, filename)
        
        if os.path.exists(filepath):
            try:
                os.remove(filepath)
                log(f"ê¸°ì¡´ AI ë¶„ì„ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {filename}", "INFO")
            except Exception as e:
                log(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}", "WARNING")

        # ë¶„ì„ ëŒ€ìƒ ì„ ì • (Score ìƒìœ„ 20ê°œ)
        if 'score' in target_df.columns:
            target_df['score'] = pd.to_numeric(target_df['score'], errors='coerce').fillna(0)
            target_df = target_df.sort_values('score', ascending=False)
            
        target_df = target_df.head(20)
        tickers = target_df['ticker'].tolist()
        
        log(f"AI ë¶„ì„ ëŒ€ìƒ: {len(tickers)} ì¢…ëª©")
        
        # ë¶„ì„ ì‹¤í–‰
        analyzer = KrAiAnalyzer()
        results = analyzer.analyze_multiple_stocks(tickers)
        
        # ë©”íƒ€ë°ì´í„°
        results['generated_at'] = datetime.now().isoformat()
        results['signal_date'] = target_date
        
        # ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
            
        log(f"AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}", "SUCCESS")
        
        # ìµœì‹  íŒŒì¼(ai_analysis_results.json)ë„ ì—…ë°ì´íŠ¸ (ì˜¤ëŠ˜ ë‚ ì§œì¸ ê²½ìš°)
        if target_date == datetime.now().strftime('%Y-%m-%d'):
            main_path = os.path.join(data_dir, 'ai_analysis_results.json')
            with open(main_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
                
        return True

    except Exception as e:
        log(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        return False

def create_kr_ai_analysis_with_key(target_dates=None, api_key=None):
    """
    [ì‚¬ìš©ì ìš”ì²­] API Keyë¥¼ ì£¼ì…í•˜ì—¬ AI ë¶„ì„ ì‹¤í–‰ (create_kr_ai_analysis ë³€í˜•)
    - ê³µìš© ë°°ì¹˜ ì‘ì—…ì´ ì•„ë‹ˆë¼, íŠ¹ì • ì‚¬ìš©ìì˜ ìš”ì²­ì— ì˜í•´ íŠ¸ë¦¬ê±°ë¨.
    - target_dates: ['YYYY-MM-DD', ...] or None
    - api_key: ì‚¬ìš©ìì˜ Google Gemini API Key (ì—†ìœ¼ë©´ ê³µìš© í‚¤ ì‚¬ìš© - ì •ì±…ì— ë”°ë¦„)
    """
    log(f"AI ì¬ë¶„ì„ ìš”ì²­ (Key Present: {bool(api_key)})", "INFO")
    
    try:
        import sys
        # Root path ì¶”ê°€
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if root_dir not in sys.path:
            sys.path.append(root_dir)
            
        from kr_ai_analyzer import KrAiAnalyzer
        import pandas as pd
        import json
        
        # Analyzer ì´ˆê¸°í™”ì‹œ í‚¤ ì£¼ì…
        analyzer = KrAiAnalyzer(api_key=api_key)
        
        data_dir = os.path.join(BASE_DIR, 'data')
        signals_path = os.path.join(data_dir, 'signals_log.csv')
        
        if not os.path.exists(signals_path):
            log("VCP ì‹œê·¸ë„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", "WARNING")
            return {'count': 0}

        df = pd.read_csv(signals_path, dtype={'ticker': str, 'signal_date': str})
        if df.empty:
            return {'count': 0}

        # ë‚ ì§œ í•„í„°ë§
        if not target_dates:
            # ë‚ ì§œ ì—†ìœ¼ë©´ ìµœì‹  ë‚ ì§œ í•˜ë‚˜ë§Œ
            latest_date = df['signal_date'].max()
            target_dates = [latest_date]
            
        all_results = {}
        total_analyzed = 0
        
        for t_date in target_dates:
            log(f"Deep Analysis for date: {t_date}")
            
            # ë‚ ì§œ í¬ë§· ë§¤ì¹­
            target_df = df[df['signal_date'] == str(t_date)].copy()
            if target_df.empty:
                 alt_date = str(t_date).replace('-', '')
                 target_df = df[df['signal_date'] == alt_date].copy()
            
            if target_df.empty:
                continue
                
            # Score ìƒìœ„ ì¢…ëª© ì„ ì •
            if 'score' in target_df.columns:
                target_df['score'] = pd.to_numeric(target_df['score'], errors='coerce').fillna(0)
                target_df = target_df.sort_values('score', ascending=False)
            
            # ìµœëŒ€ 20ê°œ (Rate Limit ë° ì‹œê°„ ê³ ë ¤)
            target_df = target_df.head(20)
            tickers = target_df['ticker'].tolist()
            
            # ë¶„ì„ ì‹¤í–‰
            results = analyzer.analyze_multiple_stocks(tickers) # api_key ì‚¬ìš©ë¨
            
            if results and 'signals' in results:
                count = len(results['signals'])
                total_analyzed += count
                
                # ì €ì¥ (ë®ì–´ì“°ê¸°)
                date_str_clean = str(t_date).replace('-', '')
                filename = f'ai_analysis_results_{date_str_clean}.json'
                filepath = os.path.join(data_dir, filename)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                
                # ì˜¤ëŠ˜ ë‚ ì§œë©´ ë©”ì¸ íŒŒì¼ë„ ì—…ë°ì´íŠ¸
                if t_date == datetime.now().strftime('%Y-%m-%d'):
                    main_path = os.path.join(data_dir, 'ai_analysis_results.json')
                    with open(main_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, ensure_ascii=False, indent=2)
                        
        return {'count': total_analyzed}

    except Exception as e:
        log(f"AI ì¬ë¶„ì„ ì‹¤íŒ¨: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}

def send_jongga_notification():
    """ì¢…ê°€ë² íŒ… V2 ê²°ê³¼ ì•Œë¦¼ ë°œì†¡"""
    try:
        import json
        import os
        from engine.messenger import Messenger
        from engine.models import ScreenerResult, Signal, ScoreDetail, ChecklistDetail, SignalStatus, Grade
        from datetime import datetime
        
        data_file = os.path.join(BASE_DIR, 'data', 'jongga_v2_latest.json')
        
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                file_data = json.load(f)
            
            if file_data and file_data.get('signals'):
                # ê°ì²´ ë³µì› (Messenger í˜¸í™˜ì„±)
                signals = []
                for s in file_data.get('signals', []):
                    # ScoreDetail ë³µì›
                    sc = s.get('score', {})
                    score_kwargs = {k: v for k, v in sc.items() if k != 'total'}
                    score_obj = ScoreDetail(**score_kwargs)
                    
                    # ChecklistDetail ë³µì›
                    cl = s.get('checklist', {})
                    checklist_obj = ChecklistDetail(**cl)
                    
                    # ë‚ ì§œ/ì‹œê°„
                    try:
                        sig_date = datetime.strptime(s.get('signal_date', datetime.now().strftime('%Y-%m-%d')), '%Y-%m-%d').date()
                    except:
                        sig_date = datetime.now().date()
                        
                    try:
                        created_at = datetime.fromisoformat(s.get('created_at', datetime.now().isoformat()))
                    except:
                        created_at = datetime.now()
                    
                    # Enum ì²˜ë¦¬
                    grade_val = s.get('grade')
                    if isinstance(grade_val, str):
                        try:
                            grade = Grade(grade_val)
                        except:
                            grade = grade_val
                    
                    status_val = s.get('status', 'waiting')
                    if isinstance(status_val, str):
                        try:
                            status = SignalStatus(status_val)
                        except:
                            status = SignalStatus.PENDING
                    
                    target_price = s.get('target_price', 0)
                    if target_price == 0:
                        target_price = s.get('target_price_1', 0)

                    signal_obj = Signal(
                        stock_code=s['stock_code'],
                        stock_name=s['stock_name'],
                        market=s.get('market', ''),
                        sector=s.get('sector', ''),
                        signal_date=sig_date,
                        signal_time=datetime.now(),
                        grade=grade,
                        score=score_obj,
                        checklist=checklist_obj,
                        news_items=s.get('news_items', []),
                        current_price=s.get('current_price', 0.0),
                        entry_price=s.get('entry_price', 0),
                        stop_price=s.get('stop_price', 0),
                        target_price=target_price,
                        r_value=s.get('r_value', 0.0),
                        position_size=s.get('position_size', 0.0),
                        quantity=s.get('quantity', 0),
                        r_multiplier=s.get('r_multiplier', 0.0),
                        trading_value=s.get('trading_value', 0),
                        change_pct=s.get('change_pct', 0.0),
                        status=status,
                        created_at=created_at,
                        volume_ratio=s.get('volume_ratio', 0.0),
                        themes=s.get('themes', []),
                        score_details=s.get('score_details', {})
                    )
                    signals.append(signal_obj)
                    
                # ScreenerResult ìƒì„±
                res_date = datetime.now().date()
                try:
                    date_val = file_data.get('date')
                    if date_val:
                        res_date = datetime.strptime(date_val, '%Y-%m-%d').date()
                except:
                    pass
                
                # Calculate statistics if missing
                by_grade = file_data.get('by_grade', {})
                if not by_grade:
                    from collections import Counter
                    grades = [str(s.grade.value if hasattr(s.grade, 'value') else s.grade) for s in signals]
                    by_grade = dict(Counter(grades))
                    
                by_market = file_data.get('by_market', {})
                if not by_market:
                    from collections import Counter
                    markets = [s.market for s in signals]
                    by_market = dict(Counter(markets))
                    
                result = ScreenerResult(
                    date=res_date,
                    total_candidates=file_data.get('total_candidates', 0),
                    filtered_count=len(signals),
                    signals=signals,
                    by_grade=by_grade,
                    by_market=by_market,
                    processing_time_ms=file_data.get('processing_time_ms', 0.0),
                    market_status=file_data.get('market_status'),
                    market_summary=file_data.get('market_summary', ""),
                    trending_themes=file_data.get('trending_themes', [])
                )
                
                messenger = Messenger()
                messenger.send_screener_result(result)
                log(f"ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ: {len(signals)}ê°œ ì‹ í˜¸", "SUCCESS")
            else:
                log("ë°œì†¡í•  ì‹ í˜¸ ì—†ìŒ (0ê°œ)", "INFO")
                
    except Exception as notify_error:
        log(f"ì•Œë¦¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {notify_error}", "ERROR")
        import traceback
        traceback.print_exc()

def main():
    log("ë°ì´í„° ì´ˆê¸°í™” ì‹œì‘...", "HEADER")
    data_dir = os.path.join(BASE_DIR, 'data')
    ensure_directory(data_dir)
    
    tasks = [
        create_korean_stocks_list,
        create_daily_prices,
        create_institutional_trend,
        create_signals_log,
        create_jongga_v2_latest,

        create_kr_ai_analysis  # AI ë¶„ì„ ì¶”ê°€
    ]

    
    success_count = 0
    total_tasks = len(tasks)
    
    for task in tasks:
        if task():
            success_count += 1
            
    print()
    log("ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ", "HEADER")
    print(f"ì™„ë£Œëœ ì‘ì—…: {success_count}/{total_tasks}")
    
    if success_count == total_tasks:
        log("ğŸ‰ ëª¨ë“  ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!", "SUCCESS")
        log("ë‹¤ìŒ ë‹¨ê³„: [python3 flask_app.py] ì‹¤í–‰ í›„ í”„ë¡ íŠ¸ì—”ë“œ í™•ì¸")
    else:
        log(f"âš ï¸ ì¼ë¶€ ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ ({total_tasks - success_count}/{total_tasks}).", "WARNING")
        log("ìƒì„¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", "WARNING")

if __name__ == '__main__':
    main()
